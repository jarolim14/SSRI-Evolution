{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "a7dd7"
   },
   "source": [
    "# Text processor and text embeddings\n",
    "\n",
    "In this notebook, we first create a new column `title_abstract` and then use a huggingface model to create text embeddings for this column.\n",
    "\n",
    "This column is a concatenation of the `title` and `abstract` columns and processes the text in the follwing way:\n",
    "\n",
    "- remove phrases like `abstract` and `introduction` from the text\n",
    "- removes ending phrases like copyrights, version numbers of journals, journal names\n",
    "- merges the title and abstract columns with `. ` as a separator\n",
    "\n",
    "We then use specter2 to create text embeddings for this column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "8f3f6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.nlp.TextProcessor import TextProcessor\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "python_path = os.getenv(\"PYTHONPATH\")\n",
    "data_dir = os.getenv(\"DATA_DIR\")\n",
    "src_dir = os.getenv(\"SRC_DIR\")\n",
    "output_dir = os.getenv(\"OUTPUT_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "72194"
   },
   "source": [
    "# read in data and process text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "bc96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA dict saved to output/descriptive-stats-logs/na_log_text_cols_20250326.json\n",
      "cleaned text and removed start and ending statements\n",
      "cleaned text - embed me now :)\n",
      "Papers to embed: 38961\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(data_dir + \"/03-connected/scopus_cleaned_connected_20250326.pkl\")\n",
    "cols = [\"abstract\", \"title\"]\n",
    "\n",
    "file_path = output_dir + \"/descriptive-stats-logs/na_log_text_cols_20250326.json\"\n",
    "\n",
    "tp = TextProcessor(df)\n",
    "tp.save_na_dict_to_json(cols, file_path)\n",
    "df = tp.clean_text_and_remove_start_and_ending_statements(\n",
    "    return_cleaned_text_separately=True\n",
    ")\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Papers to embed: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellUniqueIdByVincent": "dade4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eid', 'title', 'date', 'first_author', 'abstract', 'doi', 'year',\n",
       "       'auth_year', 'unique_auth_year', 'pubmed_id', 'api_url', 'scopus_id',\n",
       "       'journal', 'citedby_count', 'publication_type', 'publication_subtype',\n",
       "       'publication_subtype_description', 'author_count', 'authors_json',\n",
       "       'authkeywords', 'funding_no', 'openaccess', 'openaccess_flag',\n",
       "       'freetoread', 'freetoread_label', 'fund_acr', 'fund_sponsor',\n",
       "       'article_number', 'reference_eids', 'nr_references',\n",
       "       'filtered_reference_eids', 'nr_filtered_references', 'title_abstract',\n",
       "       'clean_title', 'clean_abstract'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "48701"
   },
   "source": [
    "# Create Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "6292e"
   },
   "outputs": [],
   "source": [
    "from src.nlp.EmbeddingCreator import PaperEmbeddingProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "fbfa3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90def545b5f84c9eb3a65e4680a9fb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [4:19:29<00:00, 973.09s/it]  \n"
     ]
    }
   ],
   "source": [
    "processor = PaperEmbeddingProcessor(\n",
    "    df=df,\n",
    "    model_name=\"allenai/specter2_base\",\n",
    "    adapter_name=\"specter2\",  # this is for \"proximity\"\n",
    "    save_dir=data_dir + \"/04-embeddings/2025\",\n",
    "    batch_size=32,\n",
    "    chunk_size=2500,  # 2500\n",
    ")\n",
    "total_embeddings = processor.process_papers()\n",
    "processor.save_embeddings_with_data(total_embeddings)"
   ]
  }
 ],
 "metadata": {
  "vincent": {
   "sessionId": "d3d8c4b98585e675d290449a_2025-06-10T14-01-58-188Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
