{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Disable SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Graphs and networks\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "# Scientific computing\n",
    "import math\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_hex, to_rgb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Data visualization and processing\n",
    "import colorcet as cc\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.bundling import hammer_bundle\n",
    "\n",
    "# Performance optimization\n",
    "from numba import jit, prange\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Custom modules\n",
    "from bundling3D import *\n",
    "from fa2_modified import ForceAtlas2\n",
    "\n",
    "# Set Seaborn style for plots\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Constants and configuration\n",
    "INPUT_GRAPH_PATH = \"../data/07-clustered-graphs/alpha0.3_k10_res0.002.graphml\"\n",
    "CLUSTER_INFO_LABEL_TREE = \"../output/cluster-qualifications/ClusterInfoLabelTree.xlsx\"\n",
    "CLUSTER_LABEL_DICT_PATH = \"../data/99-testdata/cluster_label_dict.json\"\n",
    "CLUSTER_TREE_PATH = \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    "OUTPUT_DIR = \"../data/99-testdata/\"\n",
    "THREEJS_OUTPUT_DIR = (\n",
    "    \"/Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/\"\n",
    ")\n",
    "CLUSTER_HIERACHY_FOR_LEGEND_PATH = (\n",
    "    \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataFrameUtility:\n",
    "    \"\"\"\n",
    "    A utility class for converting igraph graph attributes to pandas DataFrames\n",
    "    and performing DataFrame operations related to graph data.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def edges_to_dataframe(g: ig.Graph) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the edges and their attributes of an igraph graph to a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input igraph graph.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing edge attributes, source, and target nodes.\n",
    "        \"\"\"\n",
    "        # check if networkx or igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        # Extract edge attributes\n",
    "        edge_data = {attr: g.es[attr] for attr in g.es.attributes()}\n",
    "\n",
    "        # Add source and target node indices\n",
    "        edge_data[\"source\"] = [e.source for e in g.es]\n",
    "        edge_data[\"target\"] = [e.target for e in g.es]\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        edge_dataframe = pd.DataFrame(edge_data)\n",
    "\n",
    "        return edge_dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def nodes_to_dataframe(\n",
    "        g: ig.Graph, drop_columns: Optional[List[str]] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the nodes and their attributes of an igraph graph to a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input igraph graph.\n",
    "            drop_columns (Optional[List[str]]): A list of column names to drop from the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing node attributes and node indices.\n",
    "        \"\"\"\n",
    "        # check if networkx or igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        # Extract node attributes\n",
    "        node_data = {attr: g.vs[attr] for attr in g.vs.attributes()}\n",
    "\n",
    "        # Add node indices\n",
    "        node_dataframe = pd.DataFrame(node_data)\n",
    "        node_dataframe[\"node_index\"] = [n.index for n in g.vs]\n",
    "        # Calculate min/max for coordinates\n",
    "        xmin, xmax = np.min(node_dataframe[\"x\"]), np.max(node_dataframe[\"x\"])\n",
    "        ymin, ymax = np.min(node_dataframe[\"y\"]), np.max(node_dataframe[\"y\"])\n",
    "        zmin, zmax = np.min(node_dataframe[\"z\"]), np.max(node_dataframe[\"z\"])\n",
    "\n",
    "        # Normalize coordinates\n",
    "        node_dataframe[\"x\"] = minmax_normalize(node_dataframe[\"x\"], xmin, xmax)\n",
    "        node_dataframe[\"y\"] = minmax_normalize(node_dataframe[\"y\"], ymin, ymax)\n",
    "        node_dataframe[\"z\"] = minmax_normalize(node_dataframe[\"z\"], zmin, zmax)\n",
    "\n",
    "        print(\"Coordinates normalized to [0, 1] range.\")\n",
    "\n",
    "        # Drop specified columns if provided\n",
    "        if drop_columns:\n",
    "            node_dataframe = node_dataframe.drop(columns=drop_columns, errors=\"ignore\")\n",
    "\n",
    "        return node_dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_edge_node_positions(\n",
    "        edge_dataframe: pd.DataFrame, node_dataframe: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Merge the edge DataFrame with node positions (x, y, z) for source and target nodes.\n",
    "\n",
    "        Args:\n",
    "            edge_dataframe (pd.DataFrame): DataFrame containing edge information.\n",
    "            node_dataframe (pd.DataFrame): DataFrame containing node positions and other attributes.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A merged DataFrame with source and target node positions, cleaned and indexed.\n",
    "        \"\"\"\n",
    "        # Merge edge DataFrame with source node positions\n",
    "        edge_node_pos_df = pd.merge(\n",
    "            edge_dataframe,\n",
    "            node_dataframe[[\"x\", \"y\", \"z\"]],\n",
    "            left_on=\"source\",\n",
    "            right_index=True,\n",
    "        )\n",
    "        edge_node_pos_df = edge_node_pos_df.rename(\n",
    "            columns={\"x\": \"source_x\", \"y\": \"source_y\", \"z\": \"source_z\"}\n",
    "        )\n",
    "\n",
    "        # Merge with target node positions\n",
    "        edge_node_pos_df = pd.merge(\n",
    "            edge_node_pos_df,\n",
    "            node_dataframe[[\"x\", \"y\", \"z\"]],\n",
    "            left_on=\"target\",\n",
    "            right_index=True,\n",
    "        )\n",
    "        edge_node_pos_df = edge_node_pos_df.rename(\n",
    "            columns={\"x\": \"target_x\", \"y\": \"target_y\", \"z\": \"target_z\"}\n",
    "        )\n",
    "\n",
    "        # Print shape before and after dropping NaNs\n",
    "        print(f\"Shape before dropping NaNs: {edge_node_pos_df.shape}\")\n",
    "\n",
    "        # Drop rows with any NaN values\n",
    "        edge_node_pos_df.dropna(inplace=True)\n",
    "\n",
    "        # Sort and reset the index\n",
    "        edge_node_pos_df = edge_node_pos_df.sort_index().reset_index(drop=True)\n",
    "\n",
    "        print(f\"Shape after cleaning: {edge_node_pos_df.shape}\")\n",
    "\n",
    "        # calculate segment_lenths of all edges\n",
    "\n",
    "        edge_node_pos_df[\"segment_length\"] = [\n",
    "            distance_between(x[:3], x[3:])\n",
    "            for x in edge_node_pos_df[\n",
    "                [\"source_x\", \"source_y\", \"source_z\", \"target_x\", \"target_y\", \"target_z\"]\n",
    "            ].values\n",
    "        ]\n",
    "\n",
    "        edge_node_pos_df = edge_node_pos_df[edge_node_pos_df[\"segment_length\"] > 0]\n",
    "\n",
    "        edge_node_pos_df[[\"source\", \"target\"]] = (\n",
    "            edge_node_pos_df[[\"source\", \"target\"]]\n",
    "            .stack()\n",
    "            .rank(method=\"dense\")\n",
    "            .unstack()\n",
    "            .astype(int)\n",
    "        )\n",
    "\n",
    "        # Print min, max, and mean segment lengths\n",
    "        print(\"Segment length statistics:\")\n",
    "        print(f\"Min: {edge_node_pos_df['segment_length'].min()}\")\n",
    "        print(f\"Max: {edge_node_pos_df['segment_length'].max()}\")\n",
    "        print(f\"Mean: {edge_node_pos_df['segment_length'].mean()}\")\n",
    "        print(f\"Median: {edge_node_pos_df['segment_length'].median()}\")\n",
    "\n",
    "        return edge_node_pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphReader:\n",
    "    @staticmethod\n",
    "    def read_and_clean_graph(path: str) -> ig.Graph:\n",
    "        g = ig.Graph.Read_GraphML(path)\n",
    "        g.vs[\"node_id\"] = [int(i) for i in range(g.vcount())]\n",
    "\n",
    "        if \"id\" in g.vs.attribute_names():\n",
    "            g.vs[\"node_name\"] = g.vs[\"id\"]\n",
    "            del g.vs[\"id\"]\n",
    "\n",
    "        if \"cluster\" in g.vs.attribute_names():\n",
    "            g.vs[\"cluster\"] = [int(cluster) for cluster in g.vs[\"cluster\"]]\n",
    "\n",
    "        if \"year\" in g.vs.attribute_names():\n",
    "            g.vs[\"year\"] = [int(year) for year in g.vs[\"year\"]]\n",
    "\n",
    "        if \"eid\" in g.vs.attribute_names():\n",
    "            del g.vs[\"eid\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.006\" in g.vs.attribute_names():\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.006\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.002\" in g.vs.attribute_names():\n",
    "            g.vs[\"centrality\"] = g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "\n",
    "        g.es[\"edge_id\"] = list(range(g.ecount()))\n",
    "        print(\"Node Attributes:\", g.vs.attribute_names())\n",
    "        print(\"Edge Attributes:\", g.es.attribute_names())\n",
    "        # print number of nodes and edges\n",
    "        print(f\"Number of nodes: {g.vcount()}\")\n",
    "        print(f\"Number of edges: {g.ecount()}\")\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def subgraph_of_clusters(G, clusters):\n",
    "        if isinstance(G, nx.Graph):\n",
    "            nodes = [\n",
    "                node for node in G.nodes if G.nodes[node].get(\"cluster\") in clusters\n",
    "            ]\n",
    "            return G.subgraph(nodes)\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            nodes = [v.index for v in G.vs if v[\"cluster\"] in clusters]\n",
    "            return G.subgraph(nodes)\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "    @staticmethod\n",
    "    def add_cluster_labels(\n",
    "        G: Union[nx.Graph, ig.Graph],\n",
    "        labels_file_path: str = \"../output/cluster-qualifications/raw_cluster_labels.json\",\n",
    "    ) -> Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "        \"\"\"\n",
    "        Add cluster labels to the graph nodes.\n",
    "\n",
    "        Args:\n",
    "            G (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "            labels_file_path (str): Path to the JSON file containing cluster labels.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "                The graph with added cluster labels and the cluster label dictionary.\n",
    "        \"\"\"\n",
    "        with open(labels_file_path) as file:\n",
    "            cluster_label_dict = json.load(file)\n",
    "        cluster_label_dict = {float(k): v[0] for k, v in cluster_label_dict.items()}\n",
    "\n",
    "        if isinstance(G, nx.Graph):\n",
    "            for node in G.nodes:\n",
    "                cluster = G.nodes[node][\"cluster\"]\n",
    "                G.nodes[node][\"cluster_label\"] = cluster_label_dict.get(\n",
    "                    cluster, \"Unknown\"\n",
    "                )\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            G.vs[\"cluster_label\"] = [\n",
    "                cluster_label_dict.get(v[\"cluster\"], \"Unknown\") for v in G.vs\n",
    "            ]\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "        return G, cluster_label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout Utilities (Fruchterman-Reingold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "from typing import Union, Dict, Tuple, Optional\n",
    "\n",
    "\n",
    "class LayoutUtility:\n",
    "    \"\"\"\n",
    "    Layout utility class for igraph layout operations. made for fruchterman-reingold layout.\n",
    "\n",
    "    Args:\n",
    "        g (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "        layout_params (Optional[Dict]): The layout parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[nx.Graph, Dict]: The graph with assigned coordinates and the layout dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fr_layout_nx(\n",
    "        g: Union[nx.Graph, ig.Graph], layout_params: Optional[Dict] = None\n",
    "    ) -> Tuple[nx.Graph, Dict]:\n",
    "        print(\"Starting Fruchterman-Reingold layout process...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if layout_params is None:\n",
    "            layout_params = {\n",
    "                \"iterations\": 100,\n",
    "                \"threshold\": 0.00001,\n",
    "                \"weight\": \"weight\",\n",
    "                \"scale\": 1,\n",
    "                \"center\": (0, 0),\n",
    "                \"dim\": 2,\n",
    "                \"seed\": 1887,\n",
    "            }\n",
    "        print(f\"Layout parameters: {layout_params}\")\n",
    "\n",
    "        if not isinstance(g, nx.Graph):\n",
    "            print(\"Converting to NetworkX Graph...\")\n",
    "            G = g.to_networkx()\n",
    "            print(\"Conversion complete.\")\n",
    "        else:\n",
    "            G = g\n",
    "\n",
    "        print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "        print(\"Calculating layout...\")\n",
    "        layout_start_time = time.time()\n",
    "        pos = nx.spring_layout(G, **layout_params)\n",
    "        layout_end_time = time.time()\n",
    "        print(\n",
    "            f\"Layout calculation completed in {layout_end_time - layout_start_time:.2f} seconds.\"\n",
    "        )\n",
    "\n",
    "        print(\"Processing layout results...\")\n",
    "        node_xy_dict = {node: pos[node] for node in G.nodes}\n",
    "\n",
    "        x_values, y_values = zip(*node_xy_dict.values())\n",
    "        min_x, max_x = min(x_values), max(x_values)\n",
    "        min_y, max_y = min(y_values), max(y_values)\n",
    "\n",
    "        print(f\"Layout boundaries:\")\n",
    "        print(f\"X-axis: Min = {min_x:.2f}, Max = {max_x:.2f}\")\n",
    "        print(f\"Y-axis: Min = {min_y:.2f}, Max = {max_y:.2f}\")\n",
    "\n",
    "        print(\"Assigning coordinates to nodes...\")\n",
    "        for node in G.nodes:\n",
    "            G.nodes[node][\"x\"] = node_xy_dict[node][0]\n",
    "            G.nodes[node][\"y\"] = node_xy_dict[node][1]\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Layout process completed in {total_time:.2f} seconds.\")\n",
    "\n",
    "        return G, pos\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# g = ... # your graph object\n",
    "# G, pos = LayoutUtility.fr_layout_nx(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add z coordinates to the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZCoordinateAdder:\n",
    "    def __init__(self, g, scale_factor=0.15):\n",
    "        self.g = g\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def add_z_coordinate_to_nodes(self):\n",
    "        \"\"\"\n",
    "        Add a z-coordinate to the nodes of the graph based on their centrality values.\n",
    "\n",
    "        Args:\n",
    "            g (nx.Graph): The input graph.\n",
    "            scale_factor (float): The scaling factor for the z-coordinates. (they should not be as spread out as x and y)\n",
    "\n",
    "        Returns:\n",
    "            nx.Graph: The graph with the z-coordinate added to the nodes.\n",
    "        \"\"\"\n",
    "        # Calculate the bounds of x and y coordinates\n",
    "        # Assuming self.g is a NetworkX graph\n",
    "        xvalues = [attributes[\"x\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        yvalues = [attributes[\"y\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        min_x, max_x = min(xvalues), max(xvalues)\n",
    "        min_y, max_y = min(yvalues), max(yvalues)\n",
    "\n",
    "        print(\"Bounds of the layout:\")\n",
    "        print(f\"Min x: {min_x}, Max x: {max_x}\")\n",
    "        print(f\"Min y: {min_y}, Max y: {max_y}\")\n",
    "\n",
    "        # Extract centrality values from nodes\n",
    "        centralities = np.array(\n",
    "            [self.g.nodes[node][\"centrality\"] for node in self.g.nodes]\n",
    "        )\n",
    "\n",
    "        # Normalize centrality values to range [0, 1]\n",
    "        centrality_min = centralities.min()\n",
    "        centrality_max = centralities.max()\n",
    "        centralities_normalized = (centralities - centrality_min) / (\n",
    "            centrality_max - centrality_min\n",
    "        )\n",
    "\n",
    "        # Adjust normalized centrality values to range [-1, 1]\n",
    "        centralities_adjusted = centralities_normalized * 2 - 1\n",
    "\n",
    "        # Scale down the z-values to make them less pronounced\n",
    "        z_coordinates = centralities_adjusted * self.scale_factor\n",
    "\n",
    "        # Add z-coordinate to nodes\n",
    "        for i, node in enumerate(self.g.nodes):\n",
    "            self.g.nodes[node][\"z\"] = z_coordinates[i]\n",
    "\n",
    "        # Describe the distribution of z values\n",
    "        print(\"Description of the Z coordinate values:\")\n",
    "        print(pd.Series(z_coordinates).describe())\n",
    "\n",
    "        print(\"Z coordinate added to nodes\")\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class PruneEdges:\n",
    "    \"\"\"\n",
    "    A class for pruning edges in a graph based on specific criteria, such as edge weight percentiles or random selection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initial_edge_count = 0\n",
    "        self.initial_isolates = 0\n",
    "        self.final_edge_count = 0\n",
    "        self.final_isolates = 0\n",
    "\n",
    "    def _update_statistics(self, g: ig.Graph, g_modified: ig.Graph) -> None:\n",
    "        \"\"\"\n",
    "        Update class attributes related to graph statistics.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The original graph.\n",
    "            g_modified (ig.Graph): The modified graph after pruning or random selection.\n",
    "        \"\"\"\n",
    "        self.initial_edge_count = g.ecount()\n",
    "        self.initial_isolates = len(g.vs.select(_degree=0))\n",
    "        self.final_edge_count = g_modified.ecount()\n",
    "        self.final_isolates = len(g_modified.vs.select(_degree=0))\n",
    "\n",
    "    def prune_edges_by_percentile_weight(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Remove edges from the graph that have weight less than or equal to the specified percentile weight.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph. Must have a 'weight' attribute for edges.\n",
    "            percentile (float): The percentile to use as the threshold for pruning edges.\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with edges removed based on the specified percentile.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input graph has no 'weight' attribute for edges.\n",
    "            ValueError: If percentile is not between 0 and 100.\n",
    "        \"\"\"\n",
    "        if not (0 <= percentile <= 100):\n",
    "            raise ValueError(\"Percentile must be between 0 and 100.\")\n",
    "\n",
    "        if \"weight\" not in g.es.attributes():\n",
    "            raise ValueError(\"Input graph must have a 'weight' attribute for edges.\")\n",
    "\n",
    "        # Get all weights and calculate the specified percentile\n",
    "        weights = g.es[\"weight\"]\n",
    "        weight_threshold = np.percentile(weights, percentile)\n",
    "\n",
    "        # Identify edges to keep\n",
    "        edges_to_keep = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] > weight_threshold\n",
    "        ]\n",
    "        threshold_edges = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] == weight_threshold\n",
    "        ]\n",
    "\n",
    "        # Randomly select from threshold edges to reach target number of edges\n",
    "        target_edge_count = int(self.initial_edge_count * (1 - percentile / 100))\n",
    "        edges_to_add = target_edge_count - len(edges_to_keep)\n",
    "        if edges_to_add > 0:\n",
    "            random.shuffle(threshold_edges)\n",
    "            edges_to_keep.extend(threshold_edges[:edges_to_add])\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_pruned = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Update statistics\n",
    "        self._update_statistics(g, g_pruned)\n",
    "\n",
    "        return g_pruned\n",
    "\n",
    "    def keep_random_percentile_of_edges(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Keep a random selection of edges based on the provided percentile.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph.\n",
    "            percentile (float): The percentile of edges to keep (0-100).\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with the randomly selected edges.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If percentile is not between 0 and 100.\n",
    "        \"\"\"\n",
    "        if not (0 <= percentile <= 100):\n",
    "            raise ValueError(\"percentile must be between 0 and 100.\")\n",
    "\n",
    "        # Calculate the number of edges to keep\n",
    "        total_edges = g.ecount()\n",
    "        num_edges_to_keep = int(total_edges * (percentile / 100))\n",
    "\n",
    "        # Randomly select edges to keep\n",
    "        all_edges = list(range(total_edges))\n",
    "        random.shuffle(all_edges)\n",
    "        edges_to_keep = all_edges[:num_edges_to_keep]\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_random = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Update statistics\n",
    "        self._update_statistics(g, g_random)\n",
    "\n",
    "        return g_random\n",
    "\n",
    "    def get_prune_summary(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Returns a summary of the pruning process.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, int]: A dictionary containing the initial and final edge counts and the number of isolates.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"initial_edge_count\": self.initial_edge_count,\n",
    "            \"final_edge_count\": self.final_edge_count,\n",
    "            \"initial_isolates\": self.initial_isolates,\n",
    "            \"final_isolates\": self.final_isolates,\n",
    "        }\n",
    "\n",
    "\n",
    "# example usage\n",
    "# g = ... # your graph object\n",
    "# pruner = PruneEdges()\n",
    "# g_pruned = pruner.prune_edges_by_percentile_weight(g, 10)\n",
    "# summary = pruner.get_prune_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes Saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodesSaver:\n",
    "    \"\"\"\n",
    "    A utility class for saving graph data to JSON format, particularly for use in JavaScript applications.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_igraph_nodes_to_json(\n",
    "        g: ig.Graph,\n",
    "        paths: Union[str, List[str]],\n",
    "        return_json: bool = False,\n",
    "        attributes: List[str] = None,\n",
    "    ) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Save the igraph nodes to one or more JSON files.\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph.\n",
    "            paths (Union[str, List[str]]): Path or list of paths to save the JSON file(s).\n",
    "            return_json (bool): If True, return the JSON data as well as saving it.\n",
    "            attributes (List[str]): List of node attributes to include in the JSON.\n",
    "        Returns:\n",
    "            Optional[List[Dict]]: List of node dictionaries if return_json is True, else None.\n",
    "        Raises:\n",
    "            ValueError: If a specified attribute is missing from a node.\n",
    "        \"\"\"\n",
    "        if attributes is None:\n",
    "            attributes = [\n",
    "                \"node_id\",\n",
    "                \"node_name\",\n",
    "                \"doi\",\n",
    "                \"year\",\n",
    "                \"title\",\n",
    "                \"cluster\",\n",
    "                \"centrality\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "\n",
    "        # Fix encoding of titles\n",
    "        g.vs[\"title\"] = [NodesSaver.fix_encoding(title) for title in g.vs[\"title\"]]\n",
    "\n",
    "        nodes_json = []\n",
    "        for node in g.vs:\n",
    "            if not all(attr in node.attributes() for attr in attributes):\n",
    "                raise ValueError(f\"Missing attribute in node: {node.attributes()}\")\n",
    "            node_dict = {attr: node[attr] for attr in attributes}\n",
    "            nodes_json.append(node_dict)\n",
    "\n",
    "        # Convert single path to list for consistent processing\n",
    "        if isinstance(paths, str):\n",
    "            paths = [paths]\n",
    "\n",
    "        # Save to all specified paths\n",
    "        for path in paths:\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(nodes_json, f)\n",
    "            print(f\"Graph nodes saved to {path}\")\n",
    "\n",
    "        return nodes_json if return_json else None\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_encoding(title: str) -> str:\n",
    "        \"\"\"\n",
    "        Fix the encoding of a string.\n",
    "        Args:\n",
    "            title (str): The input string to fix.\n",
    "        Returns:\n",
    "            str: The fixed string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            decoded_title = title.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            return decoded_title.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except UnicodeEncodeError:\n",
    "            # If the above method fails, return the original title\n",
    "            return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and layout the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Attributes: ['_nx_name', 'doi', 'year', 'title', 'cluster', 'node_id', 'node_name', 'centrality', 'x', 'y', 'z']\n",
      "Edge Attributes: ['edge_id', 'weight']\n",
      "Number of nodes: 37804\n",
      "Number of edges: 112849\n",
      "Starting Fruchterman-Reingold layout process...\n",
      "Layout parameters: {'iterations': 20, 'threshold': 0.0001, 'weight': 'weight', 'scale': 1, 'center': (0, 0), 'dim': 2, 'seed': 1887}\n",
      "Converting to NetworkX Graph...\n",
      "Conversion complete.\n",
      "Graph has 3792 nodes and 10941 edges.\n",
      "Calculating layout...\n",
      "Layout calculation completed in 12.07 seconds.\n",
      "Processing layout results...\n",
      "Layout boundaries:\n",
      "X-axis: Min = -0.99, Max = 1.00\n",
      "Y-axis: Min = -1.00, Max = 0.98\n",
      "Assigning coordinates to nodes...\n",
      "Layout process completed in 12.79 seconds.\n",
      "####################################################################################################\n",
      "Layout done\n",
      "####################################################################################################\n",
      "Bounds of the layout:\n",
      "Min x: -0.990547239780426, Max x: 0.9962700605392456\n",
      "Min y: -1.0, Max y: 0.9798666834831238\n",
      "Description of the Z coordinate values:\n",
      "count    3792.000000\n",
      "mean       -0.101142\n",
      "std         0.047136\n",
      "min        -0.150000\n",
      "25%        -0.135637\n",
      "50%        -0.113908\n",
      "75%        -0.082305\n",
      "max         0.150000\n",
      "dtype: float64\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# g = GraphReader.read_and_clean_graph(INPUT_GRAPH_PATH)\n",
    "g = GraphReader.read_and_clean_graph(\n",
    "    \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/intermediate_graph_bundled_clusters0to100.graphml\"\n",
    ")\n",
    "cluster_list = list(range(39, 50))\n",
    "\n",
    "# subset to only cluster 0 to 100\n",
    "g = GraphReader.subgraph_of_clusters(g, cluster_list)\n",
    "\n",
    "total_nodes = len(g.vs)\n",
    "################################################################################################\n",
    "layout_params = {\n",
    "    # \"k\": 0.5, # distance between nodes; best to leave it to algo\n",
    "    \"iterations\": 20,  # (default=50) use 100\n",
    "    \"threshold\": 0.0001,  # default 0.0001\n",
    "    \"weight\": \"weight\",\n",
    "    \"scale\": 1,\n",
    "    \"center\": (0, 0),\n",
    "    \"dim\": 2,\n",
    "    \"seed\": 1887,\n",
    "}\n",
    "\n",
    "g_fr, pos = LayoutUtility.fr_layout_nx(g, layout_params)\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Layout done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Add z-coordinate to nodes based on centrality\n",
    "z_adder = ZCoordinateAdder(g_fr, scale_factor=0.15)\n",
    "g_z = z_adder.add_z_coordinate_to_nodes()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Z coordinate added to nodes\")\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_edge_count': 10941, 'final_edge_count': 5470, 'initial_isolates': 685, 'final_isolates': 1179}\n",
      "{'initial_edge_count': 10941, 'final_edge_count': 8205, 'initial_isolates': 685, 'final_isolates': 833}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "# prune edges\n",
    "pruning_weight_percentile = 50\n",
    "pruner = PruneEdges()\n",
    "g_pruned_weight = pruner.prune_edges_by_percentile_weight(g, pruning_weight_percentile)\n",
    "summary = pruner.get_prune_summary()\n",
    "print(summary)\n",
    "\n",
    "# random percentage of edges\n",
    "pruning_random_percentile = 50\n",
    "pruner = PruneEdges()\n",
    "g_pruned_random = pruner.keep_random_percentile_of_edges(g, pruning_random_percentile)\n",
    "summary = pruner.get_prune_summary()\n",
    "print(summary)\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates normalized to [0, 1] range.\n",
      "Shape before dropping NaNs: (8205, 10)\n",
      "Shape after cleaning: (8205, 10)\n",
      "Segment length statistics:\n",
      "Min: 0.004206821137500441\n",
      "Max: 0.983849412649517\n",
      "Mean: 0.223738389478224\n",
      "Median: 0.15884537152081998\n"
     ]
    }
   ],
   "source": [
    "# Assume `g` is an igraph.Graph object and you have the utility class imported.\n",
    "edges_df = GraphDataFrameUtility.edges_to_dataframe(g_pruned_random)\n",
    "# Create edge and node DataFrames\n",
    "nodes_df = GraphDataFrameUtility.nodes_to_dataframe(\n",
    "    g_pruned_random, drop_columns=[\"_nx_name\", \"node_name\"]\n",
    ")\n",
    "\n",
    "# Merge edge and node positions\n",
    "all_coords_edge_df = GraphDataFrameUtility.merge_edge_node_positions(edges_df, nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "      <th>node_id</th>\n",
       "      <th>centrality</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>node_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1982</td>\n",
       "      <td>Treatment of intention myoclonus with paroxeti...</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.784951</td>\n",
       "      <td>0.378091</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1111/j.1600-0404.1982.tb04525.x</td>\n",
       "      <td>1982</td>\n",
       "      <td>Treatment of myoclonic syndromes with paroxeti...</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0.053676</td>\n",
       "      <td>0.732362</td>\n",
       "      <td>0.524226</td>\n",
       "      <td>0.053055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  doi  year  \\\n",
       "0                                      1982   \n",
       "1  10.1111/j.1600-0404.1982.tb04525.x  1982   \n",
       "\n",
       "                                               title  cluster  node_id  \\\n",
       "0  Treatment of intention myoclonus with paroxeti...       41        2   \n",
       "1  Treatment of myoclonic syndromes with paroxeti...       41        4   \n",
       "\n",
       "   centrality         x         y         z  node_index  \n",
       "0    0.039863  0.784951  0.378091  0.039233           0  \n",
       "1    0.053676  0.732362  0.524226  0.053055           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.663864</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>0.795334</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id    weight  source  target\n",
       "0        2  0.663864       0       1\n",
       "1       82  0.795334       4      14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_y</th>\n",
       "      <th>source_z</th>\n",
       "      <th>target_x</th>\n",
       "      <th>target_y</th>\n",
       "      <th>target_z</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.663864</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.784951</td>\n",
       "      <td>0.378091</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0.732362</td>\n",
       "      <td>0.524226</td>\n",
       "      <td>0.053055</td>\n",
       "      <td>0.155923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>0.795334</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.495683</td>\n",
       "      <td>0.871647</td>\n",
       "      <td>0.098976</td>\n",
       "      <td>0.475381</td>\n",
       "      <td>0.922010</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>0.084701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id    weight  source  target  source_x  source_y  source_z  target_x  \\\n",
       "0        2  0.663864       1       2  0.784951  0.378091  0.039233  0.732362   \n",
       "1       82  0.795334       4       9  0.495683  0.871647  0.098976  0.475381   \n",
       "\n",
       "   target_y  target_z  segment_length  \n",
       "0  0.524226  0.053055        0.155923  \n",
       "1  0.922010  0.033970        0.084701  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coords_edge_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quick check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3792, 3792)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Nnodes = nodes_df.shape[0]\n",
    "\n",
    "subedges = all_coords_edge_df[\"segment_length\"] > 0.03\n",
    "\n",
    "mat = sparse.coo_matrix(\n",
    "    (\n",
    "        np.ones(all_coords_edge_df.loc[subedges].shape[0], dtype=int),\n",
    "        (\n",
    "            all_coords_edge_df.loc[subedges, \"source\"].values,\n",
    "            all_coords_edge_df.loc[subedges, \"target\"].values,\n",
    "        ),\n",
    "    ),\n",
    "    shape=(Nnodes, Nnodes),\n",
    ")\n",
    "\n",
    "print(mat.shape)\n",
    "\n",
    "ncomp, membership = sparse.csgraph.connected_components(mat)\n",
    "\n",
    "mvalue, mcounts = np.unique(membership, return_counts=True)\n",
    "mcounts, mcountdist = np.unique(mcounts, return_counts=True)\n",
    "\n",
    "mcounts, mcountdist\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "dist, bins = np.histogram(\n",
    "    all_coords_edge_df[\"segment_length\"].values, bins=np.exp(np.linspace(-8, 3, 100))\n",
    ")\n",
    "\n",
    "ax.scatter(np.log(bins[:-1]), dist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUNDLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Threshold for Edge Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges to bundle: 4124\n"
     ]
    }
   ],
   "source": [
    "# get edges to bundle above a certain threshold\n",
    "# threshold = 0.03\n",
    "threshold = 0.15807877788821245\n",
    "edges_to_bundle = all_coords_edge_df[\"segment_length\"] > threshold\n",
    "edges_to_bundle_df = all_coords_edge_df.loc[edges_to_bundle].reset_index(drop=True)\n",
    "print(f\"Edges to bundle: {edges_to_bundle.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Bundling\n",
      "Start Bundling\n"
     ]
    }
   ],
   "source": [
    "bundled_edge_pts = hammer_bundle(\n",
    "    nodes_df[[\"x\", \"y\", \"z\"]],\n",
    "    edges_to_bundle_df[[\"source\", \"target\"]],\n",
    "    initial_bandwidth=0.40,\n",
    "    decay=0.7,\n",
    "    accuracy=5 * 10**2,\n",
    "    weight=None,\n",
    "    advect_iterations=50,\n",
    "    iterations=5,\n",
    "    min_segment_length=0.001,\n",
    "    max_segment_length=0.05,\n",
    ")\n",
    "bundled_edge_pts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Bundling Processing\n",
    "\n",
    "add source and target columns, create clean df and save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bundled edges: 4104\n",
      "Number of straight edges: 4101\n",
      "Number of total edges: 8205\n"
     ]
    }
   ],
   "source": [
    "def createBundledEdgesDf(bundled_edge_pts, edges_to_bundle_df):\n",
    "    sub_bundle_idx = 0\n",
    "    x, y, z = [], [], []\n",
    "    bundled_edges_dict = {}\n",
    "    for i in range(len(bundled_edge_pts)):\n",
    "        # if not nan\n",
    "        if pd.isna(bundled_edge_pts.iloc[i, 0]):\n",
    "            target = edges_to_bundle_df.loc[sub_bundle_idx, \"target\"]\n",
    "            source = edges_to_bundle_df.loc[sub_bundle_idx, \"source\"]\n",
    "            bundled_edges_dict[(source, target)] = {\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"z\": z,\n",
    "            }\n",
    "            sub_bundle_idx += 1\n",
    "            x, y, z = [], [], []\n",
    "        else:\n",
    "            x.append(bundled_edge_pts.iloc[i, 0])\n",
    "            y.append(bundled_edge_pts.iloc[i, 1])\n",
    "            z.append(bundled_edge_pts.iloc[i, 2])\n",
    "\n",
    "    # create df\n",
    "    bundled_edges_df = pd.DataFrame.from_dict(bundled_edges_dict, orient=\"index\")\n",
    "    bundled_edges_df[\"source\"] = [x[0] for x in bundled_edges_df.index]\n",
    "    bundled_edges_df[\"target\"] = [x[1] for x in bundled_edges_df.index]\n",
    "    bundled_edges_df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Number of bundled edges: {bundled_edges_df.shape[0]}\")\n",
    "    return bundled_edges_df\n",
    "\n",
    "\n",
    "def createStraightEdgesDf(all_coords_edge_df, threshold):\n",
    "    straight_edges_mask = all_coords_edge_df[\"segment_length\"] <= threshold\n",
    "\n",
    "    straight_edges_df = all_coords_edge_df.loc[\n",
    "        straight_edges_mask,\n",
    "        [\n",
    "            \"source\",\n",
    "            \"target\",\n",
    "            \"source_x\",\n",
    "            \"source_y\",\n",
    "            \"source_z\",\n",
    "            \"target_x\",\n",
    "            \"target_y\",\n",
    "            \"target_z\",\n",
    "        ],\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    straight_edges_df[\"x\"] = [\n",
    "        [source_x, target_x]\n",
    "        for source_x, target_x in zip(\n",
    "            straight_edges_df[\"source_x\"], straight_edges_df[\"target_x\"]\n",
    "        )\n",
    "    ]\n",
    "    straight_edges_df[\"y\"] = [\n",
    "        [source_y, target_y]\n",
    "        for source_y, target_y in zip(\n",
    "            straight_edges_df[\"source_y\"], straight_edges_df[\"target_y\"]\n",
    "        )\n",
    "    ]\n",
    "    straight_edges_df[\"z\"] = [\n",
    "        [source_z, target_z]\n",
    "        for source_z, target_z in zip(\n",
    "            straight_edges_df[\"source_z\"], straight_edges_df[\"target_z\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Drop coordinate columns\n",
    "    straight_edges_df = straight_edges_df.drop(\n",
    "        columns=[\"source_x\", \"source_y\", \"source_z\", \"target_x\", \"target_y\", \"target_z\"]\n",
    "    )\n",
    "\n",
    "    return straight_edges_df\n",
    "\n",
    "\n",
    "bundled_edges_df = createBundledEdgesDf(bundled_edge_pts, edges_to_bundle_df)\n",
    "straight_edges_df = createStraightEdgesDf(all_coords_edge_df, threshold)\n",
    "\n",
    "print(f\"Number of straight edges: {straight_edges_df.shape[0]}\")\n",
    "# Concatenate bundled and straight edges\n",
    "final_edges_df = pd.concat([bundled_edges_df, straight_edges_df], ignore_index=True)\n",
    "\n",
    "# round to 10 decimal places in x,y,z\n",
    "final_edges_df[\"x\"] = final_edges_df[\"x\"].apply(lambda x: [round(i, 10) for i in x])\n",
    "final_edges_df[\"y\"] = final_edges_df[\"y\"].apply(lambda x: [round(i, 10) for i in x])\n",
    "final_edges_df[\"z\"] = final_edges_df[\"z\"].apply(lambda x: [round(i, 10) for i in x])\n",
    "\n",
    "print(f\"Number of total edges: {final_edges_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 32,\n",
       " 'target': 35,\n",
       " 'color': -1,\n",
       " 'points': [{'x': 0.6645066167, 'y': 0.4120611025, 'z': 0.1709082913},\n",
       "  {'x': 0.6408171884, 'y': 0.4145779769, 'z': 0.1616696211},\n",
       "  {'x': 0.6187730522, 'y': 0.4164484031, 'z': 0.1535411514},\n",
       "  {'x': 0.5994927084, 'y': 0.4175275712, 'z': 0.1470893367},\n",
       "  {'x': 0.583827111, 'y': 0.4181890605, 'z': 0.1425183212},\n",
       "  {'x': 0.5724238437, 'y': 0.4192687586, 'z': 0.1398481202},\n",
       "  {'x': 0.5657010962, 'y': 0.4218395527, 'z': 0.1391053426},\n",
       "  {'x': 0.5637152494, 'y': 0.4268505663, 'z': 0.140426167},\n",
       "  {'x': 0.566022621, 'y': 0.4347335012, 'z': 0.1440541816},\n",
       "  {'x': 0.5716634157, 'y': 0.4451574243, 'z': 0.1502591648},\n",
       "  {'x': 0.5793315832, 'y': 0.4570884499, 'z': 0.1592148923},\n",
       "  {'x': 0.5876821696, 'y': 0.4691537447, 'z': 0.1708846615},\n",
       "  {'x': 0.5956531834, 'y': 0.4801424701, 'z': 0.1849709606},\n",
       "  {'x': 0.6026843036, 'y': 0.48942081, 'z': 0.2009559357},\n",
       "  {'x': 0.60876866, 'y': 0.4971016762, 'z': 0.2181965056},\n",
       "  {'x': 0.6143346344, 'y': 0.5039261756, 'z': 0.2360069614},\n",
       "  {'x': 0.6057933487, 'y': 0.4688542807, 'z': 0.2660907661}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_color_attr(edges_df, nodes_df):\n",
    "    # Add cluster to nr or -1 if not in same cluster\n",
    "    color = []\n",
    "    for source, target in zip(edges_df[\"source\"], edges_df[\"target\"]):\n",
    "        if nodes_df.loc[source, \"cluster\"] == nodes_df.loc[target, \"cluster\"]:\n",
    "            color.append(nodes_df.loc[source, \"cluster\"])\n",
    "        else:\n",
    "            color.append(-1)\n",
    "    edges_df[\"color\"] = color\n",
    "    return edges_df\n",
    "\n",
    "\n",
    "def transform_edges(\n",
    "    edges_df, x_col=\"x\", y_col=\"y\", z_col=\"z\", extra_edge_attributes=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Transform edge data from a DataFrame into a list of dictionaries with points and extra attributes.\n",
    "\n",
    "    Args:\n",
    "    edges_df (pd.DataFrame): DataFrame containing edge data.\n",
    "    x_col (str): Name of the column containing x-coordinates. Default is \"x\".\n",
    "    y_col (str): Name of the column containing y-coordinates. Default is \"y\".\n",
    "    z_col (str): Name of the column containing z-coordinates. Default is \"z\".\n",
    "    extra_edge_attributes (list): List of additional attribute names to include. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each representing an edge with its points and attributes.\n",
    "    \"\"\"\n",
    "    if extra_edge_attributes is None:\n",
    "        extra_edge_attributes = []\n",
    "\n",
    "    def create_edge_object(edge):\n",
    "        return {\n",
    "            **{attr: edge[attr] for attr in extra_edge_attributes if attr in edge},\n",
    "            \"points\": [\n",
    "                {\"x\": float(x), \"y\": float(y), \"z\": float(z)}\n",
    "                for x, y, z in zip(edge[x_col], edge[y_col], edge[z_col])\n",
    "                if not (pd.isna(x) or pd.isna(y) or pd.isna(z))\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    return [create_edge_object(edge) for edge in edges_df.to_dict(orient=\"records\")]\n",
    "\n",
    "\n",
    "edges_df = add_color_attr(final_edges_df, nodes_df)\n",
    "\n",
    "edges_list = transform_edges(\n",
    "    edges_df, extra_edge_attributes=[\"source\", \"target\", \"color\"]\n",
    ")\n",
    "\n",
    "edges_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges data saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/NewBundledEdges.json\n",
      "Edges data saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = (\n",
    "    \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/NewBundledEdges.json\"\n",
    ")\n",
    "with open(OUTPUT_DIR, \"w\") as f:\n",
    "    json.dump(edges_list, f)\n",
    "print(f\"Edges data saved to {OUTPUT_DIR}\")\n",
    "\n",
    "with open(THREEJS_OUTPUT_DIR + \"NewBundledEdges.json\", \"w\") as f:\n",
    "    json.dump(edges_list, f)\n",
    "print(f\"Edges data saved to {THREEJS_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doi', 'year', 'title', 'cluster', 'node_id', 'centrality', 'x', 'y',\n",
       "       'z', 'node_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, Union\n",
    "\n",
    "\n",
    "class NodesSaver:\n",
    "    \"\"\"\n",
    "    A utility class for saving node data from a DataFrame to JSON format, particularly for use in JavaScript applications.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_dataframe_nodes_to_json(\n",
    "        df: pd.DataFrame,\n",
    "        paths: Union[str, List[str]],\n",
    "        return_json: bool = False,\n",
    "        attributes: List[str] = None,\n",
    "    ) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Save the DataFrame nodes to one or more JSON files.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The input DataFrame containing node data.\n",
    "            paths (Union[str, List[str]]): Path or list of paths to save the JSON file(s).\n",
    "            return_json (bool): If True, return the JSON data as well as saving it.\n",
    "            attributes (List[str]): List of node attributes to include in the JSON.\n",
    "\n",
    "        Returns:\n",
    "            Optional[List[Dict]]: List of node dictionaries if return_json is True, else None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If a specified attribute is missing from the DataFrame.\n",
    "        \"\"\"\n",
    "        if attributes is None:\n",
    "            attributes = [\n",
    "                \"node_id\",\n",
    "                \"node_name\",\n",
    "                \"doi\",\n",
    "                \"year\",\n",
    "                \"title\",\n",
    "                \"cluster\",\n",
    "                \"centrality\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "\n",
    "        # Check if all attributes are present in the DataFrame\n",
    "        missing_attributes = [attr for attr in attributes if attr not in df.columns]\n",
    "        if missing_attributes:\n",
    "            raise ValueError(f\"Missing attributes in DataFrame: {missing_attributes}\")\n",
    "\n",
    "        # Fix encoding of titles\n",
    "        df[\"title\"] = df[\"title\"].apply(NodesSaver.fix_encoding)\n",
    "\n",
    "        # Convert DataFrame to list of dictionaries\n",
    "        nodes_json = df[attributes].to_dict(orient=\"records\")\n",
    "\n",
    "        # Convert single path to list for consistent processing\n",
    "        if isinstance(paths, str):\n",
    "            paths = [paths]\n",
    "\n",
    "        # Save to all specified paths\n",
    "        for path in paths:\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(nodes_json, f)\n",
    "            print(f\"Graph nodes saved to {path}\")\n",
    "\n",
    "        return nodes_json if return_json else None\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_encoding(title: str) -> str:\n",
    "        \"\"\"\n",
    "        Fix the encoding of a string.\n",
    "\n",
    "        Args:\n",
    "            title (str): The input string to fix.\n",
    "\n",
    "        Returns:\n",
    "            str: The fixed string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            decoded_title = title.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            return decoded_title.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except UnicodeEncodeError:\n",
    "            # If the above method fails, return the original title\n",
    "            return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes saved to output.json\n",
      "Graph nodes saved to output_backup.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doi': '',\n",
       " 'year': 1982,\n",
       " 'title': 'Treatment of intention myoclonus with paroxetine alone or in combination with L-5-hydroxytryptophan and carbidopa',\n",
       " 'cluster': 41,\n",
       " 'node_id': 2,\n",
       " 'centrality': 0.0398630556438627,\n",
       " 'x': 0.7849507084567265,\n",
       " 'y': 0.37809139375208817,\n",
       " 'z': 0.03923277098436997,\n",
       " 'node_index': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save nodes\n",
    "OUTPUT_DIRA = (\n",
    "    \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/NewNodes.json\"\n",
    ")\n",
    "\n",
    "OUTPUT_DIRB = THREEJS_OUTPUT_DIR + \"NewNodes.json\"\n",
    "\n",
    "saver = NodesSaver()\n",
    "nodes_json = saver.save_dataframe_nodes_to_json(\n",
    "    nodes_df,\n",
    "    paths=[\"output.json\", \"output_backup.json\"],\n",
    "    return_json=True,\n",
    "    attributes=[\n",
    "        \"doi\",\n",
    "        \"year\",\n",
    "        \"title\",\n",
    "        \"cluster\",\n",
    "        \"node_id\",\n",
    "        \"centrality\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"node_index\",\n",
    "    ],\n",
    ")\n",
    "nodes_json[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
