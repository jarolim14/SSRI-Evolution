{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Disable SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Graphs and networks\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "# Scientific computing\n",
    "import math\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_hex, to_rgb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Data visualization and processing\n",
    "import colorcet as cc\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "\n",
    "# from datashader.bundling import hammer_bundle\n",
    "\n",
    "# Performance optimization\n",
    "from numba import jit, prange\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Custom modules\n",
    "from bundling3D import *\n",
    "from fa2_modified import ForceAtlas2\n",
    "\n",
    "# Set Seaborn style for plots\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Constants and configuration\n",
    "INPUT_GRAPH_PATH = \"../data/07-clustered-graphs/alpha0.3_k10_res0.002.graphml\"\n",
    "CLUSTER_INFO_LABEL_TREE = \"../output/cluster-qualifications/ClusterInfoLabelTree.xlsx\"\n",
    "CLUSTER_LABEL_DICT_PATH = \"../data/99-testdata/cluster_label_dict.json\"\n",
    "CLUSTER_TREE_PATH = \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    "OUTPUT_DIR = \"../data/99-testdata/\"\n",
    "THREEJS_OUTPUT_DIR = (\n",
    "    \"/Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/\"\n",
    ")\n",
    "CLUSTER_HIERACHY_FOR_LEGEND_PATH = (\n",
    "    \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    ")\n",
    "\n",
    "FR_GRAPH_FILENAME = \"fr_0to100clusters.graphml\"\n",
    "\n",
    "NODES_DATA_FILENAME = \"NodesData0to100_BundlPerc50_BW0,4.json\"\n",
    "EDGES_DATA_FILENAME = \"EdgesData0to100_BundlPerc50_BW0,4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataFrameUtility:\n",
    "    \"\"\"\n",
    "    A utility class for converting igraph graph attributes to pandas DataFrames\n",
    "    and performing DataFrame operations related to graph data.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def minmax_normalize(\n",
    "        data: Union[List[float], np.ndarray], new_range: Tuple[float, float] = (0, 1)\n",
    "    ) -> np.ndarray:\n",
    "        data = np.array(data)\n",
    "        if len(data) == 0:\n",
    "            raise ValueError(\"Input data is empty\")\n",
    "\n",
    "        data_min, data_max = np.min(data), np.max(data)\n",
    "        if data_min == data_max:\n",
    "            raise ValueError(\"All values in the input data are identical\")\n",
    "\n",
    "        normalized_data = (data - data_min) / (data_max - data_min)\n",
    "\n",
    "        if new_range != (0, 1):\n",
    "            new_min, new_max = new_range\n",
    "            normalized_data = normalized_data * (new_max - new_min) + new_min\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def minmax_denormalize(\n",
    "        normalized_data: Union[List[float], np.ndarray],\n",
    "        original_range: Tuple[float, float],\n",
    "        current_range: Tuple[float, float] = (0, 1),\n",
    "    ) -> np.ndarray:\n",
    "\n",
    "        normalized_data = np.array(normalized_data)\n",
    "        if len(normalized_data) == 0:\n",
    "            raise ValueError(\"Input data is empty\")\n",
    "\n",
    "        orig_min, orig_max = original_range\n",
    "        curr_min, curr_max = current_range\n",
    "\n",
    "        if orig_min >= orig_max or curr_min >= curr_max:\n",
    "            raise ValueError(\"Invalid range: min should be less than max\")\n",
    "\n",
    "        # First, normalize to [0, 1] if not already\n",
    "        if current_range != (0, 1):\n",
    "            normalized_data = (normalized_data - curr_min) / (curr_max - curr_min)\n",
    "\n",
    "        # Then, scale to original range\n",
    "        denormalized_data = normalized_data * (orig_max - orig_min) + orig_min\n",
    "\n",
    "        return denormalized_data\n",
    "\n",
    "    @staticmethod\n",
    "    def edges_to_dataframe(g: ig.Graph) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the edges and their attributes of an igraph graph to a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input igraph graph.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing edge attributes, source, and target nodes.\n",
    "        \"\"\"\n",
    "        # check if networkx or igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        # Extract edge attributes\n",
    "        edge_data = {attr: g.es[attr] for attr in g.es.attributes()}\n",
    "\n",
    "        # Add source and target node indices\n",
    "        edge_data[\"source\"] = [e.source for e in g.es]\n",
    "        edge_data[\"target\"] = [e.target for e in g.es]\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        edge_dataframe = pd.DataFrame(edge_data)\n",
    "\n",
    "        return edge_dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def nodes_to_dataframe(\n",
    "        g: ig.Graph,\n",
    "        normalize_coordinates: bool = False,\n",
    "        drop_columns: Optional[List[str]] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the nodes and their attributes of an igraph graph to a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input igraph graph.\n",
    "            drop_columns (Optional[List[str]]): A list of column names to drop from the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing node attributes and node indices.\n",
    "        \"\"\"\n",
    "        # check if networkx or igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        # Extract node attributes\n",
    "        node_data = {attr: g.vs[attr] for attr in g.vs.attributes()}\n",
    "\n",
    "        # Add node indices\n",
    "        node_dataframe = pd.DataFrame(node_data)\n",
    "        node_dataframe[\"node_index\"] = [n.index for n in g.vs]\n",
    "        if normalize_coordinates:\n",
    "            # Calculate min/max for coordinates\n",
    "            xmin, xmax = np.min(node_dataframe[\"x\"]), np.max(node_dataframe[\"x\"])\n",
    "            ymin, ymax = np.min(node_dataframe[\"y\"]), np.max(node_dataframe[\"y\"])\n",
    "            zmin, zmax = np.min(node_dataframe[\"z\"]), np.max(node_dataframe[\"z\"])\n",
    "\n",
    "            # Normalize coordinates\n",
    "            node_dataframe[\"x\"] = minmax_normalize(node_dataframe[\"x\"], xmin, xmax)\n",
    "            node_dataframe[\"y\"] = minmax_normalize(node_dataframe[\"y\"], ymin, ymax)\n",
    "            node_dataframe[\"z\"] = minmax_normalize(node_dataframe[\"z\"], zmin, zmax)\n",
    "            print(\"Coordinates normalized to [0, 1] range.\")\n",
    "\n",
    "        # Drop specified columns if provided\n",
    "        if drop_columns:\n",
    "            node_dataframe = node_dataframe.drop(columns=drop_columns, errors=\"ignore\")\n",
    "\n",
    "        return node_dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def create_edge_df_with_source_target_coords(g: ig.Graph) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a DataFrame containing edge information with source and target coordinates.\n",
    "\n",
    "        This method processes an igraph Graph object and extracts edge information,\n",
    "        including weights, IDs, source and target nodes, and their coordinates.\n",
    "        It also calculates the length of each edge segment.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        g : ig.Graph\n",
    "            The input graph object from which to extract edge information.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            A DataFrame containing the following columns:\n",
    "            - weight: Edge weight\n",
    "            - edge_id: Unique identifier for each edge\n",
    "            - source: Source node ID\n",
    "            - target: Target node ID\n",
    "            - source_x, source_y, source_z: Coordinates of the source node\n",
    "            - target_x, target_y, target_z: Coordinates of the target node\n",
    "            - segment_length: Euclidean distance between source and target nodes\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        - Assumes the graph nodes have 'x', 'y', and 'z' attributes for coordinates.\n",
    "        - Prints statistics about segment lengths after creating the DataFrame.\n",
    "        \"\"\"\n",
    "        edge_data = []\n",
    "        for edge in g.es:\n",
    "            source = edge.source\n",
    "            target = edge.target\n",
    "            source_coords = (g.vs[source][\"x\"], g.vs[source][\"y\"], g.vs[source][\"z\"])\n",
    "            target_coords = (g.vs[target][\"x\"], g.vs[target][\"y\"], g.vs[target][\"z\"])\n",
    "\n",
    "            edge_data.append(\n",
    "                {\n",
    "                    \"weight\": edge[\"weight\"],\n",
    "                    \"edge_id\": edge[\"edge_id\"],\n",
    "                    \"source\": source,\n",
    "                    \"target\": target,\n",
    "                    \"source_x\": source_coords[0],\n",
    "                    \"source_y\": source_coords[1],\n",
    "                    \"source_z\": source_coords[2],\n",
    "                    \"target_x\": target_coords[0],\n",
    "                    \"target_y\": target_coords[1],\n",
    "                    \"target_z\": target_coords[2],\n",
    "                    \"segment_length\": GraphDataFrameUtility.distance_between(\n",
    "                        source_coords, target_coords\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df = pd.DataFrame(edge_data)\n",
    "\n",
    "        # Print segment length statistics\n",
    "        print(\"Segment length statistics:\")\n",
    "        print(f\"Min: {df['segment_length'].min():.2f}\")\n",
    "        print(f\"Max: {df['segment_length'].max():.2f}\")\n",
    "        print(f\"Mean: {df['segment_length'].mean():.2f}\")\n",
    "        print(f\"Median: {df['segment_length'].median():.2f}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def distance_between(\n",
    "        point1: Tuple[float, float, float], point2: Tuple[float, float, float]\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate the Euclidean distance between two 3D points.\"\"\"\n",
    "        return np.sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(point1, point2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphReader:\n",
    "    @staticmethod\n",
    "    def read_and_clean_graph(path: str) -> ig.Graph:\n",
    "        g = ig.Graph.Read_GraphML(path)\n",
    "        g.vs[\"node_id\"] = [int(i) for i in range(g.vcount())]\n",
    "\n",
    "        if \"id\" in g.vs.attribute_names():\n",
    "            g.vs[\"node_name\"] = g.vs[\"id\"]\n",
    "            del g.vs[\"id\"]\n",
    "\n",
    "        if \"cluster\" in g.vs.attribute_names():\n",
    "            g.vs[\"cluster\"] = [int(cluster) for cluster in g.vs[\"cluster\"]]\n",
    "\n",
    "        if \"year\" in g.vs.attribute_names():\n",
    "            g.vs[\"year\"] = [int(year) for year in g.vs[\"year\"]]\n",
    "\n",
    "        if \"eid\" in g.vs.attribute_names():\n",
    "            del g.vs[\"eid\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.006\" in g.vs.attribute_names():\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.006\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.002\" in g.vs.attribute_names():\n",
    "            g.vs[\"centrality\"] = g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "\n",
    "        g.es[\"edge_id\"] = list(range(g.ecount()))\n",
    "        print(\"Node Attributes:\", g.vs.attribute_names())\n",
    "        print(\"Edge Attributes:\", g.es.attribute_names())\n",
    "        # print number of nodes and edges\n",
    "        print(f\"Number of nodes: {g.vcount()}\")\n",
    "        print(f\"Number of edges: {g.ecount()}\")\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def subgraph_of_clusters(G, clusters):\n",
    "        if isinstance(G, nx.Graph):\n",
    "            nodes = [\n",
    "                node for node in G.nodes if G.nodes[node].get(\"cluster\") in clusters\n",
    "            ]\n",
    "            return G.subgraph(nodes)\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            nodes = [v.index for v in G.vs if v[\"cluster\"] in clusters]\n",
    "            return G.subgraph(nodes)\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "    @staticmethod\n",
    "    def add_cluster_labels(\n",
    "        G: Union[nx.Graph, ig.Graph],\n",
    "        labels_file_path: str = \"../output/cluster-qualifications/raw_cluster_labels.json\",\n",
    "    ) -> Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "        \"\"\"\n",
    "        Add cluster labels to the graph nodes.\n",
    "\n",
    "        Args:\n",
    "            G (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "            labels_file_path (str): Path to the JSON file containing cluster labels.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "                The graph with added cluster labels and the cluster label dictionary.\n",
    "        \"\"\"\n",
    "        with open(labels_file_path) as file:\n",
    "            cluster_label_dict = json.load(file)\n",
    "        cluster_label_dict = {float(k): v[0] for k, v in cluster_label_dict.items()}\n",
    "\n",
    "        if isinstance(G, nx.Graph):\n",
    "            for node in G.nodes:\n",
    "                cluster = G.nodes[node][\"cluster\"]\n",
    "                G.nodes[node][\"cluster_label\"] = cluster_label_dict.get(\n",
    "                    cluster, \"Unknown\"\n",
    "                )\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            G.vs[\"cluster_label\"] = [\n",
    "                cluster_label_dict.get(v[\"cluster\"], \"Unknown\") for v in G.vs\n",
    "            ]\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "        return G, cluster_label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout Utilities (Fruchterman-Reingold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutUtility:\n",
    "    \"\"\"\n",
    "    Layout utility class for igraph layout operations. made for fruchterman-reingold layout.\n",
    "\n",
    "    Args:\n",
    "        g (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "        layout_params (Optional[Dict]): The layout parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[nx.Graph, Dict]: The graph with assigned coordinates and the layout dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fr_layout_nx(\n",
    "        g: Union[nx.Graph, ig.Graph], layout_params: Optional[Dict] = None\n",
    "    ) -> Tuple[nx.Graph, Dict]:\n",
    "        print(\"Starting Fruchterman-Reingold layout process...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if layout_params is None:\n",
    "            layout_params = {\n",
    "                \"iterations\": 100,\n",
    "                \"threshold\": 0.00001,\n",
    "                \"weight\": \"weight\",\n",
    "                \"scale\": 1,\n",
    "                \"center\": (0, 0),\n",
    "                \"dim\": 2,\n",
    "                \"seed\": 1887,\n",
    "            }\n",
    "        print(f\"Layout parameters: {layout_params}\")\n",
    "\n",
    "        if not isinstance(g, nx.Graph):\n",
    "            print(\"Converting to NetworkX Graph...\")\n",
    "            G = g.to_networkx()\n",
    "            print(\"Conversion complete.\")\n",
    "        else:\n",
    "            G = g\n",
    "\n",
    "        print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "        print(\"Calculating layout...\")\n",
    "        layout_start_time = time.time()\n",
    "        pos = nx.spring_layout(G, **layout_params)\n",
    "        layout_end_time = time.time()\n",
    "        print(\n",
    "            f\"Layout calculation completed in {layout_end_time - layout_start_time:.2f} seconds.\"\n",
    "        )\n",
    "\n",
    "        print(\"Processing layout results...\")\n",
    "        node_xy_dict = {node: pos[node] for node in G.nodes}\n",
    "\n",
    "        x_values, y_values = zip(*node_xy_dict.values())\n",
    "        min_x, max_x = min(x_values), max(x_values)\n",
    "        min_y, max_y = min(y_values), max(y_values)\n",
    "\n",
    "        print(f\"Layout boundaries:\")\n",
    "        print(f\"X-axis: Min = {min_x:.2f}, Max = {max_x:.2f}\")\n",
    "        print(f\"Y-axis: Min = {min_y:.2f}, Max = {max_y:.2f}\")\n",
    "\n",
    "        print(\"Assigning coordinates to nodes...\")\n",
    "        for node in G.nodes:\n",
    "            G.nodes[node][\"x\"] = node_xy_dict[node][0]\n",
    "            G.nodes[node][\"y\"] = node_xy_dict[node][1]\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Layout process completed in {total_time:.2f} seconds.\")\n",
    "\n",
    "        return G, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add z coordinates to the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZCoordinateAdder:\n",
    "    \"\"\"\n",
    "    A class for adding a z-coordinate to the nodes of a graph based on their centrality values.\n",
    "    The z-coordinate range is determined by a percentage of the x-y dimension range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, g, percentage=50):\n",
    "        self.g = g\n",
    "        self.percentage = percentage / 100  # Convert percentage to decimal\n",
    "\n",
    "    def add_z_coordinate_to_nodes(self):\n",
    "        \"\"\"\n",
    "        Add a z-coordinate to the nodes of the graph based on their centrality values.\n",
    "        Args:\n",
    "            g (nx.Graph): The input graph.\n",
    "            percentage (float): The percentage of x-y dimension range to use for z-coordinate range.\n",
    "        Returns:\n",
    "            nx.Graph: The graph with the z-coordinate added to the nodes.\n",
    "        \"\"\"\n",
    "        # Calculate the bounds of x and y coordinates\n",
    "        xvalues = [attributes[\"x\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        yvalues = [attributes[\"y\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        min_x, max_x = min(xvalues), max(xvalues)\n",
    "        min_y, max_y = min(yvalues), max(yvalues)\n",
    "\n",
    "        # Calculate the range of x and y\n",
    "        x_range = max_x - min_x\n",
    "        y_range = max_y - min_y\n",
    "\n",
    "        # Calculate the maximum z range based on the larger of x or y range\n",
    "        max_z_range = max(x_range, y_range) * self.percentage\n",
    "\n",
    "        print(\"Bounds of the layout:\")\n",
    "        print(f\"Min x: {min_x}, Max x: {max_x}\")\n",
    "        print(f\"Min y: {min_y}, Max y: {max_y}\")\n",
    "        print(f\"Z coordinate range: 0 to {max_z_range}\")\n",
    "\n",
    "        # Extract centrality values from nodes\n",
    "        centralities = np.array(\n",
    "            [self.g.nodes[node][\"centrality\"] for node in self.g.nodes]\n",
    "        )\n",
    "\n",
    "        # Normalize centrality values to range [0, 1]\n",
    "        centrality_min = centralities.min()\n",
    "        centrality_max = centralities.max()\n",
    "        centralities_normalized = (centralities - centrality_min) / (\n",
    "            centrality_max - centrality_min\n",
    "        )\n",
    "\n",
    "        # Scale the normalized centralities to the desired z range\n",
    "        z_coordinates = centralities_normalized * max_z_range\n",
    "\n",
    "        # Add z-coordinate to nodes\n",
    "        for i, node in enumerate(self.g.nodes):\n",
    "            self.g.nodes[node][\"z\"] = z_coordinates[i]\n",
    "\n",
    "        # Describe the distribution of z values\n",
    "        print(\"Description of the Z coordinate values:\")\n",
    "        print(pd.Series(z_coordinates).describe())\n",
    "        print(\"Z coordinate added to nodes\")\n",
    "\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class PruneEdges:\n",
    "    \"\"\"\n",
    "    A class for pruning edges in a graph based on specific criteria, such as edge weight percentiles or random selection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initial_edge_count = 0\n",
    "        self.initial_isolates = 0\n",
    "        self.final_edge_count = 0\n",
    "        self.final_isolates = 0\n",
    "\n",
    "    def _update_statistics(self, g: ig.Graph, g_modified: ig.Graph) -> None:\n",
    "        \"\"\"\n",
    "        Update class attributes related to graph statistics.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The original graph.\n",
    "            g_modified (ig.Graph): The modified graph after pruning or random selection.\n",
    "        \"\"\"\n",
    "        # if nx object, convert to igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        self.initial_edge_count = g.ecount()\n",
    "        self.initial_isolates = len(g.vs.select(_degree=0))\n",
    "        self.final_edge_count = g_modified.ecount()\n",
    "        self.final_isolates = len(g_modified.vs.select(_degree=0))\n",
    "\n",
    "    def prune_edges_by_percentile_weight(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Remove edges from the graph that have weight less than or equal to the specified percentile weight.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph. Must have a 'weight' attribute for edges.\n",
    "            percentile (float): The percentile to use as the threshold for pruning edges.\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with edges removed based on the specified percentile.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input graph has no 'weight' attribute for edges.\n",
    "            ValueError: If percentile is not between 0 and 100.\n",
    "        \"\"\"\n",
    "        # if nx object, convert to igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        if not (0 <= percentile <= 100):\n",
    "            raise ValueError(\"Percentile must be between 0 and 100.\")\n",
    "\n",
    "        if \"weight\" not in g.es.attributes():\n",
    "            raise ValueError(\"Input graph must have a 'weight' attribute for edges.\")\n",
    "\n",
    "        # Get all weights and calculate the specified percentile\n",
    "        weights = g.es[\"weight\"]\n",
    "        weight_threshold = np.percentile(weights, percentile)\n",
    "\n",
    "        # Identify edges to keep\n",
    "        edges_to_keep = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] > weight_threshold\n",
    "        ]\n",
    "        threshold_edges = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] == weight_threshold\n",
    "        ]\n",
    "\n",
    "        # Randomly select from threshold edges to reach target number of edges\n",
    "        target_edge_count = int(self.initial_edge_count * (1 - percentile / 100))\n",
    "        edges_to_add = target_edge_count - len(edges_to_keep)\n",
    "        if edges_to_add > 0:\n",
    "            random.shuffle(threshold_edges)\n",
    "            edges_to_keep.extend(threshold_edges[:edges_to_add])\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_pruned = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Update statistics\n",
    "        self._update_statistics(g, g_pruned)\n",
    "\n",
    "        return g_pruned\n",
    "\n",
    "    def keep_random_percentile_of_edges(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Keep a random selection of edges based on the provided percentile.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph.\n",
    "            percentile (float): The percentile of edges to keep (0-100).\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with the randomly selected edges.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If percentile is not between 0 and 100.\n",
    "        \"\"\"\n",
    "        # if nx object, convert to igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        if not (0 <= percentile <= 100):\n",
    "            raise ValueError(\"percentile must be between 0 and 100.\")\n",
    "\n",
    "        # Calculate the number of edges to keep\n",
    "        total_edges = g.ecount()\n",
    "        num_edges_to_keep = int(total_edges * (percentile / 100))\n",
    "\n",
    "        # Randomly select edges to keep\n",
    "        all_edges = list(range(total_edges))\n",
    "        random.shuffle(all_edges)\n",
    "        edges_to_keep = all_edges[:num_edges_to_keep]\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_random = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Update statistics\n",
    "        self._update_statistics(g, g_random)\n",
    "\n",
    "        return g_random\n",
    "\n",
    "    def get_prune_summary(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Returns a summary of the pruning process.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, int]: A dictionary containing the initial and final edge counts and the number of isolates.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"initial_edge_count\": self.initial_edge_count,\n",
    "            \"final_edge_count\": self.final_edge_count,\n",
    "            \"initial_isolates\": self.initial_isolates,\n",
    "            \"final_isolates\": self.final_isolates,\n",
    "        }\n",
    "\n",
    "\n",
    "# example usage\n",
    "# g = ... # your graph object\n",
    "# pruner = PruneEdges()\n",
    "# g_pruned = pruner.prune_edges_by_percentile_weight(g, 10)\n",
    "# summary = pruner.get_prune_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes Saver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and layout the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/zjbwrdgj0bg9zyhx3l7134mm0000gn/T/ipykernel_39661/1447177093.py:4: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute. at src/io/graphml.c:488\n",
      "  g = ig.Graph.Read_GraphML(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Attributes: ['doi', 'year', 'title', 'cluster', 'node_id', 'node_name', 'centrality']\n",
      "Edge Attributes: ['weight', 'edge_id']\n",
      "Number of nodes: 40643\n",
      "Number of edges: 602779\n",
      "Starting Fruchterman-Reingold layout process...\n",
      "Layout parameters: {'iterations': 50, 'threshold': 0.0001, 'weight': 'weight', 'scale': 5000, 'center': (0, 0), 'dim': 2, 'seed': 1887}\n",
      "Converting to NetworkX Graph...\n",
      "Conversion complete.\n",
      "Graph has 37804 nodes and 564246 edges.\n",
      "Calculating layout...\n",
      "Layout calculation completed in 1931.34 seconds.\n",
      "Processing layout results...\n",
      "Layout boundaries:\n",
      "X-axis: Min = -5000.00, Max = 3732.82\n",
      "Y-axis: Min = -3769.51, Max = 3854.39\n",
      "Assigning coordinates to nodes...\n",
      "Layout process completed in 1933.11 seconds.\n",
      "####################################################################################################\n",
      "Layout done\n",
      "####################################################################################################\n",
      "Bounds of the layout:\n",
      "Min x: -5000.0, Max x: 3732.816162109375\n",
      "Min y: -3769.513427734375, Max y: 3854.394287109375\n",
      "Z coordinate range: 0 to 1746.563232421875\n",
      "Description of the Z coordinate values:\n",
      "count    37804.000000\n",
      "mean       265.433894\n",
      "std        274.004050\n",
      "min          0.000000\n",
      "25%         76.839088\n",
      "50%        179.341355\n",
      "75%        357.205859\n",
      "max       1746.563232\n",
      "dtype: float64\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# g = GraphReader.read_and_clean_graph(INPUT_GRAPH_PATH)\n",
    "g = GraphReader.read_and_clean_graph(\n",
    "    \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/07-clustered-graphs/alpha0.3_k10_res0.002.graphml\"\n",
    ")\n",
    "cluster_list = list(range(0, 101))\n",
    "\n",
    "# subset to only cluster 0 to 100\n",
    "g = GraphReader.subgraph_of_clusters(g, cluster_list)\n",
    "\n",
    "total_nodes = len(g.vs)\n",
    "################################################################################################\n",
    "layout_params = {\n",
    "    # \"k\": 0.5, # distance between nodes; best to leave it to algo\n",
    "    \"iterations\": 50,  # (default=50) use 100\n",
    "    \"threshold\": 0.0001,  # default 0.0001\n",
    "    \"weight\": \"weight\",\n",
    "    \"scale\": 5000,\n",
    "    \"center\": (0, 0),\n",
    "    \"dim\": 2,\n",
    "    \"seed\": 1887,\n",
    "}\n",
    "\n",
    "g_fr, pos = LayoutUtility.fr_layout_nx(g, layout_params)\n",
    "\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Layout done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Add z-coordinate to nodes based on centrality\n",
    "z_adder = ZCoordinateAdder(g_fr, percentage=20)\n",
    "g_z = z_adder.add_z_coordinate_to_nodes()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Z coordinate added to nodes\")\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved as GraphML: /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/fr_0to100clusters.graphml\n"
     ]
    }
   ],
   "source": [
    "# Assuming g_z is your NetworkX graph object\n",
    "\n",
    "path = \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/\"\n",
    "full_path = path + FR_GRAPH_FILENAME\n",
    "\n",
    "# Save as GraphML file\n",
    "# nx.write_graphml(g_z, full_path)\n",
    "\n",
    "print(f\"Graph saved as GraphML: {full_path}\")\n",
    "\n",
    "\n",
    "# read back in\n",
    "g_z = nx.read_graphml(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_edge_count': 564246, 'final_edge_count': 267167, 'initial_isolates': 0, 'final_isolates': 0}\n",
      "{'initial_edge_count': 564246, 'final_edge_count': 141061, 'initial_isolates': 0, 'final_isolates': 425}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "# prune edges\n",
    "pruning_weight_percentile = 25\n",
    "pruner = PruneEdges()\n",
    "g_pruned_weight = pruner.prune_edges_by_percentile_weight(\n",
    "    g_z, pruning_weight_percentile\n",
    ")\n",
    "summary = pruner.get_prune_summary()\n",
    "print(summary)\n",
    "\n",
    "# random percentage of edges\n",
    "pruning_random_percentile = 25\n",
    "pruner = PruneEdges()\n",
    "g_pruned_random = pruner.keep_random_percentile_of_edges(g_z, pruning_random_percentile)\n",
    "summary = pruner.get_prune_summary()\n",
    "print(summary)\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment length statistics:\n",
      "Min: 0.00\n",
      "Max: 4021.77\n",
      "Mean: 844.71\n",
      "Median: 752.23\n"
     ]
    }
   ],
   "source": [
    "# Assume `g` is an igraph.Graph object and you have the utility class imported.\n",
    "edges_df = GraphDataFrameUtility.edges_to_dataframe(g_pruned_random)\n",
    "# Create edge and node DataFrames\n",
    "nodes_df = GraphDataFrameUtility.nodes_to_dataframe(\n",
    "    g_pruned_random, normalize_coordinates=False, drop_columns=[\"node_id\", \"node_name\"]\n",
    ")\n",
    "\n",
    "# Merge edge and node positions\n",
    "edge_df_with_source_target_coords = (\n",
    "    GraphDataFrameUtility.create_edge_df_with_source_target_coords(g_pruned_random)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10th_percentile': 304.129170530789,\n",
       " '25th_percentile': 480.03024806059074,\n",
       " '50th_percentile': 752.2250815491802,\n",
       " '75th_percentile': 1111.2734952635042}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dictionary of segment length, 25th, 50th, 75th percentile\n",
    "segment_length_dict = {\n",
    "    \"10th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].quantile(\n",
    "        0.10\n",
    "    ),\n",
    "    \"25th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].quantile(\n",
    "        0.25\n",
    "    ),\n",
    "    \"50th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].median(),\n",
    "    \"75th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].quantile(\n",
    "        0.75\n",
    "    ),\n",
    "}\n",
    "segment_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quick check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37804, 37804)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_edge_df_with_source_target_coords = edge_df_with_source_target_coords.copy()\n",
    "to_normalize = [\n",
    "    \"source_x\",\n",
    "    \"source_y\",\n",
    "    \"source_z\",\n",
    "    \"target_x\",\n",
    "    \"target_y\",\n",
    "    \"target_z\",\n",
    "    \"segment_length\",\n",
    "]\n",
    "for col in to_normalize:\n",
    "    normalized_edge_df_with_source_target_coords[col] = (\n",
    "        GraphDataFrameUtility.minmax_normalize(\n",
    "            normalized_edge_df_with_source_target_coords[col]\n",
    "        )\n",
    "    )\n",
    "\n",
    "Nnodes = nodes_df.shape[0]\n",
    "\n",
    "subedges = (\n",
    "    normalized_edge_df_with_source_target_coords[\"segment_length\"]\n",
    "    > normalized_edge_df_with_source_target_coords[\"segment_length\"].median()\n",
    ")\n",
    "\n",
    "mat = sparse.coo_matrix(\n",
    "    (\n",
    "        np.ones(\n",
    "            normalized_edge_df_with_source_target_coords.loc[subedges].shape[0],\n",
    "            dtype=int,\n",
    "        ),\n",
    "        (\n",
    "            normalized_edge_df_with_source_target_coords.loc[subedges, \"source\"].values,\n",
    "            normalized_edge_df_with_source_target_coords.loc[subedges, \"target\"].values,\n",
    "        ),\n",
    "    ),\n",
    "    shape=(Nnodes, Nnodes),\n",
    ")\n",
    "\n",
    "print(mat.shape)\n",
    "\n",
    "ncomp, membership = sparse.csgraph.connected_components(mat)\n",
    "\n",
    "mvalue, mcounts = np.unique(membership, return_counts=True)\n",
    "mcounts, mcountdist = np.unique(mcounts, return_counts=True)\n",
    "\n",
    "# mcounts, mcountdist\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "dist, bins = np.histogram(\n",
    "    normalized_edge_df_with_source_target_coords[\"segment_length\"].values,\n",
    "    bins=np.exp(np.linspace(-8, 3, 100)),\n",
    ")\n",
    "\n",
    "ax.scatter(np.log(bins[:-1]), dist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUNDLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Threshold for Edge Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nr of Pruned Edges: 141061\n",
      "Edges to Bundle: 70530\n"
     ]
    }
   ],
   "source": [
    "# get edges to bundle above a certain threshold\n",
    "# threshold = 0.03\n",
    "threshold = segment_length_dict[\"50th_percentile\"]\n",
    "edges_to_bundle = edge_df_with_source_target_coords[\"segment_length\"] > threshold\n",
    "edges_to_bundle_df = edge_df_with_source_target_coords.loc[edges_to_bundle].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "print(f\"Total Nr of Pruned Edges: {len(edge_df_with_source_target_coords)}\")\n",
    "print(f\"Edges to Bundle: {edges_to_bundle.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09351909553512086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_edge_df_with_source_target_coords[\"segment_length\"].median() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.025 / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Bundling\n",
      "Start Bundling\n"
     ]
    }
   ],
   "source": [
    "bundled_edge_pts = hammer_bundle(\n",
    "    nodes_df[[\"x\", \"y\", \"z\"]],\n",
    "    edges_to_bundle_df[[\"source\", \"target\"]],\n",
    "    initial_bandwidth=0.10,  # 0.01,\n",
    "    decay=0.7,  # 0.8,\n",
    "    tension=0.5,  # 0.8,\n",
    "    accuracy=5 * 10**2,\n",
    "    weight=None,\n",
    "    advect_iterations=50,\n",
    "    iterations=5,\n",
    "    min_segment_length=0.01,\n",
    "    max_segment_length=0.05,\n",
    ")\n",
    "bundled_edge_pts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Bundling Processing\n",
    "\n",
    "add source and target columns, create clean df and save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bundled edges: 70530\n",
      "Number of total edges: 141061\n",
      "Number of straight edges: 70531\n"
     ]
    }
   ],
   "source": [
    "class EdgeProcessor:\n",
    "    \"\"\"\n",
    "    A class to process edge data for graph visualization.\n",
    "\n",
    "    This class handles the creation of bundled and straight edges from input dataframes,\n",
    "    concatenates the results, and cleans the edge attributes for further analysis or visualization.\n",
    "\n",
    "    Attributes:\n",
    "    bundled_edge_pts (pd.DataFrame): DataFrame containing points for bundled edges.\n",
    "    edges_to_bundle_df (pd.DataFrame): DataFrame mapping edges to their source and target nodes.\n",
    "    edge_df_with_source_target_coords (pd.DataFrame): DataFrame containing all edge coordinates and their lengths.\n",
    "    threshold (float): Length threshold to determine which edges are considered straight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bundled_edge_pts,\n",
    "        edges_to_bundle_df,\n",
    "        edge_df_with_source_target_coords,\n",
    "        threshold,\n",
    "    ):\n",
    "        self.bundled_edge_pts = bundled_edge_pts\n",
    "        self.edges_to_bundle_df = edges_to_bundle_df\n",
    "        self.edge_df_with_source_target_coords = edge_df_with_source_target_coords\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def create_bundled_edges_df(self):\n",
    "        sub_bundle_idx = 0\n",
    "        x, y, z = [], [], []\n",
    "        bundled_edges_dict = {}\n",
    "\n",
    "        for i in range(len(self.bundled_edge_pts)):\n",
    "            # if not nan\n",
    "            if pd.isna(self.bundled_edge_pts.iloc[i, 0]):\n",
    "                target = self.edges_to_bundle_df.loc[sub_bundle_idx, \"target\"]\n",
    "                source = self.edges_to_bundle_df.loc[sub_bundle_idx, \"source\"]\n",
    "                bundled_edges_dict[(source, target)] = {\n",
    "                    \"x\": x,\n",
    "                    \"y\": y,\n",
    "                    \"z\": z,\n",
    "                }\n",
    "                sub_bundle_idx += 1\n",
    "                x, y, z = [], [], []\n",
    "            else:\n",
    "                x.append(self.bundled_edge_pts.iloc[i, 0])\n",
    "                y.append(self.bundled_edge_pts.iloc[i, 1])\n",
    "                z.append(self.bundled_edge_pts.iloc[i, 2])\n",
    "\n",
    "        # Create DataFrame\n",
    "        bundled_edges_df = pd.DataFrame.from_dict(bundled_edges_dict, orient=\"index\")\n",
    "        bundled_edges_df[\"source\"] = [x[0] for x in bundled_edges_df.index]\n",
    "        bundled_edges_df[\"target\"] = [x[1] for x in bundled_edges_df.index]\n",
    "        bundled_edges_df.reset_index(drop=True, inplace=True)\n",
    "        print(f\"Number of bundled edges: {bundled_edges_df.shape[0]}\")\n",
    "        return bundled_edges_df\n",
    "\n",
    "    def create_straight_edges_df(self):\n",
    "        straight_edges_mask = (\n",
    "            self.edge_df_with_source_target_coords[\"segment_length\"] <= self.threshold\n",
    "        )\n",
    "\n",
    "        straight_edges_df = self.edge_df_with_source_target_coords.loc[\n",
    "            straight_edges_mask,\n",
    "            [\n",
    "                \"source\",\n",
    "                \"target\",\n",
    "                \"source_x\",\n",
    "                \"source_y\",\n",
    "                \"source_z\",\n",
    "                \"target_x\",\n",
    "                \"target_y\",\n",
    "                \"target_z\",\n",
    "            ],\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "        straight_edges_df[\"x\"] = [\n",
    "            [source_x, target_x]\n",
    "            for source_x, target_x in zip(\n",
    "                straight_edges_df[\"source_x\"], straight_edges_df[\"target_x\"]\n",
    "            )\n",
    "        ]\n",
    "        straight_edges_df[\"y\"] = [\n",
    "            [source_y, target_y]\n",
    "            for source_y, target_y in zip(\n",
    "                straight_edges_df[\"source_y\"], straight_edges_df[\"target_y\"]\n",
    "            )\n",
    "        ]\n",
    "        straight_edges_df[\"z\"] = [\n",
    "            [source_z, target_z]\n",
    "            for source_z, target_z in zip(\n",
    "                straight_edges_df[\"source_z\"], straight_edges_df[\"target_z\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Drop coordinate columns\n",
    "        straight_edges_df = straight_edges_df.drop(\n",
    "            columns=[\n",
    "                \"source_x\",\n",
    "                \"source_y\",\n",
    "                \"source_z\",\n",
    "                \"target_x\",\n",
    "                \"target_y\",\n",
    "                \"target_z\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return straight_edges_df\n",
    "\n",
    "    def concat_and_clean_edges(self, bundled_edges_df, straight_edges_df):\n",
    "        # Concatenate bundled and straight edges\n",
    "        final_edges_df = pd.concat(\n",
    "            [bundled_edges_df, straight_edges_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Round to 10 decimal places in x, y, z\n",
    "        for coord in [\"x\", \"y\", \"z\"]:\n",
    "            final_edges_df[coord] = final_edges_df[coord].apply(\n",
    "                lambda points: [round(i, 10) for i in points]\n",
    "            )\n",
    "\n",
    "        return final_edges_df\n",
    "\n",
    "    def post_process_edges(self):\n",
    "        bundled_edges_df = self.create_bundled_edges_df()\n",
    "        straight_edges_df = self.create_straight_edges_df()\n",
    "        final_edges_df = self.concat_and_clean_edges(\n",
    "            bundled_edges_df, straight_edges_df\n",
    "        )\n",
    "\n",
    "        print(f\"Number of total edges: {final_edges_df.shape[0]}\")\n",
    "        print(f\"Number of straight edges: {straight_edges_df.shape[0]}\")\n",
    "\n",
    "        return final_edges_df\n",
    "\n",
    "\n",
    "# Example of how to use the class\n",
    "edge_processor = EdgeProcessor(\n",
    "    bundled_edge_pts, edges_to_bundle_df, edge_df_with_source_target_coords, threshold\n",
    ")\n",
    "final_edges_df = edge_processor.post_process_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 0, 'target': 2916, 'color': -1, 'points': [{'x': -460.8943481445, 'y': 2466.6667480469, 'z': 79.6361000248}, {'x': -419.0615006756, 'y': 2340.2105795777, 'z': 90.4760682307}, {'x': -379.2034074916, 'y': 2213.9786366679, 'z': 101.4943508081}, {'x': -342.6192764904, 'y': 2088.0458273596, 'z': 112.7942623587}, {'x': -310.2939242205, 'y': 1962.3991485009, 'z': 124.4408566149}, {'x': -282.7454466194, 'y': 1836.9724335436, 'z': 136.4588570773}, {'x': -259.910511501, 'y': 1711.6981301785, 'z': 148.8380082145}, {'x': -241.117353832, 'y': 1586.5543339053, 'z': 161.5435101908}, {'x': -225.1748457714, 'y': 1461.5921027519, 'z': 174.5281491556}, {'x': -210.5682455795, 'y': 1336.9406999217, 'z': 187.7427871842}, {'x': -195.7169525755, 'y': 1212.8032868606, 'z': 201.1423857197}, {'x': -179.2346591951, 'y': 1089.4699994879, 'z': 214.68482833}, {'x': -160.1440175076, 'y': 967.3855194457, 'z': 228.3193288859}, {'x': -138.0264994126, 'y': 847.3058514575, 'z': 241.9613822882}, {'x': -113.1126420337, 'y': 730.5510960088, 'z': 255.4543178268}, {'x': -86.3198472682, 'y': 619.3002180485, 'z': 268.5251181704}, {'x': -59.2233254557, 'y': 516.7969935072, 'z': 280.7523854236}, {'x': -33.9226607339, 'y': 427.29322164, 'z': 291.570486935}, {'x': -12.7737416453, 'y': 355.6043150198, 'z': 300.3276737559}, {'x': 1.992531763, 'y': 306.3066428168, 'z': 306.3948551499}, {'x': 8.6712331193, 'y': 282.7961219696, 'z': 309.2947613202}, {'x': 6.3686621162, 'y': 286.5330237231, 'z': 308.8052668211}, {'x': -4.9369661848, 'y': 316.7383377029, 'z': 304.9977872193}, {'x': -24.5800939395, 'y': 370.6126418308, 'z': 298.1988208592}, {'x': -51.5566335757, 'y': 443.9392387241, 'z': 288.8936780044}, {'x': -84.894572236, 'y': 531.825112116, 'z': 277.6095504629}, {'x': -123.9094869041, 'y': 629.35922284, 'z': 264.8144220691}, {'x': -168.2712214939, 'y': 732.0762860366, 'z': 250.8547043178}, {'x': -217.8944878185, 'y': 836.2252786549, 'z': 235.9380435709}, {'x': -272.7353062085, 'y': 938.9024247562, 'z': 220.1553710395}, {'x': -332.5975056843, 'y': 1038.1109531845, 'z': 203.5292727196}, {'x': -397.0243392324, 'y': 1132.7785668448, 'z': 186.0724963827}, {'x': -465.2923101173, 'y': 1222.7293303482, 'z': 167.8398319991}, {'x': -536.4736489235, 'y': 1308.5903051134, 'z': 148.9593313481}, {'x': -609.5168082804, 'y': 1391.6195078721, 'z': 129.635522363}, {'x': -683.3115487843, 'y': 1473.4625172014, 'z': 110.1265710767}, {'x': -769.4600219727, 'y': 1544.5858154297, 'z': 75.958921497}]}\n",
      "Edges data saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/EdgesData0to100_BundlPerc50_BW0,4.json\n",
      "Edges data saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/EdgesData0to100_BundlPerc50_BW0,4.json\n"
     ]
    }
   ],
   "source": [
    "class EdgeTransformer:\n",
    "    def __init__(self, edges_df, nodes_df):\n",
    "        self.edges_df = edges_df\n",
    "        self.nodes_df = nodes_df\n",
    "\n",
    "    def add_color_attr(self):\n",
    "        \"\"\"\n",
    "        Add cluster information to edges based on node clusters.\n",
    "        If nodes are in the same cluster, the cluster ID is added; otherwise, -1 is added.\n",
    "        \"\"\"\n",
    "        self.edges_df[\"color\"] = [\n",
    "            (\n",
    "                self.nodes_df.loc[source, \"cluster\"]\n",
    "                if self.nodes_df.loc[source, \"cluster\"]\n",
    "                == self.nodes_df.loc[target, \"cluster\"]\n",
    "                else -1\n",
    "            )\n",
    "            for source, target in zip(self.edges_df[\"source\"], self.edges_df[\"target\"])\n",
    "        ]\n",
    "        return self.edges_df\n",
    "\n",
    "    def transform_edges(\n",
    "        self, x_col=\"x\", y_col=\"y\", z_col=\"z\", extra_edge_attributes=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Transform edge data from a DataFrame into a list of dictionaries with points and extra attributes.\n",
    "\n",
    "        Args:\n",
    "        x_col (str): Name of the column containing x-coordinates. Default is \"x\".\n",
    "        y_col (str): Name of the column containing y-coordinates. Default is \"y\".\n",
    "        z_col (str): Name of the column containing z-coordinates. Default is \"z\".\n",
    "        extra_edge_attributes (list): List of additional attribute names to include. Default is None.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of dictionaries, each representing an edge with its points and attributes.\n",
    "        \"\"\"\n",
    "        if extra_edge_attributes is None:\n",
    "            extra_edge_attributes = []\n",
    "\n",
    "        def create_edge_object(edge):\n",
    "            return {\n",
    "                **{attr: edge[attr] for attr in extra_edge_attributes if attr in edge},\n",
    "                \"points\": [\n",
    "                    {\"x\": float(x), \"y\": float(y), \"z\": float(z)}\n",
    "                    for x, y, z in zip(edge[x_col], edge[y_col], edge[z_col])\n",
    "                    if not (pd.isna(x) or pd.isna(y) or pd.isna(z))\n",
    "                ],\n",
    "            }\n",
    "\n",
    "        return [\n",
    "            create_edge_object(edge) for edge in self.edges_df.to_dict(orient=\"records\")\n",
    "        ]\n",
    "\n",
    "    def save_edges_to_json(self, edges_list, output_dir):\n",
    "        \"\"\"\n",
    "        Save the edges list to a JSON file.\n",
    "\n",
    "        Args:\n",
    "        edges_list (list): The list of edges to save.\n",
    "        output_dir (str): The directory path to save the JSON file.\n",
    "        \"\"\"\n",
    "        with open(output_dir, \"w\") as f:\n",
    "            json.dump(edges_list, f)\n",
    "        print(f\"Edges data saved to {output_dir}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "edge_transformer = EdgeTransformer(final_edges_df, nodes_df)\n",
    "edges_df_with_color = edge_transformer.add_color_attr()\n",
    "edges_list = edge_transformer.transform_edges(\n",
    "    extra_edge_attributes=[\"source\", \"target\", \"color\"]\n",
    ")\n",
    "\n",
    "print(edges_list[0])\n",
    "\n",
    "# Save to JSON\n",
    "OUTPUT_DIR = \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/\"\n",
    "edge_transformer.save_edges_to_json(edges_list, OUTPUT_DIR + EDGES_DATA_FILENAME)\n",
    "edge_transformer.save_edges_to_json(\n",
    "    edges_list,\n",
    "    THREEJS_OUTPUT_DIR + EDGES_DATA_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodesSaver:\n",
    "    \"\"\"\n",
    "    A utility class for saving node data from a DataFrame to JSON format, particularly for use in JavaScript applications.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_dataframe_nodes_to_json(\n",
    "        df: pd.DataFrame,\n",
    "        paths: Union[str, List[str]],\n",
    "        return_json: bool = False,\n",
    "        attributes: List[str] = None,\n",
    "    ) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Save the DataFrame nodes to one or more JSON files.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The input DataFrame containing node data.\n",
    "            paths (Union[str, List[str]]): Path or list of paths to save the JSON file(s).\n",
    "            return_json (bool): If True, return the JSON data as well as saving it.\n",
    "            attributes (List[str]): List of node attributes to include in the JSON.\n",
    "\n",
    "        Returns:\n",
    "            Optional[List[Dict]]: List of node dictionaries if return_json is True, else None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If a specified attribute is missing from the DataFrame.\n",
    "        \"\"\"\n",
    "        if attributes is None:\n",
    "            attributes = [\n",
    "                \"node_id\",\n",
    "                \"node_name\",\n",
    "                \"doi\",\n",
    "                \"year\",\n",
    "                \"title\",\n",
    "                \"cluster\",\n",
    "                \"centrality\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "\n",
    "        # Check if all attributes are present in the DataFrame\n",
    "        missing_attributes = [attr for attr in attributes if attr not in df.columns]\n",
    "        if missing_attributes:\n",
    "            raise ValueError(f\"Missing attributes in DataFrame: {missing_attributes}\")\n",
    "\n",
    "        # Fix encoding of titles\n",
    "        df[\"title\"] = df[\"title\"].apply(NodesSaver.fix_encoding)\n",
    "\n",
    "        # Convert DataFrame to list of dictionaries\n",
    "        nodes_json = df[attributes].to_dict(orient=\"records\")\n",
    "\n",
    "        # Convert single path to list for consistent processing\n",
    "        if isinstance(paths, str):\n",
    "            paths = [paths]\n",
    "\n",
    "        # Save to all specified paths\n",
    "        for path in paths:\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(nodes_json, f)\n",
    "            print(f\"Graph nodes saved to {path}\")\n",
    "\n",
    "        return nodes_json if return_json else None\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_encoding(title: str) -> str:\n",
    "        \"\"\"\n",
    "        Fix the encoding of a string.\n",
    "\n",
    "        Args:\n",
    "            title (str): The input string to fix.\n",
    "\n",
    "        Returns:\n",
    "            str: The fixed string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            decoded_title = title.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            return decoded_title.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except UnicodeEncodeError:\n",
    "            # If the above method fails, return the original title\n",
    "            return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/NodesData0to100_BundlPerc50_BW0,4.json\n",
      "Graph nodes saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/NodesData0to100_BundlPerc50_BW0,4.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doi': '10.1016/0024-3205(82)90686-5',\n",
       " 'year': 1982,\n",
       " 'title': 'Serotonergic mechanism in the control of -endorphin and acth release in male rats',\n",
       " 'cluster': 70,\n",
       " 'centrality': 0.0456272141630445,\n",
       " 'x': -460.89434814453125,\n",
       " 'y': 2466.666748046875,\n",
       " 'z': 79.63610002475772,\n",
       " 'node_index': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save nodes\n",
    "OUTPUT_DIRA = OUTPUT_DIR + NODES_DATA_FILENAME\n",
    "\n",
    "OUTPUT_DIRB = THREEJS_OUTPUT_DIR + NODES_DATA_FILENAME\n",
    "\n",
    "saver = NodesSaver()\n",
    "nodes_json = saver.save_dataframe_nodes_to_json(\n",
    "    nodes_df,\n",
    "    paths=[OUTPUT_DIRA, OUTPUT_DIRB],\n",
    "    return_json=True,\n",
    "    attributes=[\n",
    "        \"doi\",\n",
    "        \"year\",\n",
    "        \"title\",\n",
    "        \"cluster\",\n",
    "        \"centrality\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"node_index\",\n",
    "    ],\n",
    ")\n",
    "nodes_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
