{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphReader:**\n",
    "\n",
    "- `read_and_clean_graph`: Reads a graph from a GraphML file, assigns node IDs, cleans up attribute names, and prints summary information about the graph.\n",
    "\n",
    "**LayoutUtility:**\n",
    "\n",
    "- `fr_layout_nx`: Performs a Fruchterman-Reingold layout on the graph using NetworkX. It allows for customization of layout parameters and prints information about the layout process.\n",
    "\n",
    "**ZCoordinateAdder:**\n",
    "\n",
    "- `add_z_coordinate_to_nodes`: Adds a z-coordinate to each node in the graph based on its centrality value. It calculates the bounds of the x and y coordinates, normalizes centrality values, scales the z-coordinates, and adds them to the nodes.\n",
    "\n",
    "**GraphBundler2d:**\n",
    "\n",
    "- `prune_edges_by_percentile_weight`: Removes edges with weights below a specified percentile threshold.\n",
    "  bundle_edges: Performs edge bundling using the Hammer Bundle algorithm. It first prunes edges and then performs bundling with user-defined parameters. It also groups the bundled edges by edge ID and includes source and target positions.\n",
    "\n",
    "**EdgeZInterpolator:**\n",
    "\n",
    "- `interpolate_z_to_edges`: Interpolates z-coordinates for each edge in a DataFrame using cubic spline interpolation. It considers the source and target node z-coordinates and the edge path to assign z-coordinates to all points along the bundled edge.\n",
    "\n",
    "**Apply3DEdgeBundling:**\n",
    "\n",
    "- `apply_3d_bundling`: Applies 3D edge bundling to a graph's edges. It utilizes neighbor information, forces, and smoothing to create a bundled representation of edges in 3D space. It allows for customization of various parameters like the number of iterations, step size, smoothing iterations, and neighbor radius.\n",
    "\n",
    "**GraphSaver:**\n",
    "\n",
    "- `save_igraph_nodes_to_json`: Saves node data from an igraph graph to a JSON file. It offers options to return the JSON string as well as specify which node attributes to include.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import logging\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Disable SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Graphs and networks\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet as cc\n",
    "from matplotlib.colors import to_hex, to_rgb\n",
    "\n",
    "# Data visualization and processing\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.bundling import hammer_bundle\n",
    "\n",
    "# Scientific computing\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "\n",
    "\n",
    "# Progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Performance optimization\n",
    "from numba import jit, prange\n",
    "\n",
    "# Custom modules\n",
    "from fa2_modified import ForceAtlas2\n",
    "\n",
    "# Warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Constants and configuration\n",
    "INPUT_GRAPH_PATH = \"../data/07-clustered-graphs/alpha0.3_k10_res0.002.graphml\"\n",
    "CLUSTER_INFO_LABEL_TREE = \"../output/cluster-qualifications/ClusterInfoLabelTree.xlsx\"\n",
    "CLUSTER_LABEL_DICT_PATH = \"../data/99-testdata/cluster_label_dict.json\"\n",
    "CLUSTER_TREE_PATH = \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    "OUTPUT_DIR = \"../data/99-testdata/\"\n",
    "THREEJS_OUTPUT_DIR = (\n",
    "    \"/Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/\"\n",
    ")\n",
    "CLUSTER_HIERACHY_FOR_LEGEND_PATH = (\n",
    "    \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utility functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphReader:\n",
    "    @staticmethod\n",
    "    def read_and_clean_graph(path: str) -> ig.Graph:\n",
    "        g = ig.Graph.Read_GraphML(path)\n",
    "        g.vs[\"node_id\"] = [int(i) for i in range(g.vcount())]\n",
    "\n",
    "        if \"id\" in g.vs.attribute_names():\n",
    "            g.vs[\"node_name\"] = g.vs[\"id\"]\n",
    "            del g.vs[\"id\"]\n",
    "\n",
    "        if \"cluster\" in g.vs.attribute_names():\n",
    "            g.vs[\"cluster\"] = [int(cluster) for cluster in g.vs[\"cluster\"]]\n",
    "\n",
    "        if \"year\" in g.vs.attribute_names():\n",
    "            g.vs[\"year\"] = [int(year) for year in g.vs[\"year\"]]\n",
    "\n",
    "        if \"eid\" in g.vs.attribute_names():\n",
    "            del g.vs[\"eid\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.006\" in g.vs.attribute_names():\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.006\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.002\" in g.vs.attribute_names():\n",
    "            g.vs[\"centrality\"] = g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "\n",
    "        g.es[\"edge_id\"] = list(range(g.ecount()))\n",
    "        print(\"Node Attributes:\", g.vs.attribute_names())\n",
    "        print(\"Edge Attributes:\", g.es.attribute_names())\n",
    "        # print number of nodes and edges\n",
    "        print(f\"Number of nodes: {g.vcount()}\")\n",
    "        print(f\"Number of edges: {g.ecount()}\")\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def subgraph_of_clusters(G, clusters):\n",
    "        if isinstance(G, nx.Graph):\n",
    "            nodes = [\n",
    "                node for node in G.nodes if G.nodes[node].get(\"cluster\") in clusters\n",
    "            ]\n",
    "            return G.subgraph(nodes)\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            nodes = [v.index for v in G.vs if v[\"cluster\"] in clusters]\n",
    "            return G.subgraph(nodes)\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "    @staticmethod\n",
    "    def add_cluster_labels(\n",
    "        G: Union[nx.Graph, ig.Graph],\n",
    "        labels_file_path: str = \"../output/cluster-qualifications/raw_cluster_labels.json\",\n",
    "    ) -> Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "        \"\"\"\n",
    "        Add cluster labels to the graph nodes.\n",
    "\n",
    "        Args:\n",
    "            G (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "            labels_file_path (str): Path to the JSON file containing cluster labels.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "                The graph with added cluster labels and the cluster label dictionary.\n",
    "        \"\"\"\n",
    "        with open(labels_file_path) as file:\n",
    "            cluster_label_dict = json.load(file)\n",
    "        cluster_label_dict = {float(k): v[0] for k, v in cluster_label_dict.items()}\n",
    "\n",
    "        if isinstance(G, nx.Graph):\n",
    "            for node in G.nodes:\n",
    "                cluster = G.nodes[node][\"cluster\"]\n",
    "                G.nodes[node][\"cluster_label\"] = cluster_label_dict.get(\n",
    "                    cluster, \"Unknown\"\n",
    "                )\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            G.vs[\"cluster_label\"] = [\n",
    "                cluster_label_dict.get(v[\"cluster\"], \"Unknown\") for v in G.vs\n",
    "            ]\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "        return G, cluster_label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayoutUtility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "from typing import Union, Dict, Tuple, Optional\n",
    "\n",
    "\n",
    "class LayoutUtility:\n",
    "    \"\"\"\n",
    "    Layout utility class for igraph layout operations. made for fruchterman-reingold layout.\n",
    "\n",
    "    Args:\n",
    "        g (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "        layout_params (Optional[Dict]): The layout parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[nx.Graph, Dict]: The graph with assigned coordinates and the layout dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fr_layout_nx(\n",
    "        g: Union[nx.Graph, ig.Graph], layout_params: Optional[Dict] = None\n",
    "    ) -> Tuple[nx.Graph, Dict]:\n",
    "        print(\"Starting Fruchterman-Reingold layout process...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if layout_params is None:\n",
    "            layout_params = {\n",
    "                \"iterations\": 100,\n",
    "                \"threshold\": 0.00001,\n",
    "                \"weight\": \"weight\",\n",
    "                \"scale\": 1,\n",
    "                \"center\": (0, 0),\n",
    "                \"dim\": 2,\n",
    "                \"seed\": 1887,\n",
    "            }\n",
    "        print(f\"Layout parameters: {layout_params}\")\n",
    "\n",
    "        if not isinstance(g, nx.Graph):\n",
    "            print(\"Converting to NetworkX Graph...\")\n",
    "            G = g.to_networkx()\n",
    "            print(\"Conversion complete.\")\n",
    "        else:\n",
    "            G = g\n",
    "\n",
    "        print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "        print(\"Calculating layout...\")\n",
    "        layout_start_time = time.time()\n",
    "        pos = nx.spring_layout(G, **layout_params)\n",
    "        layout_end_time = time.time()\n",
    "        print(\n",
    "            f\"Layout calculation completed in {layout_end_time - layout_start_time:.2f} seconds.\"\n",
    "        )\n",
    "\n",
    "        print(\"Processing layout results...\")\n",
    "        node_xy_dict = {node: pos[node] for node in G.nodes}\n",
    "\n",
    "        x_values, y_values = zip(*node_xy_dict.values())\n",
    "        min_x, max_x = min(x_values), max(x_values)\n",
    "        min_y, max_y = min(y_values), max(y_values)\n",
    "\n",
    "        print(f\"Layout boundaries:\")\n",
    "        print(f\"X-axis: Min = {min_x:.2f}, Max = {max_x:.2f}\")\n",
    "        print(f\"Y-axis: Min = {min_y:.2f}, Max = {max_y:.2f}\")\n",
    "\n",
    "        print(\"Assigning coordinates to nodes...\")\n",
    "        for node in G.nodes:\n",
    "            G.nodes[node][\"x\"] = node_xy_dict[node][0]\n",
    "            G.nodes[node][\"y\"] = node_xy_dict[node][1]\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Layout process completed in {total_time:.2f} seconds.\")\n",
    "\n",
    "        return G, pos\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# g = ... # your graph object\n",
    "# G, pos = LayoutUtility.fr_layout_nx(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z Coordinate Adder\n",
    "\n",
    "adds a z coodrinate bases on the centrality of the node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZCoordinateAdder:\n",
    "    def __init__(self, g, scale_factor=0.15):\n",
    "        self.g = g\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def add_z_coordinate_to_nodes(self):\n",
    "        \"\"\"\n",
    "        Add a z-coordinate to the nodes of the graph based on their centrality values.\n",
    "\n",
    "        Args:\n",
    "            g (nx.Graph): The input graph.\n",
    "            scale_factor (float): The scaling factor for the z-coordinates. (they should not be as spread out as x and y)\n",
    "\n",
    "        Returns:\n",
    "            nx.Graph: The graph with the z-coordinate added to the nodes.\n",
    "        \"\"\"\n",
    "        # Calculate the bounds of x and y coordinates\n",
    "        # Assuming self.g is a NetworkX graph\n",
    "        xvalues = [attributes[\"x\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        yvalues = [attributes[\"y\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        min_x, max_x = min(xvalues), max(xvalues)\n",
    "        min_y, max_y = min(yvalues), max(yvalues)\n",
    "\n",
    "        print(\"Bounds of the layout:\")\n",
    "        print(f\"Min x: {min_x}, Max x: {max_x}\")\n",
    "        print(f\"Min y: {min_y}, Max y: {max_y}\")\n",
    "\n",
    "        # Extract centrality values from nodes\n",
    "        centralities = np.array(\n",
    "            [self.g.nodes[node][\"centrality\"] for node in self.g.nodes]\n",
    "        )\n",
    "\n",
    "        # Normalize centrality values to range [0, 1]\n",
    "        centrality_min = centralities.min()\n",
    "        centrality_max = centralities.max()\n",
    "        centralities_normalized = (centralities - centrality_min) / (\n",
    "            centrality_max - centrality_min\n",
    "        )\n",
    "\n",
    "        # Adjust normalized centrality values to range [-1, 1]\n",
    "        centralities_adjusted = centralities_normalized * 2 - 1\n",
    "\n",
    "        # Scale down the z-values to make them less pronounced\n",
    "        z_coordinates = centralities_adjusted * self.scale_factor\n",
    "\n",
    "        # Add z-coordinate to nodes\n",
    "        for i, node in enumerate(self.g.nodes):\n",
    "            self.g.nodes[node][\"z\"] = z_coordinates[i]\n",
    "\n",
    "        # Describe the distribution of z values\n",
    "        print(\"Description of the Z coordinate values:\")\n",
    "        print(pd.Series(z_coordinates).describe())\n",
    "\n",
    "        print(\"Z coordinate added to nodes\")\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning and 2D Bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2395667157.py, line 170)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[103], line 170\u001b[0;36m\u001b[0m\n\u001b[0;31m    : self.graph.vs[node_id][\"z\"],\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class GraphBundler2d:\n",
    "    \"\"\"\n",
    "    A class for bundling edges in graphs using the Hammer Bundle algorithm.\n",
    "\n",
    "    This class supports both igraph and NetworkX graph objects as input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph: Union[ig.Graph, nx.Graph],\n",
    "        pruning_weight_percentile: float = 50,\n",
    "        bundle_kwargs: Optional[Dict] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the GraphBundler.\n",
    "\n",
    "        Args:\n",
    "            graph (Union[ig.Graph, nx.Graph]): The input graph.\n",
    "            pruning_weight_percentile (float): The percentile to use for pruning edges (default is 50).\n",
    "            bundle_kwargs (Optional[Dict]): Optional parameters for the bundling algorithm.\n",
    "        \"\"\"\n",
    "        self.graph = self._ensure_igraph(graph)\n",
    "        self.pruning_weight_percentile = pruning_weight_percentile\n",
    "        self.bundle_kwargs = bundle_kwargs or {\n",
    "            \"decay\": 0.90,\n",
    "            \"initial_bandwidth\": 0.10,\n",
    "            \"iterations\": 15,\n",
    "            \"include_edge_id\": True,\n",
    "        }\n",
    "        self.bundled_edges = None\n",
    "\n",
    "    def _ensure_igraph(self, graph: Union[ig.Graph, nx.Graph]) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Ensure the input graph is an igraph object.\n",
    "\n",
    "        Args:\n",
    "            graph (Union[ig.Graph, nx.Graph]): The input graph.\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: The graph as an igraph object.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input is neither an igraph nor a NetworkX graph object.\n",
    "        \"\"\"\n",
    "        if isinstance(graph, ig.Graph):\n",
    "            return graph\n",
    "        if isinstance(graph, nx.Graph):\n",
    "            return ig.Graph.from_networkx(graph)\n",
    "        raise ValueError(\n",
    "            \"Input graph must be either an igraph or NetworkX graph object.\"\n",
    "        )\n",
    "\n",
    "    def prune_edges_by_percentile_weight(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Remove edges from the graph that have weight less than or equal to the specified percentile weight.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph. Must have a 'weight' attribute for edges.\n",
    "            percentile (float): The percentile to use as the threshold for pruning edges.\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with edges removed based on the specified percentile.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input graph has no 'weight' attribute for edges.\n",
    "        \"\"\"\n",
    "        # Check if 'weight' attribute exists\n",
    "        if \"weight\" not in g.es.attributes():\n",
    "            raise ValueError(\"Input graph must have a 'weight' attribute for edges.\")\n",
    "\n",
    "        # Get initial number of edges and isolates\n",
    "        initial_edge_count = g.ecount()\n",
    "        initial_isolates = len(g.vs.select(_degree=0))\n",
    "\n",
    "        # Get all weights and calculate the specified percentile\n",
    "        weights = g.es[\"weight\"]\n",
    "        weight_threshold = np.percentile(weights, percentile)\n",
    "\n",
    "        # Identify edges to keep\n",
    "        edges_to_keep = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] > weight_threshold\n",
    "        ]\n",
    "        threshold_edges = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] == weight_threshold\n",
    "        ]\n",
    "\n",
    "        # Randomly select from threshold edges to reach target number of edges\n",
    "        target_edge_count = int(initial_edge_count * (1 - percentile / 100))\n",
    "        edges_to_add = target_edge_count - len(edges_to_keep)\n",
    "        if edges_to_add > 0:\n",
    "            random.shuffle(threshold_edges)\n",
    "            edges_to_keep.extend(threshold_edges[:edges_to_add])\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_pruned = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Get final number of edges and isolates\n",
    "        final_edge_count = g_pruned.ecount()\n",
    "        final_isolates = len(g_pruned.vs.select(_degree=0))\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Pruning edges by weight percentile: {percentile}%\")\n",
    "        print(\"-\" * 20)\n",
    "        print(f\"Number of edges before: {initial_edge_count}\")\n",
    "        print(f\"Number of edges after: {final_edge_count}\")\n",
    "        print(f\"Number of isolates before: {initial_isolates}\")\n",
    "        print(f\"Number of isolates after: {final_isolates}\")\n",
    "\n",
    "        return g_pruned\n",
    "\n",
    "    def bundle_edges(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Perform edge bundling on the graph.\n",
    "\n",
    "        Returns:\n",
    "            Optional[pd.DataFrame]: A DataFrame containing the bundled edges,\n",
    "            or None if an error occurs.\n",
    "        \"\"\"\n",
    "        g_pruned = self.prune_edges_by_percentile_weight(\n",
    "            self.graph, self.pruning_weight_percentile\n",
    "        )\n",
    "        self.graph = g_pruned\n",
    "\n",
    "        print(\"Starting edge bundling process...\")\n",
    "\n",
    "        try:\n",
    "            df_nodes = pd.DataFrame(\n",
    "                {\n",
    "                    \"x\": self.graph.vs[\"x\"],\n",
    "                    \"y\": self.graph.vs[\"y\"],\n",
    "                    \"z\": self.graph.vs[\"z\"],\n",
    "                    \"cluster\": self.graph.vs[\"cluster\"],\n",
    "                }\n",
    "            )\n",
    "            edges_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"source\": [e.source for e in self.graph.es],\n",
    "                    \"target\": [e.target for e in self.graph.es],\n",
    "                    \"edge_id\": self.graph.es[\"edge_id\"],\n",
    "                    \"weight\": self.graph.es[\"weight\"],\n",
    "                }\n",
    "            )\n",
    "            bundled_edges = hammer_bundle(df_nodes, edges_df, **self.bundle_kwargs)\n",
    "            bundled_edges = pd.DataFrame(\n",
    "                bundled_edges, columns=[\"x\", \"y\", \"edge_id\", \"weight\"]\n",
    "            )\n",
    "            self.bundled_edges = self._group_bundled_edges(bundled_edges)\n",
    "            return self.bundled_edges, g_pruned\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during edge bundling: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _group_bundled_edges(self, bundled_edges: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Group the bundled edges by edge_id and include source and target positions.\n",
    "\n",
    "        Args:\n",
    "            bundled_edges (pd.DataFrame): DataFrame containing the bundled edges.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with grouped bundled edges including source and target positions.\n",
    "        \"\"\"\n",
    "\n",
    "        def _get_node_positions(node_id):\n",
    "            return {\n",
    "                \"x\": self.graph.vs[node_id][\"x\"],\n",
    "                \"y\": self.graph.vs[node_id][\"y\"],\n",
    "            : self.graph.vs[node_id][\"z\"],\n",
    "            }\n",
    "\n",
    "        grouped = bundled_edges.groupby(\"edge_id\")\n",
    "        result = pd.DataFrame(\n",
    "            {\n",
    "                \"source\": [\n",
    "                    self.graph.es.find(edge_id=eid).source for eid in grouped.groups\n",
    "                ],\n",
    "                \"target\": [\n",
    "                    self.graph.es.find(edge_id=eid).target for eid in grouped.groups\n",
    "                ],\n",
    "                \"x\": [group[\"x\"].values for _, group in grouped],\n",
    "                \"y\": [group[\"y\"].values for _, group in grouped],\n",
    "                \"weight\": grouped[\"weight\"].first(),\n",
    "            },\n",
    "            index=grouped.groups.keys(),\n",
    "        )\n",
    "\n",
    "        # Convert the DataFrame's index into a column named 'edge_id'\n",
    "        result.reset_index(inplace=True)\n",
    "        result.rename(columns={\"index\": \"edge_id\"}, inplace=True)\n",
    "\n",
    "        # Add source and target positions\n",
    "        result[\"source_position\"] = result[\"source\"].apply(_get_node_positions)\n",
    "        result[\"target_position\"] = result[\"target\"].apply(_get_node_positions)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation of Z coordinates\n",
    "\n",
    "add z coordinates to the positions of bundled edges using cubic spline interpolation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeZInterpolator:\n",
    "    def __init__(self, pruned_bundled_edges_2d, graph, centrality_scale_factor=0.2):\n",
    "        \"\"\"\n",
    "        Initialize the EdgeZInterpolator.\n",
    "\n",
    "        Args:\n",
    "            pruned_bundled_edges_2d (pd.DataFrame): The DataFrame containing bundled edges.\n",
    "            graph (ig.Graph): The original graph object.\n",
    "        \"\"\"\n",
    "        self.pruned_bundled_edges_2d = pruned_bundled_edges_2d\n",
    "        self.graph = graph\n",
    "        self.adjusted_edges_3d = None\n",
    "\n",
    "    def interpolate_z_to_edges(self):\n",
    "        \"\"\"\n",
    "        Interpolate z-coordinates for each edge in the pruned_bundled_edges_2d DataFrame.\n",
    "        \"\"\"\n",
    "        self.adjusted_edges_3d = self.pruned_bundled_edges_2d.apply(\n",
    "            self._interpolate_z, axis=1\n",
    "        )\n",
    "        self.adjusted_edges_3d = pd.concat(\n",
    "            [self.pruned_bundled_edges_2d, self.adjusted_edges_3d], axis=1\n",
    "        )\n",
    "        print(\"Initial Z Coordinates added to edges\")\n",
    "        return self.adjusted_edges_3d\n",
    "\n",
    "    def _interpolate_z(self, row):\n",
    "        \"\"\"\n",
    "        Interpolate z-coordinates for a single edge.\n",
    "\n",
    "        Args:\n",
    "            row (pd.Series): A pandas Series representing a single row in the pruned_bundled_edges_2d DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: A pandas Series containing the x, y, and interpolated z-coordinates.\n",
    "        \"\"\"\n",
    "        x = np.array(row[\"x\"])\n",
    "        y = np.array(row[\"y\"])\n",
    "\n",
    "        source_z = row[\"source_position\"][\"z\"]\n",
    "        target_z = row[\"target_position\"][\"z\"]\n",
    "\n",
    "        distances = np.sqrt(np.diff(x) ** 2 + np.diff(y) ** 2)\n",
    "        cumulative_distances = np.cumsum(distances)\n",
    "\n",
    "        if cumulative_distances.size == 0 or cumulative_distances[-1] == 0:\n",
    "            num_points = len(x)\n",
    "            z = np.linspace(source_z, target_z, num_points)\n",
    "        else:\n",
    "            t = np.insert(cumulative_distances, 0, 0) / cumulative_distances[-1]\n",
    "            cs = CubicSpline([0, 1], [source_z, target_z])\n",
    "            z = cs(t)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\"interpolated_x\": x, \"interpolated_y\": y, \"interpolated_z\": z}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apply3DEdgeBundling:\n",
    "    \"\"\"Applies 3D edge bundling to a graph's edges.\n",
    "    bundled_edges: DataFrame containing edge data with interpolated 3D coordinates.\n",
    "    bundling_iterations: Number of iterations for the bundling algorithm.More iterations result in more bundling.\n",
    "    step_size: Controls the magnitude of force application in each iteration. Smaller steps provide more stable bundling but require more iterations for the same effect.\n",
    "    compatibility_threshold: Threshold for determining edge compatibility (not used in current implementation). High: More strict compatibility, fewer edges are bundled together.\n",
    "    smoothing_iterations: Number of smoothing passes applied to each edge. High: More smoothing iterations create smoother curves but may lose some detail. Low: Fewer smoothing iterations preserve more original path details but may result in jagged edges.\n",
    "    neighbor_radius: Radius for finding neighboring points, 'auto' for automatic inference. High: Larger radius considers more distant points, potentially leading to more global bundling. Low: Smaller radius only considers nearby points, resulting in more local bundling.\n",
    "    radius_multiplier: Used to adjust the automatically inferred radius. High: Increases the automatically inferred neighbor radius, considering more distant points. Low: Decreases the automatically inferred neighbor radius, focusing on more local interactions.\n",
    "    n_jobs: Number of CPU cores to use for parallel processing.\n",
    "    points: Array of 3D coordinates for all edge points.\n",
    "    neighbor_indices: Array of indices of neighboring points for each point.\n",
    "    neighbor_counts: Array of neighbor counts for each point.\n",
    "    point_to_edge: Array mapping each point to its corresponding edge index.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bundled_edges,\n",
    "        bundling_iterations=20,\n",
    "        step_size=0.3,\n",
    "        compatibility_threshold=0.3,\n",
    "        smoothing_iterations=5,\n",
    "        neighbor_radius=\"auto\",\n",
    "        radius_multiplier=0.2,\n",
    "    ):\n",
    "        self.bundled_edges = bundled_edges\n",
    "        self.bundling_iterations = bundling_iterations\n",
    "        self.step_size = step_size\n",
    "        self.compatibility_threshold = compatibility_threshold\n",
    "        self.smoothing_iterations = smoothing_iterations\n",
    "        self.neighbor_radius = neighbor_radius\n",
    "        self.radius_multiplier = radius_multiplier\n",
    "        self.n_jobs = min(4, max(1, cpu_count() - 2))  # Limit to 4 processes\n",
    "        self.adjusted_edges = None\n",
    "\n",
    "        # Set up logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def _infer_neighbor_radius(self, points):\n",
    "        try:\n",
    "            min_coords = np.min(points, axis=0)\n",
    "            max_coords = np.max(points, axis=0)\n",
    "            diagonal = np.linalg.norm(max_coords - min_coords)\n",
    "\n",
    "            base_percentage = 0.05\n",
    "            point_count_factor = np.log10(len(points)) / 10\n",
    "            adjusted_percentage = base_percentage / (1 + point_count_factor)\n",
    "\n",
    "            inferred_radius = diagonal * adjusted_percentage * self.radius_multiplier\n",
    "\n",
    "            self.logger.info(f\"Diagonal of bounding box: {diagonal}\")\n",
    "            self.logger.info(f\"Adjusted percentage: {adjusted_percentage:.6f}\")\n",
    "            self.logger.info(f\"Inferred radius: {inferred_radius:.6f}\")\n",
    "\n",
    "            return inferred_radius\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in _infer_neighbor_radius: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(nopython=True, parallel=True)\n",
    "    def _apply_forces(\n",
    "        points, neighbor_indices, neighbor_counts, point_to_edge, step_size\n",
    "    ):\n",
    "        new_points = points.copy()\n",
    "        for i in prange(1, len(points) - 1):\n",
    "            edge_index = point_to_edge[i]\n",
    "            force = np.zeros(3)\n",
    "            count = 0\n",
    "            for j in range(neighbor_counts[i]):\n",
    "                n = neighbor_indices[i, j]\n",
    "                if n != -1 and point_to_edge[n] != edge_index:\n",
    "                    direction = points[n] - points[i]\n",
    "                    distance = np.linalg.norm(direction)\n",
    "                    if distance > 0:\n",
    "                        force += direction / distance\n",
    "                    count += 1\n",
    "            if count > 0:\n",
    "                force_magnitude = np.linalg.norm(force)\n",
    "                if force_magnitude > 0:\n",
    "                    new_points[i] += step_size * (force / force_magnitude)\n",
    "        return new_points\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(nopython=True)\n",
    "    def _smooth_edge(edge_points, smoothing_iterations):\n",
    "        for _ in range(smoothing_iterations):\n",
    "            new_points = edge_points.copy()\n",
    "            new_points[1:-1] = 0.5 * edge_points[1:-1] + 0.25 * (\n",
    "                edge_points[:-2] + edge_points[2:]\n",
    "            )\n",
    "            edge_points = new_points\n",
    "        return edge_points\n",
    "\n",
    "    def apply_3d_bundling(self):\n",
    "        try:\n",
    "            self.adjusted_edges = self.bundled_edges.copy()\n",
    "\n",
    "            # Convert interpolated x, y, z to points\n",
    "            self.adjusted_edges[\"points\"] = self.adjusted_edges.apply(\n",
    "                lambda row: np.column_stack(\n",
    "                    (\n",
    "                        row[\"interpolated_x\"],\n",
    "                        row[\"interpolated_y\"],\n",
    "                        row[\"interpolated_z\"],\n",
    "                    )\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            all_points = np.vstack(self.adjusted_edges[\"points\"].values)\n",
    "\n",
    "            point_to_edge = np.repeat(\n",
    "                np.arange(len(self.adjusted_edges)),\n",
    "                self.adjusted_edges[\"points\"].apply(len),\n",
    "            )\n",
    "\n",
    "            if self.neighbor_radius == \"auto\":\n",
    "                self.neighbor_radius = self._infer_neighbor_radius(all_points)\n",
    "                self.logger.info(\n",
    "                    f\"Inferred neighbor radius: {self.neighbor_radius:.4f}\"\n",
    "                )\n",
    "\n",
    "            tree = cKDTree(all_points)\n",
    "            neighbors_list = tree.query_ball_point(all_points, r=self.neighbor_radius)\n",
    "\n",
    "            max_neighbors = max(len(n) for n in neighbors_list)\n",
    "            neighbor_indices = np.full(\n",
    "                (len(all_points), max_neighbors), -1, dtype=np.int64\n",
    "            )\n",
    "            neighbor_counts = np.zeros(len(all_points), dtype=np.int64)\n",
    "\n",
    "            for i, neighbors in enumerate(neighbors_list):\n",
    "                neighbor_counts[i] = len(neighbors)\n",
    "                neighbor_indices[i, : len(neighbors)] = neighbors\n",
    "\n",
    "            self.logger.info(\n",
    "                f\"Starting 3D edge bundling with {self.bundling_iterations} iterations\"\n",
    "            )\n",
    "            self.logger.info(f\"Using {self.n_jobs} CPU cores for parallel processing\")\n",
    "\n",
    "            with tqdm(\n",
    "                total=self.bundling_iterations, desc=\"3D Bundling Progress\"\n",
    "            ) as pbar:\n",
    "                for iteration in range(self.bundling_iterations):\n",
    "                    iteration_start_time = time.time()\n",
    "\n",
    "                    all_points = self._apply_forces(\n",
    "                        all_points,\n",
    "                        neighbor_indices,\n",
    "                        neighbor_counts,\n",
    "                        point_to_edge,\n",
    "                        self.step_size,\n",
    "                    )\n",
    "\n",
    "                    edge_points = np.split(\n",
    "                        all_points,\n",
    "                        np.cumsum(self.adjusted_edges[\"points\"].apply(len))[:-1],\n",
    "                    )\n",
    "                    with Pool(self.n_jobs) as pool:\n",
    "                        smoothed_edges = pool.starmap(\n",
    "                            self._smooth_edge,\n",
    "                            [(edge, self.smoothing_iterations) for edge in edge_points],\n",
    "                        )\n",
    "                    all_points = np.concatenate(smoothed_edges)\n",
    "\n",
    "                    iteration_time = time.time() - iteration_start_time\n",
    "                    self.logger.info(\n",
    "                        f\"Iteration {iteration + 1}/{self.bundling_iterations} completed in {iteration_time:.2f}s\"\n",
    "                    )\n",
    "                    pbar.update(1)\n",
    "\n",
    "            # Create new columns for bundled coordinates\n",
    "            self.adjusted_edges[\"bundled_x\"] = None\n",
    "            self.adjusted_edges[\"bundled_y\"] = None\n",
    "            self.adjusted_edges[\"bundled_z\"] = None\n",
    "\n",
    "            # Update the adjusted_edges with new bundled coordinates\n",
    "            start = 0\n",
    "            for i, length in enumerate(self.adjusted_edges[\"points\"].apply(len)):\n",
    "                self.adjusted_edges.at[i, \"bundled_x\"] = all_points[\n",
    "                    start : start + length, 0\n",
    "                ].tolist()\n",
    "                self.adjusted_edges.at[i, \"bundled_y\"] = all_points[\n",
    "                    start : start + length, 1\n",
    "                ].tolist()\n",
    "                self.adjusted_edges.at[i, \"bundled_z\"] = all_points[\n",
    "                    start : start + length, 2\n",
    "                ].tolist()\n",
    "                start += length\n",
    "\n",
    "            self.logger.info(\"3D edge bundling applied successfully\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in apply_3d_bundling: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_bundled_edges(self):\n",
    "        return self.adjusted_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EdgesSaver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgesSaver:\n",
    "    \"\"\"\n",
    "    A utility class for saving graph data to JSON format, particularly for use in JavaScript applications.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def add_color_bool_to_edges(\n",
    "        bundled_edges_3d: pd.DataFrame, g: ig.Graph\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Add color boolean if source and target node are of the same cluster.\n",
    "        \"\"\"\n",
    "        bundled_edges_3d[\"color\"] = False\n",
    "        for idx, edge in bundled_edges_3d.iterrows():\n",
    "            source_cluster = g.vs[edge[\"source\"]][\"cluster\"]\n",
    "            target_cluster = g.vs[edge[\"target\"]][\"cluster\"]\n",
    "            if source_cluster == target_cluster:\n",
    "                bundled_edges_3d.at[idx, \"color\"] = True\n",
    "\n",
    "        print(\n",
    "            f\"{bundled_edges_3d['color'].sum()} out of {len(bundled_edges_3d)} edges have the same source and target cluster.\"\n",
    "        )\n",
    "        return bundled_edges_3d\n",
    "\n",
    "    @staticmethod\n",
    "    def inspect_nan_edges(bundled_edges_3d: pd.DataFrame, x_col, y_col, z_col):\n",
    "        \"\"\"\n",
    "        Inspect and print information about edges containing NaN values.\n",
    "        Args:\n",
    "            bundled_edges_3d (pd.DataFrame): DataFrame containing adjusted edge data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Function to check if any element in a list is NaN\n",
    "        def has_nan(lst):\n",
    "            return any(pd.isna(x) for x in lst)\n",
    "\n",
    "        # Filter rows where any of bundled_x, bundled_y, or bundled_z contains a NaN\n",
    "        nan_edges = bundled_edges_3d[\n",
    "            bundled_edges_3d[x_col].apply(has_nan)\n",
    "            | bundled_edges_3d[y_col].apply(has_nan)\n",
    "            | bundled_edges_3d[z_col].apply(has_nan)\n",
    "            | pd.isna(bundled_edges_3d[\"weight\"])\n",
    "        ]\n",
    "\n",
    "        if nan_edges.empty:\n",
    "            print(\"No edges with NaN values found.\")\n",
    "        else:\n",
    "            print(f\"Found {len(nan_edges)} edges with NaN values:\")\n",
    "            for idx, edge in nan_edges.iterrows():\n",
    "                print(f\"Edge ID: {edge['edge_id']}\")\n",
    "                print(f\"  Source: {edge['source']}, Target: {edge['target']}\")\n",
    "                print(f\"  Weight: {edge['weight']}\")\n",
    "                print(\"  NaN positions:\")\n",
    "                for i, (x, y, z) in enumerate(\n",
    "                    zip(edge[\"x\"], edge[\"y\"], edge[\"bundled_z\"])\n",
    "                ):\n",
    "                    if pd.isna(x) or pd.isna(y) or pd.isna(z):\n",
    "                        print(f\"    Point {i}: x={x}, y={y}, z={z}\")\n",
    "                print()\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_edges_for_js(\n",
    "        bundled_edges_3d: pd.DataFrame, x_col, y_col, z_col\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Prepare adjusted edges data for efficient use in JavaScript.\n",
    "        Args:\n",
    "            bundled_edges_3d (pd.DataFrame): DataFrame containing adjusted edge data.\n",
    "        Returns:\n",
    "            List[Dict]: List of edge objects ready for JSON serialization.\n",
    "        Raises:\n",
    "            ValueError: If bundled_edges_3d is None.\n",
    "        \"\"\"\n",
    "        if bundled_edges_3d is None:\n",
    "            raise ValueError(\"Adjusted edges data is not available.\")\n",
    "\n",
    "        # First, inspect edges with NaN values\n",
    "        EdgesSaver.inspect_nan_edges(bundled_edges_3d, x_col, y_col, z_col)\n",
    "\n",
    "        # Then proceed with the rest of the method\n",
    "        edges_for_js = []\n",
    "        for _, edge in bundled_edges_3d.iterrows():\n",
    "            edge_object = {\n",
    "                \"id\": int(edge[\"edge_id\"]),\n",
    "                \"source\": int(edge[\"source\"]),\n",
    "                \"target\": int(edge[\"target\"]),\n",
    "                \"weight\": (\n",
    "                    float(edge[\"weight\"]) if not pd.isna(edge[\"weight\"]) else None\n",
    "                ),\n",
    "                \"colored\": bool(edge[\"color\"]) if \"color\" in edge else False,\n",
    "                \"points\": [\n",
    "                    {\"x\": float(x), \"y\": float(y), \"z\": float(z)}\n",
    "                    for x, y, z in zip(edge[x_col], edge[y_col], edge[z_col])\n",
    "                    if not (pd.isna(x) or pd.isna(y) or pd.isna(z))\n",
    "                ],\n",
    "            }\n",
    "            edges_for_js.append(edge_object)\n",
    "        return edges_for_js\n",
    "\n",
    "    @staticmethod\n",
    "    def save_edges_for_js(\n",
    "        bundled_edges_3d: pd.DataFrame,\n",
    "        output_files: Union[str, List[str]],\n",
    "        add_color_bool: bool = False,\n",
    "        g: ig.Graph = None,\n",
    "        return_json: bool = False,\n",
    "        x_col: str = \"x\",\n",
    "        y_col: str = \"y\",\n",
    "        z_col: str = \"z\",\n",
    "    ) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Save adjusted edges to one or more JSON files optimized for JavaScript use.\n",
    "        Args:\n",
    "            bundled_edges_3d (pd.DataFrame): DataFrame containing adjusted edge data.\n",
    "            output_files (Union[str, List[str]]): Path or list of paths to the output JSON file(s).\n",
    "            add_color_bool (bool): If True, add color boolean based on cluster information.\n",
    "            g (ig.Graph): Graph object required if add_color_bool is True.\n",
    "            return_json (bool): If True, return the JSON data as well as saving it.\n",
    "        Returns:\n",
    "            Optional[List[Dict]]: List of edge objects if return_json is True, else None.\n",
    "        \"\"\"\n",
    "        if add_color_bool:\n",
    "            if not g:\n",
    "                raise ValueError(\"Graph object is required to add color boolean.\")\n",
    "            bundled_edges_3d = EdgesSaver.add_color_bool_to_edges(bundled_edges_3d, g)\n",
    "\n",
    "        edges_data = EdgesSaver.prepare_edges_for_js(\n",
    "            bundled_edges_3d, x_col, y_col, z_col\n",
    "        )\n",
    "\n",
    "        # Convert single path to list for consistent processing\n",
    "        if isinstance(output_files, str):\n",
    "            output_files = [output_files]\n",
    "\n",
    "        # Save to all specified paths\n",
    "        for output_file in output_files:\n",
    "            with open(output_file, \"w\") as f:\n",
    "                json.dump(edges_data, f)\n",
    "            print(f\"Edges data saved to {output_file}\")\n",
    "\n",
    "        return edges_data if return_json else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes Saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import igraph as ig\n",
    "from typing import List, Dict, Optional, Union\n",
    "\n",
    "\n",
    "class NodesSaver:\n",
    "    \"\"\"\n",
    "    A utility class for saving graph data to JSON format, particularly for use in JavaScript applications.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_igraph_nodes_to_json(\n",
    "        g: ig.Graph,\n",
    "        paths: Union[str, List[str]],\n",
    "        return_json: bool = False,\n",
    "        attributes: List[str] = None,\n",
    "    ) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Save the igraph nodes to one or more JSON files.\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph.\n",
    "            paths (Union[str, List[str]]): Path or list of paths to save the JSON file(s).\n",
    "            return_json (bool): If True, return the JSON data as well as saving it.\n",
    "            attributes (List[str]): List of node attributes to include in the JSON.\n",
    "        Returns:\n",
    "            Optional[List[Dict]]: List of node dictionaries if return_json is True, else None.\n",
    "        Raises:\n",
    "            ValueError: If a specified attribute is missing from a node.\n",
    "        \"\"\"\n",
    "        if attributes is None:\n",
    "            attributes = [\n",
    "                \"node_id\",\n",
    "                \"node_name\",\n",
    "                \"doi\",\n",
    "                \"year\",\n",
    "                \"title\",\n",
    "                \"cluster\",\n",
    "                \"centrality\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "\n",
    "        # Fix encoding of titles\n",
    "        g.vs[\"title\"] = [NodesSaver.fix_encoding(title) for title in g.vs[\"title\"]]\n",
    "\n",
    "        nodes_json = []\n",
    "        for node in g.vs:\n",
    "            if not all(attr in node.attributes() for attr in attributes):\n",
    "                raise ValueError(f\"Missing attribute in node: {node.attributes()}\")\n",
    "            node_dict = {attr: node[attr] for attr in attributes}\n",
    "            nodes_json.append(node_dict)\n",
    "\n",
    "        # Convert single path to list for consistent processing\n",
    "        if isinstance(paths, str):\n",
    "            paths = [paths]\n",
    "\n",
    "        # Save to all specified paths\n",
    "        for path in paths:\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(nodes_json, f)\n",
    "            print(f\"Graph nodes saved to {path}\")\n",
    "\n",
    "        return nodes_json if return_json else None\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_encoding(title: str) -> str:\n",
    "        \"\"\"\n",
    "        Fix the encoding of a string.\n",
    "        Args:\n",
    "            title (str): The input string to fix.\n",
    "        Returns:\n",
    "            str: The fixed string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            decoded_title = title.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            return decoded_title.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except UnicodeEncodeError:\n",
    "            # If the above method fails, return the original title\n",
    "            return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationUtility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationUtility:\n",
    "    @staticmethod\n",
    "    def plot_graph_with_bundled_edges(g, bundled_edges, **kwargs):\n",
    "        \"\"\"\n",
    "        Plot the graph with bundled edges.\n",
    "        Args:\n",
    "        g (igraph.Graph or networkx.Graph): The graph object containing node positions and cluster information.\n",
    "        bundled_edges (pd.DataFrame): DataFrame containing the bundled edge coordinates.\n",
    "        **kwargs: Additional keyword arguments for customizing the plot.\n",
    "            figsize (tuple): Figure size in inches. Default is (10, 10).\n",
    "            node_size (int): Size of the nodes in the scatter plot. Default is 10.\n",
    "            edge_alpha (float): Alpha (transparency) of the edges. Default is 0.2.\n",
    "            edge_width (float): Width of the edge lines. Default is 0.2.\n",
    "            node_alpha (float): Alpha (transparency) of the nodes. Default is 0.7.\n",
    "            edge_color (str): Color of the edges. Default is \"black\".\n",
    "            cmap (str): Colormap for the nodes. Default is \"tab20\".\n",
    "        Returns:\n",
    "        None: Displays the plot.\n",
    "        \"\"\"\n",
    "        # Default values\n",
    "        defaults = {\n",
    "            \"figsize\": (10, 10),\n",
    "            \"node_size\": 10,\n",
    "            \"edge_alpha\": 0.2,\n",
    "            \"edge_width\": 0.2,\n",
    "            \"node_alpha\": 0.7,\n",
    "            \"edge_color\": \"black\",\n",
    "            \"cmap\": \"tab20\",\n",
    "        }\n",
    "        # transform the graph if not igraph\n",
    "        if not isinstance(g, ig.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "            print(\"Converted to igraph Graph\")\n",
    "\n",
    "        # Update defaults with any provided kwargs\n",
    "        defaults.update(kwargs)\n",
    "\n",
    "        plt.figure(figsize=defaults[\"figsize\"])\n",
    "\n",
    "        # Plot edges\n",
    "        plt.plot(\n",
    "            bundled_edges[\"x\"],\n",
    "            bundled_edges[\"y\"],\n",
    "            color=defaults[\"edge_color\"],\n",
    "            alpha=defaults[\"edge_alpha\"],\n",
    "            linewidth=defaults[\"edge_width\"],\n",
    "        )\n",
    "\n",
    "        # Get unique clusters and map them to consecutive integers\n",
    "        unique_clusters = sorted(set(g.vs[\"cluster\"]))\n",
    "        cluster_map = {c: i for i, c in enumerate(unique_clusters)}\n",
    "\n",
    "        # Map cluster values to consecutive integers\n",
    "        cluster_colors = [cluster_map[c] for c in g.vs[\"cluster\"]]\n",
    "\n",
    "        # Create a custom colormap\n",
    "        cmap = plt.get_cmap(defaults[\"cmap\"])\n",
    "        n_colors = len(unique_clusters)\n",
    "        custom_cmap = cmap(np.linspace(0, 1, n_colors))\n",
    "\n",
    "        # Plot nodes\n",
    "        scatter = plt.scatter(\n",
    "            g.vs[\"x\"],\n",
    "            g.vs[\"y\"],\n",
    "            s=defaults[\"node_size\"],\n",
    "            c=cluster_colors,\n",
    "            cmap=cmap,\n",
    "            alpha=defaults[\"node_alpha\"],\n",
    "        )\n",
    "\n",
    "        # Add a colorbar\n",
    "        # plt.colorbar(scatter, label=\"Cluster\", ticks=range(len(unique_clusters)))\n",
    "        # plt.clim(-0.5, len(unique_clusters) - 0.5)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # Draw the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL RUN\n",
    "\n",
    "1. read graph\n",
    "2. layout\n",
    "3. prune edges\n",
    "4. bundle edges\n",
    "5. visualize\n",
    "6. adjust for 3d plotting\n",
    "   1. add z coordinate to nodes\n",
    "   2. add z coordinate to bundled edges\n",
    "7. use extra 3d bundling step\n",
    "8. save nodes and edges for 3d plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/zjbwrdgj0bg9zyhx3l7134mm0000gn/T/ipykernel_7094/1447177093.py:4: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute. at src/io/graphml.c:488\n",
      "  g = ig.Graph.Read_GraphML(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Attributes: ['doi', 'year', 'title', 'cluster', 'node_id', 'node_name', 'centrality']\n",
      "Edge Attributes: ['weight', 'edge_id']\n",
      "Number of nodes: 40643\n",
      "Number of edges: 602779\n",
      "Starting Fruchterman-Reingold layout process...\n",
      "Layout parameters: {'iterations': 20, 'threshold': 0.0001, 'weight': 'weight', 'scale': 1, 'center': (0, 0), 'dim': 2, 'seed': 1887}\n",
      "Converting to NetworkX Graph...\n",
      "Conversion complete.\n",
      "Graph has 12292 nodes and 132380 edges.\n",
      "Calculating layout...\n",
      "Layout calculation completed in 101.01 seconds.\n",
      "Processing layout results...\n",
      "Layout boundaries:\n",
      "X-axis: Min = -1.00, Max = 0.90\n",
      "Y-axis: Min = -0.99, Max = 0.82\n",
      "Assigning coordinates to nodes...\n",
      "Layout process completed in 101.49 seconds.\n",
      "####################################################################################################\n",
      "Layout done\n",
      "####################################################################################################\n",
      "Bounds of the layout:\n",
      "Min x: -1.0, Max x: 0.8989654779434204\n",
      "Min y: -0.9858399033546448, Max y: 0.8221459984779358\n",
      "Description of the Z coordinate values:\n",
      "count    12292.000000\n",
      "mean        -0.101998\n",
      "std          0.046564\n",
      "min         -0.150000\n",
      "25%         -0.134855\n",
      "50%         -0.115466\n",
      "75%         -0.084148\n",
      "max          0.150000\n",
      "dtype: float64\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Pruning edges by weight percentile: 75%\n",
      "--------------------\n",
      "Number of edges before: 132380\n",
      "Number of edges after: 33095\n",
      "Number of isolates before: 0\n",
      "Number of isolates after: 2262\n",
      "Starting edge bundling process...\n",
      "####################################################################################################\n",
      "Edge bundling done\n",
      "####################################################################################################\n",
      "Initial Z Coordinates added to edges\n",
      "####################################################################################################\n",
      "Z interpolation done\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "g = GraphReader.read_and_clean_graph(INPUT_GRAPH_PATH)\n",
    "\n",
    "cluster_list = list(range(40, 51))\n",
    "\n",
    "# subset to only cluster 0 to 100\n",
    "g = GraphReader.subgraph_of_clusters(g, cluster_list)\n",
    "\n",
    "total_nodes = len(g.vs)\n",
    "################################################################################################\n",
    "layout_params = {\n",
    "    # \"k\": 0.5, # distance between nodes; best to leave it to algo\n",
    "    \"iterations\": 20,  # (default=50) use 100\n",
    "    \"threshold\": 0.0001,  # default 0.0001\n",
    "    \"weight\": \"weight\",\n",
    "    \"scale\": 1,\n",
    "    \"center\": (0, 0),\n",
    "    \"dim\": 2,\n",
    "    \"seed\": 1887,\n",
    "}\n",
    "\n",
    "g_fr, pos = LayoutUtility.fr_layout_nx(g, layout_params)\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Layout done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "g_fr_z = ZCoordinateAdder(g_fr, scale_factor=0.15).add_z_coordinate_to_nodes()\n",
    "print(\"#\" * 100)\n",
    "print(\"Z coordinate added to nodes\")\n",
    "print(\"#\" * 100)\n",
    "################################################################################################\n",
    "bundle_kwargs = {\n",
    "    \"decay\": 0.90,\n",
    "    \"initial_bandwidth\": 0.10,\n",
    "    \"iterations\": 15,\n",
    "    \"include_edge_id\": True,\n",
    "}\n",
    "\n",
    "bundler = GraphBundler2d(\n",
    "    g_fr_z, pruning_weight_percentile=75, bundle_kwargs=bundle_kwargs\n",
    ")\n",
    "pruned_bundled_edges_2d, g_fr_z_bundled_pruned = bundler.bundle_edges()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Edge bundling done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "# if total_nodes < 5000:\n",
    "#    VisualizationUtility.plot_graph_with_bundled_edges(\n",
    "#        g_fr_z_bundled_pruned, pruned_bundled_edges_2d\n",
    "#    )\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "interpolator = EdgeZInterpolator(pruned_bundled_edges_2d, g_fr_z_bundled_pruned)\n",
    "adjusted_edges_3d = interpolator.interpolate_z_to_edges()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Z interpolation done\")\n",
    "print(\"#\" * 100)\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>weight</th>\n",
       "      <th>source_position</th>\n",
       "      <th>target_position</th>\n",
       "      <th>interpolated_x</th>\n",
       "      <th>interpolated_y</th>\n",
       "      <th>interpolated_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3307619094848633, 0.34947332739830017]</td>\n",
       "      <td>[0.19845418632030487, 0.30729520320892334]</td>\n",
       "      <td>0.663864</td>\n",
       "      <td>{'x': 0.3307619094848633, 'y': 0.1984541863203...</td>\n",
       "      <td>{'x': 0.34947332739830017, 'y': 0.307295203208...</td>\n",
       "      <td>[0.3307619094848633, 0.34947332739830017]</td>\n",
       "      <td>[0.19845418632030487, 0.30729520320892334]</td>\n",
       "      <td>[-0.13823016870468868, -0.1340834649785878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>[-0.4124625027179718, -0.39503922612022846, -0...</td>\n",
       "      <td>[-0.4567071497440338, -0.40076967835872734, -0...</td>\n",
       "      <td>0.806230</td>\n",
       "      <td>{'x': -0.4124625027179718, 'y': -0.45670714974...</td>\n",
       "      <td>{'x': -0.36125415563583374, 'y': -0.4384048879...</td>\n",
       "      <td>[-0.4124625027179718, -0.39503922612022846, -0...</td>\n",
       "      <td>[-0.4567071497440338, -0.40076967835872734, -0...</td>\n",
       "      <td>[-0.1310213731838211, -0.13087355803861248, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  source  target                                                  x  \\\n",
       "0     50.0       0       1          [0.3307619094848633, 0.34947332739830017]   \n",
       "1    102.0       2      35  [-0.4124625027179718, -0.39503922612022846, -0...   \n",
       "\n",
       "                                                   y    weight  \\\n",
       "0         [0.19845418632030487, 0.30729520320892334]  0.663864   \n",
       "1  [-0.4567071497440338, -0.40076967835872734, -0...  0.806230   \n",
       "\n",
       "                                     source_position  \\\n",
       "0  {'x': 0.3307619094848633, 'y': 0.1984541863203...   \n",
       "1  {'x': -0.4124625027179718, 'y': -0.45670714974...   \n",
       "\n",
       "                                     target_position  \\\n",
       "0  {'x': 0.34947332739830017, 'y': 0.307295203208...   \n",
       "1  {'x': -0.36125415563583374, 'y': -0.4384048879...   \n",
       "\n",
       "                                      interpolated_x  \\\n",
       "0          [0.3307619094848633, 0.34947332739830017]   \n",
       "1  [-0.4124625027179718, -0.39503922612022846, -0...   \n",
       "\n",
       "                                      interpolated_y  \\\n",
       "0         [0.19845418632030487, 0.30729520320892334]   \n",
       "1  [-0.4567071497440338, -0.40076967835872734, -0...   \n",
       "\n",
       "                                      interpolated_z  \n",
       "0        [-0.13823016870468868, -0.1340834649785878]  \n",
       "1  [-0.1310213731838211, -0.13087355803861248, -0...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_edges_3d.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D edge bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 14:49:36,102 - INFO - Diagonal of bounding box: 2.6338850009501926\n",
      "2024-07-24 14:49:36,102 - INFO - Adjusted percentage: 0.031992\n",
      "2024-07-24 14:49:36,102 - INFO - Inferred radius: 0.016853\n",
      "2024-07-24 14:49:36,103 - INFO - Inferred neighbor radius: 0.0169\n",
      "2024-07-24 14:50:20,344 - INFO - Starting 3D edge bundling with 10 iterations\n",
      "2024-07-24 14:50:20,349 - INFO - Using 4 CPU cores for parallel processing\n",
      "3D Bundling Progress:   0%|          | 0/10 [00:00<?, ?it/s]2024-07-24 14:51:08,626 - INFO - Iteration 1/10 completed in 48.19s\n",
      "3D Bundling Progress:  10%|         | 1/10 [00:48<07:13, 48.19s/it]2024-07-24 14:51:40,528 - INFO - Iteration 2/10 completed in 31.90s\n",
      "3D Bundling Progress:  20%|        | 2/10 [01:20<05:08, 38.61s/it]2024-07-24 14:52:17,253 - INFO - Iteration 3/10 completed in 36.72s\n",
      "3D Bundling Progress:  30%|       | 3/10 [01:56<04:24, 37.75s/it]2024-07-24 14:52:52,526 - INFO - Iteration 4/10 completed in 35.27s\n",
      "3D Bundling Progress:  40%|      | 4/10 [02:32<03:40, 36.77s/it]2024-07-24 14:53:30,307 - INFO - Iteration 5/10 completed in 37.78s\n",
      "3D Bundling Progress:  50%|     | 5/10 [03:09<03:05, 37.14s/it]2024-07-24 14:54:09,285 - INFO - Iteration 6/10 completed in 38.98s\n",
      "3D Bundling Progress:  60%|    | 6/10 [03:48<02:31, 37.76s/it]2024-07-24 14:54:46,617 - INFO - Iteration 7/10 completed in 37.33s\n",
      "3D Bundling Progress:  70%|   | 7/10 [04:26<01:52, 37.62s/it]2024-07-24 14:55:26,286 - INFO - Iteration 8/10 completed in 39.67s\n",
      "3D Bundling Progress:  80%|  | 8/10 [05:05<01:16, 38.27s/it]2024-07-24 14:56:04,626 - INFO - Iteration 9/10 completed in 38.34s\n",
      "3D Bundling Progress:  90%| | 9/10 [05:44<00:38, 38.29s/it]2024-07-24 14:56:43,791 - INFO - Iteration 10/10 completed in 39.16s\n",
      "3D Bundling Progress: 100%|| 10/10 [06:23<00:00, 38.34s/it]\n",
      "2024-07-24 14:56:44,722 - INFO - 3D edge bundling applied successfully\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "params = {\n",
    "    \"bundling_iterations\": 10,\n",
    "    \"step_size\": 0.3,\n",
    "    \"compatibility_threshold\": 0.6,\n",
    "    \"smoothing_iterations\": 5,\n",
    "    \"neighbor_radius\": \"auto\",\n",
    "    \"radius_multiplier\": 0.2,\n",
    "}\n",
    "\n",
    "try:\n",
    "    bundler_3d = Apply3DEdgeBundling(adjusted_edges_3d, **params)\n",
    "    bundler_3d.apply_3d_bundling()\n",
    "    bundled_edges_3d = bundler_3d.get_bundled_edges()\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during 3D bundling: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes saved to ../data/99-testdata/nodes_3d_clusters45to50.json\n",
      "Graph nodes saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/nodes_3d_clusters45to50.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'node_id': 6,\n",
       "  'node_name': 'Horita_1982',\n",
       "  'doi': '',\n",
       "  'year': 1982,\n",
       "  'title': 'Centrally administered thyrotropin-releasing hormone (TRH) stimulates colonic transit and diarrhea production by a vagally mediated serotonergic mechanism in the rabbit',\n",
       "  'cluster': 48,\n",
       "  'centrality': 0.136328538692653,\n",
       "  'x': 0.6405702233314514,\n",
       "  'y': -0.3191435635089874,\n",
       "  'z': -0.10927152627688637},\n",
       " {'node_id': 8,\n",
       "  'node_name': 'Mcelroy_1982',\n",
       "  'doi': '10.1007/BF00432770',\n",
       "  'year': 1982,\n",
       "  'title': 'The effects of fenfluramine and fluoxetine on the acquisition of a conditioned avoidance response in rats',\n",
       "  'cluster': 50,\n",
       "  'centrality': 0.0151485334617365,\n",
       "  'x': 0.5508721470832825,\n",
       "  'y': -0.4072713851928711,\n",
       "  'z': -0.14564939253508402}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to multiple paths\n",
    "nodes_json = NodesSaver.save_igraph_nodes_to_json(\n",
    "    g_fr_z_bundled_pruned,\n",
    "    [\n",
    "        OUTPUT_DIR + f\"nodes_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "        THREEJS_OUTPUT_DIR\n",
    "        + f\"nodes_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "    ],\n",
    "    return_json=True,\n",
    ")\n",
    "\n",
    "# print first 2 nodes\n",
    "nodes_json[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31719 out of 33095 edges have the same source and target cluster.\n",
      "No edges with NaN values found.\n",
      "Edges data saved to ../data/99-testdata/bundled_edges_3d_clusters20to50.json\n",
      "Edges data saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/bundled_edges_3d_clusters20to50.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 9282,\n",
       " 'source': 55,\n",
       " 'target': 628,\n",
       " 'weight': 0.809315085411072,\n",
       " 'colored': True,\n",
       " 'points': [{'x': 0.1797104785509199,\n",
       "   'y': 0.08640227269980194,\n",
       "   'z': -0.11921884171978157},\n",
       "  {'x': 0.16762777694242395,\n",
       "   'y': 0.07244703881857949,\n",
       "   'z': -0.13564365842741866},\n",
       "  {'x': 0.15903036949242866,\n",
       "   'y': 0.06342433086241353,\n",
       "   'z': -0.15484917390021652},\n",
       "  {'x': 0.15385792925439534,\n",
       "   'y': 0.061205861293863566,\n",
       "   'z': -0.1751324490140186},\n",
       "  {'x': 0.15009907378869408,\n",
       "   'y': 0.0664796134829248,\n",
       "   'z': -0.19236211035300899},\n",
       "  {'x': 0.14717861149056716,\n",
       "   'y': 0.08213241384961667,\n",
       "   'z': -0.20430724700450514},\n",
       "  {'x': 0.14578842711877277,\n",
       "   'y': 0.11159344556639125,\n",
       "   'z': -0.21088572610528544},\n",
       "  {'x': 0.14567282979197266,\n",
       "   'y': 0.1536696058033668,\n",
       "   'z': -0.21200172298069808},\n",
       "  {'x': 0.14628638132851618,\n",
       "   'y': 0.20140796591181168,\n",
       "   'z': -0.20667695328035182},\n",
       "  {'x': 0.1497297300315264,\n",
       "   'y': 0.24635118507521314,\n",
       "   'z': -0.19244827127885808},\n",
       "  {'x': 0.1593874292613393,\n",
       "   'y': 0.28275504415248437,\n",
       "   'z': -0.16538766901774926},\n",
       "  {'x': 0.17315561984919137,\n",
       "   'y': 0.3090027404194538,\n",
       "   'z': -0.12421575389144071},\n",
       "  {'x': 0.18265914109401207,\n",
       "   'y': 0.3271504336430806,\n",
       "   'z': -0.07393787357265579},\n",
       "  {'x': 0.18439027707174369,\n",
       "   'y': 0.341160378705217,\n",
       "   'z': -0.021112383424593734}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_json = EdgesSaver.save_edges_for_js(\n",
    "    bundled_edges_3d,\n",
    "    [\n",
    "        OUTPUT_DIR\n",
    "        + f\"bundled_edges_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "        THREEJS_OUTPUT_DIR\n",
    "        + f\"bundled_edges_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "    ],\n",
    "    add_color_bool=True,\n",
    "    g=g_fr_z_bundled_pruned,\n",
    "    return_json=True,\n",
    ")\n",
    "\n",
    "edges_json[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAILED QUALITY CHECK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_int:  33095\n",
      "false_int:  0\n",
      "correct_bund:  5810\n",
      "false_bund:  27285\n",
      "correct_both:  5810\n",
      "false_both:  27285\n"
     ]
    }
   ],
   "source": [
    "correct_int = 0\n",
    "false_int = 0\n",
    "correct_bund = 0\n",
    "false_bund = 0\n",
    "correct_both = 0\n",
    "false_both = 0\n",
    "for i, row in bundled_edges_3d.iterrows():\n",
    "    s_x = round(row[\"source_position\"][\"x\"], 7)\n",
    "    x_int = round(row[\"interpolated_x\"][0], 7)\n",
    "    x_bund = round(row[\"bundled_x\"][0], 7)\n",
    "    s_y = round(row[\"source_position\"][\"y\"], 7)\n",
    "    y_int = round(row[\"interpolated_y\"][0], 7)\n",
    "    y_bund = round(row[\"bundled_y\"][0], 7)\n",
    "    s_z = round(row[\"source_position\"][\"z\"], 7)\n",
    "    z_int = round(row[\"interpolated_z\"][0], 7)\n",
    "    z_bund = round(row[\"bundled_z\"][0], 7)\n",
    "\n",
    "    if s_x == x_int and s_y == y_int and s_z == z_int:\n",
    "        correct_int += 1\n",
    "    else:\n",
    "        false_int += 1\n",
    "\n",
    "    if s_x == x_bund and s_y == y_bund and s_z == z_bund:\n",
    "        correct_bund += 1\n",
    "    else:\n",
    "        false_bund += 1\n",
    "\n",
    "    if (\n",
    "        s_x == x_int\n",
    "        and s_y == y_int\n",
    "        and s_z == z_int\n",
    "        and s_x == x_bund\n",
    "        and s_y == y_bund\n",
    "        and s_z == z_bund\n",
    "    ):\n",
    "        correct_both += 1\n",
    "    else:\n",
    "        false_both += 1\n",
    "\n",
    "\n",
    "print(\"correct_int: \", correct_int)\n",
    "print(\"false_int: \", false_int)\n",
    "\n",
    "print(\"correct_bund: \", correct_bund)\n",
    "print(\"false_bund: \", false_bund)\n",
    "\n",
    "print(\"correct_both: \", correct_both)\n",
    "print(\"false_both: \", false_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/zjbwrdgj0bg9zyhx3l7134mm0000gn/T/ipykernel_7094/1447177093.py:4: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute. at src/io/graphml.c:488\n",
      "  g = ig.Graph.Read_GraphML(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Attributes: ['doi', 'year', 'title', 'cluster', 'node_id', 'node_name', 'centrality']\n",
      "Edge Attributes: ['weight', 'edge_id']\n",
      "Number of nodes: 40643\n",
      "Number of edges: 602779\n",
      "Starting Fruchterman-Reingold layout process...\n",
      "Layout parameters: {'iterations': 20, 'threshold': 0.0001, 'weight': 'weight', 'scale': 1, 'center': (0, 0), 'dim': 2, 'seed': 1887}\n",
      "Converting to NetworkX Graph...\n",
      "Conversion complete.\n",
      "Graph has 1976 nodes and 17666 edges.\n",
      "Calculating layout...\n",
      "Layout calculation completed in 4.33 seconds.\n",
      "Processing layout results...\n",
      "Layout boundaries:\n",
      "X-axis: Min = -0.82, Max = 1.00\n",
      "Y-axis: Min = -0.88, Max = 0.80\n",
      "Assigning coordinates to nodes...\n",
      "Layout process completed in 4.39 seconds.\n",
      "####################################################################################################\n",
      "Layout done\n",
      "####################################################################################################\n",
      "Bounds of the layout:\n",
      "Min x: -0.819740355014801, Max x: 1.0\n",
      "Min y: -0.8823116421699524, Max y: 0.8033565878868103\n",
      "Description of the Z coordinate values:\n",
      "count    1976.000000\n",
      "mean       -0.103390\n",
      "std         0.049373\n",
      "min        -0.150000\n",
      "25%        -0.138779\n",
      "50%        -0.120002\n",
      "75%        -0.084551\n",
      "max         0.150000\n",
      "dtype: float64\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Pruning edges by weight percentile: 75%\n",
      "--------------------\n",
      "Number of edges before: 17666\n",
      "Number of edges after: 4417\n",
      "Number of isolates before: 0\n",
      "Number of isolates after: 399\n",
      "Starting edge bundling process...\n",
      "####################################################################################################\n",
      "Edge bundling done\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "g = GraphReader.read_and_clean_graph(INPUT_GRAPH_PATH)\n",
    "\n",
    "cluster_list = list(range(45, 51))\n",
    "\n",
    "# subset to only cluster 0 to 100\n",
    "g = GraphReader.subgraph_of_clusters(g, cluster_list)\n",
    "\n",
    "total_nodes = len(g.vs)\n",
    "################################################################################################\n",
    "layout_params = {\n",
    "    # \"k\": 0.5, # distance between nodes; best to leave it to algo\n",
    "    \"iterations\": 20,  # (default=50) use 100\n",
    "    \"threshold\": 0.0001,  # default 0.0001\n",
    "    \"weight\": \"weight\",\n",
    "    \"scale\": 1,\n",
    "    \"center\": (0, 0),\n",
    "    \"dim\": 2,\n",
    "    \"seed\": 1887,\n",
    "}\n",
    "\n",
    "g_fr, pos = LayoutUtility.fr_layout_nx(g, layout_params)\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Layout done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "g_fr_z = ZCoordinateAdder(g_fr, scale_factor=0.15).add_z_coordinate_to_nodes()\n",
    "print(\"#\" * 100)\n",
    "print(\"Z coordinate added to nodes\")\n",
    "print(\"#\" * 100)\n",
    "################################################################################################\n",
    "\n",
    "bundle_kwargs = {\n",
    "    \"decay\": 0.95,\n",
    "    \"initial_bandwidth\": 0.05,\n",
    "    \"iterations\": 50,\n",
    "    \"include_edge_id\": True,\n",
    "}\n",
    "bundler = GraphBundler2d(\n",
    "    g_fr_z, pruning_weight_percentile=75, bundle_kwargs=bundle_kwargs\n",
    ")\n",
    "pruned_bundled_edges_2d, g_fr_z_bundled_pruned = bundler.bundle_edges()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Edge bundling done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "# if total_nodes < 5000:\n",
    "#    VisualizationUtility.plot_graph_with_bundled_edges(\n",
    "#        g_fr_z_bundled_pruned, pruned_bundled_edges_2d\n",
    "#    )\n",
    "\n",
    "################################################################################################\n",
    "#\n",
    "#\n",
    "# interpolator = EdgeZInterpolator(pruned_bundled_edges_2d, g_fr_z_bundled_pruned)\n",
    "# adjusted_edges_3d = interpolator.interpolate_z_to_edges()\n",
    "#\n",
    "# print(\"#\" * 100)\n",
    "# print(\"Z interpolation done\")\n",
    "# print(\"#\" * 100)\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>weight</th>\n",
       "      <th>source_position</th>\n",
       "      <th>target_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>[0.5508721470832825, 0.55393686033313, 0.55205...</td>\n",
       "      <td>[-0.4072713851928711, -0.3896731439439783, -0....</td>\n",
       "      <td>0.936576</td>\n",
       "      <td>{'x': 0.5508721470832825, 'y': -0.407271385192...</td>\n",
       "      <td>{'x': 0.445087194442749, 'y': -0.2985744476318...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  source  target                                                  x  \\\n",
       "0    149.0       1     280  [0.5508721470832825, 0.55393686033313, 0.55205...   \n",
       "\n",
       "                                                   y    weight  \\\n",
       "0  [-0.4072713851928711, -0.3896731439439783, -0....  0.936576   \n",
       "\n",
       "                                     source_position  \\\n",
       "0  {'x': 0.5508721470832825, 'y': -0.407271385192...   \n",
       "\n",
       "                                     target_position  \n",
       "0  {'x': 0.445087194442749, 'y': -0.2985744476318...  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_bundled_edges_2d.head(1)  # , g_fr_z_bundled_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.145649\n",
       "1      -0.144170\n",
       "2      -0.120307\n",
       "3      -0.120307\n",
       "4      -0.120307\n",
       "          ...   \n",
       "4412   -0.130054\n",
       "4413   -0.034908\n",
       "4414   -0.034908\n",
       "4415   -0.000343\n",
       "4416   -0.090827\n",
       "Name: source_position, Length: 4417, dtype: float64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_bundled_edges_2d.source_position.apply(lambda x: x[\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class BundleQualityChecker:\n",
    "    @staticmethod\n",
    "    def connection_quality_check(\n",
    "        df,\n",
    "        source_col=\"source_position\",\n",
    "        target_col=\"target_position\",\n",
    "        x_col=\"x\",\n",
    "        y_col=\"y\",\n",
    "        z_col=\"z\",\n",
    "        tolerance=1e-6,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform quality checks on the bundled edges, accounting for positive and negative coordinates.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): The dataframe containing edge data\n",
    "        source_col (str): Name of the column containing source node positions\n",
    "        target_col (str): Name of the column containing target node positions\n",
    "        x_col (str): Name of the column containing bundled x coordinates\n",
    "        y_col (str): Name of the column containing bundled y coordinates\n",
    "        z_col (str): Name of the column containing bundled z coordinates\n",
    "        tolerance (float): Tolerance for floating point comparisons\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary containing the results of various checks\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"total_edges\": len(df),\n",
    "            \"start_point_mismatches\": 0,\n",
    "            \"end_point_mismatches\": 0,\n",
    "            \"invalid_z_interpolations\": 0,\n",
    "            \"high_z_connection_count\": df[\"is_high_z_connection\"].sum(),\n",
    "        }\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            # Check start point\n",
    "            if (\n",
    "                abs(row[x_col][0] - row[source_col][\"x\"]) > tolerance\n",
    "                or abs(row[y_col][0] - row[source_col][\"y\"]) > tolerance\n",
    "                or abs(row[z_col][0] - row[source_col][\"z\"]) > tolerance\n",
    "            ):\n",
    "                results[\"start_point_mismatches\"] += 1\n",
    "\n",
    "            # Check end point\n",
    "            if (\n",
    "                abs(row[x_col][-1] - row[target_col][\"x\"]) > tolerance\n",
    "                or abs(row[y_col][-1] - row[target_col][\"y\"]) > tolerance\n",
    "                or abs(row[z_col][-1] - row[target_col][\"z\"]) > tolerance\n",
    "            ):\n",
    "                results[\"end_point_mismatches\"] += 1\n",
    "\n",
    "            # Check z interpolation\n",
    "            z_min, z_max = min(row[source_col][\"z\"], row[target_col][\"z\"]), max(\n",
    "                row[source_col][\"z\"], row[target_col][\"z\"]\n",
    "            )\n",
    "            if any(z < z_min - tolerance or z > z_max + tolerance for z in row[z_col]):\n",
    "                results[\"invalid_z_interpolations\"] += 1\n",
    "\n",
    "        # Calculate percentages\n",
    "        total = results[\"total_edges\"]\n",
    "        results[\"start_point_mismatch_percentage\"] = (\n",
    "            results[\"start_point_mismatches\"] / total\n",
    "        ) * 100\n",
    "        results[\"end_point_mismatch_percentage\"] = (\n",
    "            results[\"end_point_mismatches\"] / total\n",
    "        ) * 100\n",
    "        results[\"invalid_z_interpolation_percentage\"] = (\n",
    "            results[\"invalid_z_interpolations\"] / total\n",
    "        ) * 100\n",
    "        results[\"high_z_connection_percentage\"] = (\n",
    "            results[\"high_z_connection_count\"] / total\n",
    "        ) * 100\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def perform_quality_check(bundled_edges_3d):\n",
    "        if bundled_edges_3d is None:\n",
    "            print(\"No bundled edges available.\")\n",
    "            return None\n",
    "\n",
    "        results = BundleQualityChecker.connection_quality_check(bundled_edges_3d)\n",
    "\n",
    "        print(\"Quality Check Results:\")\n",
    "        print(f\"Total edges: {results['total_edges']}\")\n",
    "        print(\n",
    "            f\"Start point mismatches: {results['start_point_mismatches']} ({results['start_point_mismatch_percentage']:.2f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"End point mismatches: {results['end_point_mismatches']} ({results['end_point_mismatch_percentage']:.2f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Invalid z interpolations: {results['invalid_z_interpolations']} ({results['invalid_z_interpolation_percentage']:.2f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"High z connections: {results['high_z_connection_count']} ({results['high_z_connection_percentage']:.2f}%)\"\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_edge_points(bundled_edges_3d):\n",
    "        if bundled_edges_3d is None:\n",
    "            print(\"No bundled edges available. Run adjust_bundling_for_3d first.\")\n",
    "            return None\n",
    "\n",
    "        point_counts = bundled_edges_3d[\"x\"].apply(len)\n",
    "\n",
    "        analysis = {\n",
    "            \"min_points\": point_counts.min(),\n",
    "            \"max_points\": point_counts.max(),\n",
    "            \"mean_points\": point_counts.mean(),\n",
    "            \"median_points\": point_counts.median(),\n",
    "        }\n",
    "\n",
    "        print(\"Edge Point Analysis:\")\n",
    "        print(f\"Minimum points per edge: {analysis['min_points']}\")\n",
    "        print(f\"Maximum points per edge: {analysis['max_points']}\")\n",
    "        print(f\"Mean points per edge: {analysis['mean_points']:.2f}\")\n",
    "        print(f\"Median points per edge: {analysis['median_points']}\")\n",
    "\n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeBundler3d:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bundled_edges_2d,\n",
    "        z_threshold_percentile=75,\n",
    "        vertical_influence=0.8,\n",
    "    ):\n",
    "        self.bundled_edges_2d = bundled_edges_2d\n",
    "        self.z_threshold_percentile = z_threshold_percentile\n",
    "        self.vertical_influence = vertical_influence\n",
    "        self.bundled_edges_3d = None\n",
    "\n",
    "    def define_z_threshold(self, z_values):\n",
    "        z_threshold = np.percentile(z_values, self.z_threshold_percentile)\n",
    "        print(f\"Z threshold set to {z_threshold:.4f}\")\n",
    "        return z_threshold\n",
    "\n",
    "    def adjust_bundling_for_3d(self):\n",
    "        z_values = pd.concat(\n",
    "            [\n",
    "                self.bundled_edges_2d.source_position.apply(lambda x: x[\"z\"]),\n",
    "                self.bundled_edges_2d.target_position.apply(lambda x: x[\"z\"]),\n",
    "            ]\n",
    "        )\n",
    "        z_threshold = self.define_z_threshold(z_values)\n",
    "\n",
    "        adjusted_edges = []\n",
    "        for _, row in tqdm(\n",
    "            self.bundled_edges_2d.iterrows(), total=len(self.bundled_edges_2d)\n",
    "        ):\n",
    "            edge_id = row[\"edge_id\"]\n",
    "            source = row[\"source_position\"]\n",
    "            target = row[\"target_position\"]\n",
    "            source_z = source[\"z\"]\n",
    "            target_z = target[\"z\"]\n",
    "            x = np.array(row[\"x\"])\n",
    "            y = np.array(row[\"y\"])\n",
    "\n",
    "            num_points = len(x)\n",
    "            is_high_z_connection = (source_z > z_threshold and source_z > target_z) or (\n",
    "                target_z > z_threshold and target_z > source_z\n",
    "            )\n",
    "\n",
    "            # Determine high and low nodes\n",
    "            if source_z > target_z:\n",
    "                high_node, low_node = source, target\n",
    "            else:\n",
    "                high_node, low_node = target, source\n",
    "\n",
    "            # Create control points for cubic spline\n",
    "            if is_high_z_connection:\n",
    "                # For high-z connections, create a smooth vertical path\n",
    "                mid_x = (source[\"x\"] + target[\"x\"]) / 2\n",
    "                mid_y = (source[\"y\"] + target[\"y\"]) / 2\n",
    "                control_points_t = [0, 0.25, 0.75, 1]\n",
    "                control_points_x = [source[\"x\"], mid_x, mid_x, target[\"x\"]]\n",
    "                control_points_y = [source[\"y\"], mid_y, mid_y, target[\"y\"]]\n",
    "            else:\n",
    "                # For non-high-z connections, use more of the original path\n",
    "                control_points_t = [0, 1 / 3, 2 / 3, 1]\n",
    "                control_points_x = [\n",
    "                    source[\"x\"],\n",
    "                    x[num_points // 3],\n",
    "                    x[2 * num_points // 3],\n",
    "                    target[\"x\"],\n",
    "                ]\n",
    "                control_points_y = [\n",
    "                    source[\"y\"],\n",
    "                    y[num_points // 3],\n",
    "                    y[2 * num_points // 3],\n",
    "                    target[\"y\"],\n",
    "                ]\n",
    "\n",
    "            # Apply cubic spline interpolation with natural boundary conditions\n",
    "            cs_x = CubicSpline(control_points_t, control_points_x, bc_type=\"natural\")\n",
    "            cs_y = CubicSpline(control_points_t, control_points_y, bc_type=\"natural\")\n",
    "\n",
    "            # Use the original number of points, but ensure it's at least 20 for smoother curves\n",
    "            t = np.linspace(0, 1, num_points)\n",
    "            x_adj = cs_x(t)\n",
    "            y_adj = cs_y(t)\n",
    "\n",
    "            # Create a smooth z-coordinate transition\n",
    "\n",
    "            z_min, z_max = min(source_z, target_z), max(source_z, target_z)\n",
    "\n",
    "            if is_high_z_connection:\n",
    "                # For high-z connections, create a more pronounced vertical effect\n",
    "                z_mid = (z_min + z_max) / 2\n",
    "                z_control = [z_min, z_max, z_max, z_max]\n",
    "                cs_z = CubicSpline(control_points_t, z_control, bc_type=\"clamped\")\n",
    "                z = np.clip(cs_z(t), z_min, z_max)\n",
    "            else:\n",
    "                # For non-high-z connections, use linear interpolation\n",
    "                z = np.interp(t, [0, 1], [z_min, z_max])\n",
    "\n",
    "            adjusted_edges.append(\n",
    "                {\n",
    "                    \"edge_id\": edge_id,\n",
    "                    \"bundled_x\": x_adj.tolist(),\n",
    "                    \"bundled_y\": y_adj.tolist(),\n",
    "                    \"bundled_z\": z.tolist(),\n",
    "                    \"is_high_z_connection\": is_high_z_connection,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Create a new dataframe with the adjusted edges\n",
    "        adjusted_df = pd.DataFrame(adjusted_edges)\n",
    "\n",
    "        # Merge the new dataframe with the original one\n",
    "        merged_df = pd.merge(\n",
    "            self.bundled_edges_2d, adjusted_df, on=\"edge_id\", how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Rename columns to avoid confusion\n",
    "        merged_df = merged_df.rename(\n",
    "            columns={\n",
    "                \"x\": \"original_x\",\n",
    "                \"y\": \"original_y\",\n",
    "                \"bundled_x\": \"x\",\n",
    "                \"bundled_y\": \"y\",\n",
    "                \"bundled_z\": \"z\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.bundled_edges_3d = merged_df\n",
    "        return self.bundled_edges_3d\n",
    "\n",
    "    # Add this method to your GraphBundler3d class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z threshold set to -0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4417/4417 [00:01<00:00, 2466.46it/s]\n"
     ]
    }
   ],
   "source": [
    "bundler_3d = EdgeBundler3d(pruned_bundled_edges_2d)\n",
    "adjusted_edges_3d = bundler_3d.adjust_bundling_for_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>original_x</th>\n",
       "      <th>original_y</th>\n",
       "      <th>weight</th>\n",
       "      <th>source_position</th>\n",
       "      <th>target_position</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>is_high_z_connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>[0.5508721470832825, 0.55393686033313, 0.55205...</td>\n",
       "      <td>[-0.4072713851928711, -0.3896731439439783, -0....</td>\n",
       "      <td>0.936576</td>\n",
       "      <td>{'x': 0.5508721470832825, 'y': -0.407271385192...</td>\n",
       "      <td>{'x': 0.445087194442749, 'y': -0.2985744476318...</td>\n",
       "      <td>[0.5508721470832825, 0.5482098857147208, 0.544...</td>\n",
       "      <td>[-0.4072713851928711, -0.38927841208412234, -0...</td>\n",
       "      <td>[-0.1460439847414049, -0.14600811272264846, -0...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.49992355704307556, 0.5130205154418945]</td>\n",
       "      <td>[-0.5801289677619934, -0.6044682264328003]</td>\n",
       "      <td>0.816939</td>\n",
       "      <td>{'x': 0.49992355704307556, 'y': -0.58012896776...</td>\n",
       "      <td>{'x': 0.5130205154418945, 'y': -0.604468226432...</td>\n",
       "      <td>[0.49992355704307556, 0.5130205154418945]</td>\n",
       "      <td>[-0.5801289677619934, -0.6044682264328003]</td>\n",
       "      <td>[-0.1448336408037463, -0.1441700028383177]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>971.0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.5524348020553589, 0.5497690907852348, 0.544...</td>\n",
       "      <td>[-0.34138861298561096, -0.339813561933337, -0....</td>\n",
       "      <td>0.795334</td>\n",
       "      <td>{'x': 0.5524348020553589, 'y': -0.341388612985...</td>\n",
       "      <td>{'x': 0.45631155371665955, 'y': -0.40058809518...</td>\n",
       "      <td>[0.5524348020553589, 0.5496931334538281, 0.545...</td>\n",
       "      <td>[-0.34138861298561096, -0.3414993881606116, -0...</td>\n",
       "      <td>[-0.13980900556810782, -0.13785882390783016, -...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>974.0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>[0.5524348020553589, 0.5585797046720011, 0.566...</td>\n",
       "      <td>[-0.34138861298561096, -0.3394194623550637, -0...</td>\n",
       "      <td>0.806165</td>\n",
       "      <td>{'x': 0.5524348020553589, 'y': -0.341388612985...</td>\n",
       "      <td>{'x': 0.662406861782074, 'y': -0.4320113360881...</td>\n",
       "      <td>[0.5524348020553589, 0.5597469018915837, 0.567...</td>\n",
       "      <td>[-0.34138861298561096, -0.3394893537229342, -0...</td>\n",
       "      <td>[-0.1436823801075662, -0.14108513664731787, -0...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>981.0</td>\n",
       "      <td>3</td>\n",
       "      <td>549</td>\n",
       "      <td>[0.5524348020553589, 0.5483290342278686, 0.541...</td>\n",
       "      <td>[-0.34138861298561096, -0.3477689670685117, -0...</td>\n",
       "      <td>0.792766</td>\n",
       "      <td>{'x': 0.5524348020553589, 'y': -0.341388612985...</td>\n",
       "      <td>{'x': 0.49700018763542175, 'y': -0.46284896135...</td>\n",
       "      <td>[0.5524348020553589, 0.5482820949181224, 0.541...</td>\n",
       "      <td>[-0.34138861298561096, -0.34846635889273353, -...</td>\n",
       "      <td>[-0.12947644557359098, -0.12794823613888104, -...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>601809.0</td>\n",
       "      <td>1931</td>\n",
       "      <td>1970</td>\n",
       "      <td>[-0.34231740236282343, -0.354872689493168, -0....</td>\n",
       "      <td>[-0.21710354089736938, -0.21300441973668005, -...</td>\n",
       "      <td>0.800884</td>\n",
       "      <td>{'x': -0.3423174023628235, 'y': -0.21710354089...</td>\n",
       "      <td>{'x': -0.43638426065444946, 'y': -0.2356306910...</td>\n",
       "      <td>[-0.3423174023628235, -0.35194551355679315, -0...</td>\n",
       "      <td>[-0.21710354089736938, -0.2147058240132259, -0...</td>\n",
       "      <td>[-0.13220869745589156, -0.13190087264187106, -...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>602031.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>1954</td>\n",
       "      <td>[0.5319066643714905, 0.5140461921691895]</td>\n",
       "      <td>[0.2123633772134781, 0.2381635308265686]</td>\n",
       "      <td>0.663164</td>\n",
       "      <td>{'x': 0.5319066643714905, 'y': 0.2123633772134...</td>\n",
       "      <td>{'x': 0.5140461921691895, 'y': 0.2381635308265...</td>\n",
       "      <td>[0.5319066643714905, 0.5140461921691895]</td>\n",
       "      <td>[0.2123633772134781, 0.23816353082656858]</td>\n",
       "      <td>[-0.10930934920714531, -0.034908049376908085]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>602032.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>1975</td>\n",
       "      <td>[0.5319066643714905, 0.5406255788234311, 0.548...</td>\n",
       "      <td>[0.2123633772134781, 0.2014645253000802, 0.191...</td>\n",
       "      <td>0.666620</td>\n",
       "      <td>{'x': 0.5319066643714905, 'y': 0.2123633772134...</td>\n",
       "      <td>{'x': 0.5727753043174744, 'y': 0.3141528069972...</td>\n",
       "      <td>[0.5319066643714905, 0.5406255788234311, 0.548...</td>\n",
       "      <td>[0.2123633772134781, 0.2014645253000802, 0.191...</td>\n",
       "      <td>[-0.10072348897801676, -0.07878500911098053, -...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>602314.0</td>\n",
       "      <td>1949</td>\n",
       "      <td>1959</td>\n",
       "      <td>[0.48814910650253296, 0.46257609128952026]</td>\n",
       "      <td>[-0.20887938141822815, -0.11553271114826202]</td>\n",
       "      <td>0.672519</td>\n",
       "      <td>{'x': 0.48814910650253296, 'y': -0.20887938141...</td>\n",
       "      <td>{'x': 0.46257609128952026, 'y': -0.11553271114...</td>\n",
       "      <td>[0.48814910650253296, 0.46257609128952026]</td>\n",
       "      <td>[-0.20887938141822815, -0.11553271114826202]</td>\n",
       "      <td>[-0.08850872864036753, -0.0003430996737725345]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>602441.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>1974</td>\n",
       "      <td>[-0.46193641424179077, -0.447839639490751, -0....</td>\n",
       "      <td>[0.06866210699081421, 0.06855439568785127, 0.0...</td>\n",
       "      <td>0.679925</td>\n",
       "      <td>{'x': -0.46193641424179077, 'y': 0.06866210699...</td>\n",
       "      <td>{'x': -0.3489552140235901, 'y': 0.085370562970...</td>\n",
       "      <td>[-0.46193641424179077, -0.4517554233585867, -0...</td>\n",
       "      <td>[0.06866210699081421, 0.06933505064025128, 0.0...</td>\n",
       "      <td>[-0.09082706007172069, -0.08741239326902726, -...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4417 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edge_id  source  target  \\\n",
       "0        149.0       1     280   \n",
       "1        271.0       2       7   \n",
       "2        971.0       3      16   \n",
       "3        974.0       3      44   \n",
       "4        981.0       3     549   \n",
       "...        ...     ...     ...   \n",
       "4412  601809.0    1931    1970   \n",
       "4413  602031.0    1936    1954   \n",
       "4414  602032.0    1936    1975   \n",
       "4415  602314.0    1949    1959   \n",
       "4416  602441.0    1953    1974   \n",
       "\n",
       "                                             original_x  \\\n",
       "0     [0.5508721470832825, 0.55393686033313, 0.55205...   \n",
       "1             [0.49992355704307556, 0.5130205154418945]   \n",
       "2     [0.5524348020553589, 0.5497690907852348, 0.544...   \n",
       "3     [0.5524348020553589, 0.5585797046720011, 0.566...   \n",
       "4     [0.5524348020553589, 0.5483290342278686, 0.541...   \n",
       "...                                                 ...   \n",
       "4412  [-0.34231740236282343, -0.354872689493168, -0....   \n",
       "4413           [0.5319066643714905, 0.5140461921691895]   \n",
       "4414  [0.5319066643714905, 0.5406255788234311, 0.548...   \n",
       "4415         [0.48814910650253296, 0.46257609128952026]   \n",
       "4416  [-0.46193641424179077, -0.447839639490751, -0....   \n",
       "\n",
       "                                             original_y    weight  \\\n",
       "0     [-0.4072713851928711, -0.3896731439439783, -0....  0.936576   \n",
       "1            [-0.5801289677619934, -0.6044682264328003]  0.816939   \n",
       "2     [-0.34138861298561096, -0.339813561933337, -0....  0.795334   \n",
       "3     [-0.34138861298561096, -0.3394194623550637, -0...  0.806165   \n",
       "4     [-0.34138861298561096, -0.3477689670685117, -0...  0.792766   \n",
       "...                                                 ...       ...   \n",
       "4412  [-0.21710354089736938, -0.21300441973668005, -...  0.800884   \n",
       "4413           [0.2123633772134781, 0.2381635308265686]  0.663164   \n",
       "4414  [0.2123633772134781, 0.2014645253000802, 0.191...  0.666620   \n",
       "4415       [-0.20887938141822815, -0.11553271114826202]  0.672519   \n",
       "4416  [0.06866210699081421, 0.06855439568785127, 0.0...  0.679925   \n",
       "\n",
       "                                        source_position  \\\n",
       "0     {'x': 0.5508721470832825, 'y': -0.407271385192...   \n",
       "1     {'x': 0.49992355704307556, 'y': -0.58012896776...   \n",
       "2     {'x': 0.5524348020553589, 'y': -0.341388612985...   \n",
       "3     {'x': 0.5524348020553589, 'y': -0.341388612985...   \n",
       "4     {'x': 0.5524348020553589, 'y': -0.341388612985...   \n",
       "...                                                 ...   \n",
       "4412  {'x': -0.3423174023628235, 'y': -0.21710354089...   \n",
       "4413  {'x': 0.5319066643714905, 'y': 0.2123633772134...   \n",
       "4414  {'x': 0.5319066643714905, 'y': 0.2123633772134...   \n",
       "4415  {'x': 0.48814910650253296, 'y': -0.20887938141...   \n",
       "4416  {'x': -0.46193641424179077, 'y': 0.06866210699...   \n",
       "\n",
       "                                        target_position  \\\n",
       "0     {'x': 0.445087194442749, 'y': -0.2985744476318...   \n",
       "1     {'x': 0.5130205154418945, 'y': -0.604468226432...   \n",
       "2     {'x': 0.45631155371665955, 'y': -0.40058809518...   \n",
       "3     {'x': 0.662406861782074, 'y': -0.4320113360881...   \n",
       "4     {'x': 0.49700018763542175, 'y': -0.46284896135...   \n",
       "...                                                 ...   \n",
       "4412  {'x': -0.43638426065444946, 'y': -0.2356306910...   \n",
       "4413  {'x': 0.5140461921691895, 'y': 0.2381635308265...   \n",
       "4414  {'x': 0.5727753043174744, 'y': 0.3141528069972...   \n",
       "4415  {'x': 0.46257609128952026, 'y': -0.11553271114...   \n",
       "4416  {'x': -0.3489552140235901, 'y': 0.085370562970...   \n",
       "\n",
       "                                                      x  \\\n",
       "0     [0.5508721470832825, 0.5482098857147208, 0.544...   \n",
       "1             [0.49992355704307556, 0.5130205154418945]   \n",
       "2     [0.5524348020553589, 0.5496931334538281, 0.545...   \n",
       "3     [0.5524348020553589, 0.5597469018915837, 0.567...   \n",
       "4     [0.5524348020553589, 0.5482820949181224, 0.541...   \n",
       "...                                                 ...   \n",
       "4412  [-0.3423174023628235, -0.35194551355679315, -0...   \n",
       "4413           [0.5319066643714905, 0.5140461921691895]   \n",
       "4414  [0.5319066643714905, 0.5406255788234311, 0.548...   \n",
       "4415         [0.48814910650253296, 0.46257609128952026]   \n",
       "4416  [-0.46193641424179077, -0.4517554233585867, -0...   \n",
       "\n",
       "                                                      y  \\\n",
       "0     [-0.4072713851928711, -0.38927841208412234, -0...   \n",
       "1            [-0.5801289677619934, -0.6044682264328003]   \n",
       "2     [-0.34138861298561096, -0.3414993881606116, -0...   \n",
       "3     [-0.34138861298561096, -0.3394893537229342, -0...   \n",
       "4     [-0.34138861298561096, -0.34846635889273353, -...   \n",
       "...                                                 ...   \n",
       "4412  [-0.21710354089736938, -0.2147058240132259, -0...   \n",
       "4413          [0.2123633772134781, 0.23816353082656858]   \n",
       "4414  [0.2123633772134781, 0.2014645253000802, 0.191...   \n",
       "4415       [-0.20887938141822815, -0.11553271114826202]   \n",
       "4416  [0.06866210699081421, 0.06933505064025128, 0.0...   \n",
       "\n",
       "                                                      z  is_high_z_connection  \n",
       "0     [-0.1460439847414049, -0.14600811272264846, -0...                 False  \n",
       "1            [-0.1448336408037463, -0.1441700028383177]                 False  \n",
       "2     [-0.13980900556810782, -0.13785882390783016, -...                 False  \n",
       "3     [-0.1436823801075662, -0.14108513664731787, -0...                 False  \n",
       "4     [-0.12947644557359098, -0.12794823613888104, -...                 False  \n",
       "...                                                 ...                   ...  \n",
       "4412  [-0.13220869745589156, -0.13190087264187106, -...                 False  \n",
       "4413      [-0.10930934920714531, -0.034908049376908085]                 False  \n",
       "4414  [-0.10072348897801676, -0.07878500911098053, -...                 False  \n",
       "4415     [-0.08850872864036753, -0.0003430996737725345]                  True  \n",
       "4416  [-0.09082706007172069, -0.08741239326902726, -...                 False  \n",
       "\n",
       "[4417 rows x 12 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_edges_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Check Results:\n",
      "Total edges: 4417\n",
      "Start point mismatches: 2500 (56.60%)\n",
      "End point mismatches: 2500 (56.60%)\n",
      "Invalid z interpolations: 0 (0.00%)\n",
      "High z connections: 1744 (39.48%)\n",
      "Edge Point Analysis:\n",
      "Minimum points per edge: 2\n",
      "Maximum points per edge: 75\n",
      "Mean points per edge: 8.30\n",
      "Median points per edge: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_points': 2,\n",
       " 'max_points': 75,\n",
       " 'mean_points': 8.300656554222323,\n",
       " 'median_points': 7.0}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker = BundleQualityChecker()\n",
    "checker.perform_quality_check(adjusted_edges_3d)\n",
    "\n",
    "checker.analyze_edge_points(adjusted_edges_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['edge_id', 'source', 'target', 'original_x', 'original_y', 'weight',\n",
       "       'source_position', 'target_position', 'x', 'y', 'z',\n",
       "       'is_high_z_connection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_edges_3d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_edges_3d\n",
    "\n",
    "test_edge_df = adjusted_edges_3d.copy()\n",
    "test_edge_df[\"x\"] = test_edge_df[\"original_x\"]\n",
    "test_edge_df[\"y\"] = test_edge_df[\"original_y\"]\n",
    "test_edge_df[\"z\"] = test_edge_df[\"original_y\"].apply(lambda x: [1] * len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>original_x</th>\n",
       "      <th>original_y</th>\n",
       "      <th>weight</th>\n",
       "      <th>source_position</th>\n",
       "      <th>target_position</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>is_high_z_connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>[0.5508721470832825, 0.55393686033313, 0.55205...</td>\n",
       "      <td>[-0.4072713851928711, -0.3896731439439783, -0....</td>\n",
       "      <td>0.936576</td>\n",
       "      <td>{'x': 0.5508721470832825, 'y': -0.407271385192...</td>\n",
       "      <td>{'x': 0.445087194442749, 'y': -0.2985744476318...</td>\n",
       "      <td>[0.5508721470832825, 0.5482098857147208, 0.544...</td>\n",
       "      <td>[-0.4072713851928711, -0.38927841208412234, -0...</td>\n",
       "      <td>[-0.1460439847414049, -0.14600811272264846, -0...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.49992355704307556, 0.5130205154418945]</td>\n",
       "      <td>[-0.5801289677619934, -0.6044682264328003]</td>\n",
       "      <td>0.816939</td>\n",
       "      <td>{'x': 0.49992355704307556, 'y': -0.58012896776...</td>\n",
       "      <td>{'x': 0.5130205154418945, 'y': -0.604468226432...</td>\n",
       "      <td>[0.49992355704307556, 0.5130205154418945]</td>\n",
       "      <td>[-0.5801289677619934, -0.6044682264328003]</td>\n",
       "      <td>[-0.1448336408037463, -0.1441700028383177]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  source  target                                         original_x  \\\n",
       "0    149.0       1     280  [0.5508721470832825, 0.55393686033313, 0.55205...   \n",
       "1    271.0       2       7          [0.49992355704307556, 0.5130205154418945]   \n",
       "\n",
       "                                          original_y    weight  \\\n",
       "0  [-0.4072713851928711, -0.3896731439439783, -0....  0.936576   \n",
       "1         [-0.5801289677619934, -0.6044682264328003]  0.816939   \n",
       "\n",
       "                                     source_position  \\\n",
       "0  {'x': 0.5508721470832825, 'y': -0.407271385192...   \n",
       "1  {'x': 0.49992355704307556, 'y': -0.58012896776...   \n",
       "\n",
       "                                     target_position  \\\n",
       "0  {'x': 0.445087194442749, 'y': -0.2985744476318...   \n",
       "1  {'x': 0.5130205154418945, 'y': -0.604468226432...   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [0.5508721470832825, 0.5482098857147208, 0.544...   \n",
       "1          [0.49992355704307556, 0.5130205154418945]   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [-0.4072713851928711, -0.38927841208412234, -0...   \n",
       "1         [-0.5801289677619934, -0.6044682264328003]   \n",
       "\n",
       "                                                   z  is_high_z_connection  \n",
       "0  [-0.1460439847414049, -0.14600811272264846, -0...                 False  \n",
       "1         [-0.1448336408037463, -0.1441700028383177]                 False  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_edges_3d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1133"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def find_common_coordinates(adjusted_edges_3d, tolerance=1e-7):\n",
    "    # Extract x and y coordinates, excluding first and last points\n",
    "    xs = [x[1:-1] for x in adjusted_edges_3d[\"original_x\"].values]\n",
    "    ys = [y[1:-1] for y in adjusted_edges_3d[\"original_y\"].values]\n",
    "\n",
    "    # Combine all points into a single array and keep track of edge indices\n",
    "    all_points = []\n",
    "    edge_indices = []\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        points = np.column_stack((x, y))\n",
    "        all_points.append(points)\n",
    "        edge_indices.extend([i] * len(points))\n",
    "\n",
    "    all_points = np.vstack(all_points)\n",
    "    edge_indices = np.array(edge_indices)\n",
    "\n",
    "    # Build a KD-tree for efficient nearest neighbor search\n",
    "    tree = cKDTree(all_points)\n",
    "\n",
    "    # Find pairs of points within the tolerance\n",
    "    pairs = tree.query_pairs(r=tolerance)\n",
    "\n",
    "    # Filter pairs to only include points from different edges\n",
    "    common_coords = []\n",
    "    for p1, p2 in pairs:\n",
    "        if edge_indices[p1] != edge_indices[p2]:\n",
    "            i, j = edge_indices[p1], edge_indices[p2]\n",
    "            idx1 = p1 - np.sum(edge_indices < i)\n",
    "            idx2 = p2 - np.sum(edge_indices < j)\n",
    "            common_coords.append((i, j, idx1, idx2))\n",
    "\n",
    "    return common_coords\n",
    "\n",
    "\n",
    "# Usage\n",
    "common_coordinates = find_common_coordinates(adjusted_edges_3d)\n",
    "# for i, j, idx1, idx2 in common_coordinates:\n",
    "#    print(\n",
    "#        f\"Edge {i} and Edge {j} have a common coordinate at indices {idx1} and {idx2}\"\n",
    "#    )\n",
    "len(common_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for common points amongst edges\n",
    "\n",
    "xs = adjusted_edges_3d[\"original_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.5508721470832825, 0.55393686033313, 0.55205...\n",
       "1               [0.49992355704307556, 0.5130205154418945]\n",
       "2       [0.5524348020553589, 0.5497690907852348, 0.544...\n",
       "3       [0.5524348020553589, 0.5585797046720011, 0.566...\n",
       "4       [0.5524348020553589, 0.5483290342278686, 0.541...\n",
       "                              ...                        \n",
       "4412    [-0.34231740236282343, -0.354872689493168, -0....\n",
       "4413             [0.5319066643714905, 0.5140461921691895]\n",
       "4414    [0.5319066643714905, 0.5406255788234311, 0.548...\n",
       "4415           [0.48814910650253296, 0.46257609128952026]\n",
       "4416    [-0.46193641424179077, -0.447839639490751, -0....\n",
       "Name: original_x, Length: 4417, dtype: object"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes saved to ../data/99-testdata/nodes_3d_clusters45to50.json\n",
      "Graph nodes saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/nodes_3d_clusters45to50.json\n",
      "4409 out of 4417 edges have the same source and target cluster.\n",
      "No edges with NaN values found.\n",
      "Edges data saved to ../data/99-testdata/bundled_edges_3d_clusters45to50.json\n",
      "Edges data saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/bundled_edges_3d_clusters45to50.json\n"
     ]
    }
   ],
   "source": [
    "# save to multiple paths\n",
    "nodes_json = NodesSaver.save_igraph_nodes_to_json(\n",
    "    g_fr_z_bundled_pruned,\n",
    "    [\n",
    "        OUTPUT_DIR + f\"nodes_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "        THREEJS_OUTPUT_DIR\n",
    "        + f\"nodes_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "    ],\n",
    "    return_json=True,\n",
    ")\n",
    "\n",
    "\n",
    "edges_json = EdgesSaver.save_edges_for_js(\n",
    "    test_edge_df,\n",
    "    [\n",
    "        OUTPUT_DIR\n",
    "        + f\"bundled_edges_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "        THREEJS_OUTPUT_DIR\n",
    "        + f\"bundled_edges_3d_clusters{min(cluster_list)}to{max(cluster_list)}.json\",\n",
    "    ],\n",
    "    add_color_bool=True,\n",
    "    g=g_fr_z_bundled_pruned,\n",
    "    return_json=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout fruchterman_reingold_3d applied to the graph.\n",
      "Coordinates stored in node attributes.\n"
     ]
    }
   ],
   "source": [
    "class GraphProcessor3d:\n",
    "    def __init__(self, G: Union[nx.Graph, ig.Graph]):\n",
    "        self.g = self._ensure_igraph(G)\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_igraph(G: Union[nx.Graph, ig.Graph]) -> ig.Graph:\n",
    "        if isinstance(G, nx.Graph):\n",
    "            return ig.Graph.from_networkx(G)\n",
    "        return G\n",
    "\n",
    "    def apply_layout(self, layout_name: str = \"fruchterman_reingold_3d\", **kwargs):\n",
    "        \"\"\"\n",
    "        Apply a layout to the graph. For Fruchterman-Reingold 3D, available kwargs are:\n",
    "        - dim: The dimension of the layout (default: 3)\n",
    "        - weights: Edge weights to be used. Can be a list or the name of an edge attribute.\n",
    "        - niter: The number of iterations to perform (default: 500)\n",
    "        - start_temp: The starting temperature (default: 10)\n",
    "        - seed: Random seed to use (default: None)\n",
    "        \"\"\"\n",
    "        if layout_name == \"fruchterman_reingold_3d\":\n",
    "            # Set default values\n",
    "            layout_kwargs = {\n",
    "                \"dim\": 3,\n",
    "                \"weights\": \"weight\",\n",
    "                \"niter\": 500,\n",
    "                \"start_temp\": 10,\n",
    "                \"seed\": None,\n",
    "            }\n",
    "            # Update with provided kwargs\n",
    "            layout_kwargs.update(kwargs)\n",
    "\n",
    "            layout = self.g.layout_fruchterman_reingold_3d(**layout_kwargs)\n",
    "        else:\n",
    "            layout = self.g.layout(layout_name, **kwargs)\n",
    "\n",
    "        for i, coords in enumerate(layout):\n",
    "            self.g.vs[i][\"x\"] = coords[0]\n",
    "            self.g.vs[i][\"y\"] = coords[1]\n",
    "            self.g.vs[i][\"z\"] = coords[2]\n",
    "\n",
    "        print(f\"Layout {layout_name} applied to the graph.\")\n",
    "        print(\"Coordinates stored in node attributes.\")\n",
    "        return self.g\n",
    "\n",
    "\n",
    "# example usage\n",
    "gp3d = GraphProcessor3d(g)\n",
    "g = gp3d.apply_layout(\"fruchterman_reingold_3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color and label assignment for full graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import to_hex\n",
    "from matplotlib.colors import to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterColorAssigner:\n",
    "    \"\"\"\n",
    "    TO DO:\n",
    "    1. clusters not mutually exclusive - need to assign to multiple categories\n",
    "    2. colors too similar - need to assign more distinct colors\n",
    "\n",
    "    A class for assigning colors to clusters based on their characteristics.\n",
    "\n",
    "    This class provides methods to categorize clusters into color palettes,\n",
    "    assign specific colors within those palettes, and create a mapping\n",
    "    between clusters and their assigned colors.\n",
    "\n",
    "    Attributes:\n",
    "        colormaps (dict): A dictionary mapping color names to matplotlib colormaps.\n",
    "        condition_names (dict): A dictionary mapping color names to condition names.\n",
    "\n",
    "    Methods:\n",
    "        assign_color_categories(clust_hierarchy): Assigns color categories to clusters.\n",
    "        print_color_mapping(): Prints the mapping of conditions to color palettes.\n",
    "        assign_colors(df, colormap): Assigns specific colors to clusters within a palette.\n",
    "        create_color_dataframes(clust_hierarchy): Creates separate DataFrames for each color category.\n",
    "        process_cluster_hierarchy(clust_hierarchy): Processes the entire cluster hierarchy.\n",
    "\n",
    "    Usage:\n",
    "        color_assigner = ClusterColorAssigner()\n",
    "        processed_hierarchy, color_dict = color_assigner.process_cluster_hierarchy(cluster_hierarchy_df)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colormaps = {\n",
    "            \"blue\": plt.get_cmap(\"Blues\"),\n",
    "            \"red\": plt.get_cmap(\"Reds\"),\n",
    "            \"green\": plt.get_cmap(\"Greens\"),\n",
    "            \"purple\": plt.get_cmap(\"Purples\"),\n",
    "        }\n",
    "        self.condition_names = {\n",
    "            \"blue\": \"pharmacology\",\n",
    "            \"red\": \"indications\",\n",
    "            \"green\": \"safety\",\n",
    "            \"purple\": \"other\",\n",
    "        }\n",
    "\n",
    "    def assign_color_categories(self, clust_hierarchy):\n",
    "        conditions = [\n",
    "            clust_hierarchy[\"pharmacology\"] == 1,\n",
    "            clust_hierarchy[\"indications\"] == 1,\n",
    "            clust_hierarchy[\"safety\"] == 1,\n",
    "            clust_hierarchy[\"other\"] == 1,\n",
    "        ]\n",
    "        choices = [\"blue\", \"red\", \"green\", \"purple\"]\n",
    "        clust_hierarchy[\"color_pal\"] = np.select(conditions, choices, default=\"\")\n",
    "        return clust_hierarchy\n",
    "\n",
    "    def print_color_mapping(self):\n",
    "        print(\"Mapping of conditions to color palettes:\")\n",
    "        for color, condition in self.condition_names.items():\n",
    "            print(f\"{condition.capitalize()}: {color}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def assign_colors(df, colormap):\n",
    "        num_colors = df.shape[0]\n",
    "        colors = [to_hex(colormap(x)) for x in np.linspace(0.1, 0.9, num_colors)]\n",
    "        df[\"color\"] = colors\n",
    "        return df\n",
    "\n",
    "    def create_color_dataframes(self, clust_hierarchy):\n",
    "        color_dfs = {}\n",
    "        for color_name, colormap in self.colormaps.items():\n",
    "            df_color = clust_hierarchy[\n",
    "                clust_hierarchy[\"color_pal\"] == color_name\n",
    "            ].copy()\n",
    "            if not df_color.empty:\n",
    "                color_dfs[color_name] = self.assign_colors(df_color, colormap)\n",
    "        return color_dfs\n",
    "\n",
    "    def process_cluster_hierarchy(self, clust_hierarchy):\n",
    "        clust_hierarchy = self.assign_color_categories(clust_hierarchy)\n",
    "        self.print_color_mapping()\n",
    "        color_dfs = self.create_color_dataframes(clust_hierarchy)\n",
    "        clust_hierarchy = pd.concat(color_dfs.values())\n",
    "        cluster_color_dict = dict(\n",
    "            zip(clust_hierarchy[\"cluster\"], clust_hierarchy[\"color\"])\n",
    "        )\n",
    "        return clust_hierarchy, cluster_color_dict\n",
    "\n",
    "    def save_dict_to_json(self, dict, path):\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(dict, f)\n",
    "        print(f\"Cluster color dictionary saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of conditions to color palettes:\n",
      "Pharmacology: blue\n",
      "Indications: red\n",
      "Safety: green\n",
      "Other: purple\n",
      "Cluster color dictionary saved to ../data/99-testdata/cluster_color_dict.json\n",
      "Cluster color dictionary saved to ../data/99-testdata/cluster_label_dict.json\n",
      "\n",
      "Cluster color dictionary (first 5 items):\n",
      "{0: '#e3eef9', 2: '#dfebf7', 3: '#dbe9f6', 5: '#d6e6f4', 6: '#d3e3f3'}\n",
      "\n",
      "Cluster label dictionary (first 5 items):\n",
      "{0: 'Serotonin Receptor Studies', 2: 'Risks of Prenatal Exposure', 3: 'Quantification of SSRIs in Biological Samples', 5: 'SSRIs and the Cytochrome P450 System', 6: 'SSRI Neuroscience'}\n"
     ]
    }
   ],
   "source": [
    "# Assuming clust_hierarchy is your input DataFrame\n",
    "\n",
    "clust_hierarchy = pd.read_excel(CLUSTER_INFO_LABEL_TREE)\n",
    "\n",
    "color_assigner = ClusterColorAssigner()\n",
    "clust_hierarchy, cluster_color_dict = color_assigner.process_cluster_hierarchy(\n",
    "    clust_hierarchy\n",
    ")\n",
    "\n",
    "color_assigner.save_dict_to_json(\n",
    "    cluster_color_dict, OUTPUT_DIR + \"cluster_color_dict.json\"\n",
    ")\n",
    "\n",
    "cluster_label_dict = dict(\n",
    "    zip(clust_hierarchy[\"cluster\"], clust_hierarchy[\"clusterlabel\"])\n",
    ")\n",
    "\n",
    "color_assigner.save_dict_to_json(cluster_label_dict, CLUSTER_LABEL_DICT_PATH)\n",
    "\n",
    "print(\"\\nCluster color dictionary (first 5 items):\")\n",
    "print(dict(list(cluster_color_dict.items())[:5]))\n",
    "print(\"\\nCluster label dictionary (first 5 items):\")\n",
    "print(dict(list(cluster_label_dict.items())[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# legend json creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(CLUSTER_LABEL_DICT_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     27\u001b[0m     cluster_label_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m---> 29\u001b[0m legend \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_dict_to_legend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_hierachy_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_label_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m, in \u001b[0;36mtransform_dict_to_legend\u001b[0;34m(cluster_hierachy_dict, cluster_label_dict)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m legend\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Recursively transform dictionaries\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m         \u001b[43mtransform_dict\u001b[49m(value, cluster_label_dict)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     13\u001b[0m         new_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform_dict' is not defined"
     ]
    }
   ],
   "source": [
    "def transform_dict_to_legend(cluster_hierachy_dict, cluster_label_dict):\n",
    "    \"\"\"\n",
    "    Adds the cluster labels to the cluster hierarchy dictionary to create a legend.\n",
    "    \"\"\"\n",
    "    # make sure keys in cluster_label_dict are integers\n",
    "    cluster_label_dict = {int(k): v for k, v in cluster_label_dict.items()}\n",
    "    legend = cluster_hierachy_dict.copy()\n",
    "    for key, value in legend.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Recursively transform dictionaries\n",
    "            transform_dict(value, cluster_label_dict)\n",
    "        elif isinstance(value, list):\n",
    "            new_list = []\n",
    "            for item in value:\n",
    "                if isinstance(item, int) and item in cluster_label_dict:\n",
    "                    new_list.append({item: cluster_label_dict[item]})\n",
    "                else:\n",
    "                    new_list.append(item)\n",
    "            legend[key] = new_list\n",
    "    return legend\n",
    "\n",
    "\n",
    "with open(CLUSTER_HIERACHY_FOR_LEGEND_PATH, \"r\") as f:\n",
    "    cluster_hierachy_dict = json.load(f)\n",
    "\n",
    "with open(CLUSTER_LABEL_DICT_PATH, \"r\") as f:\n",
    "    cluster_label_dict = json.load(f)\n",
    "\n",
    "legend = transform_dict_to_legend(cluster_hierachy_dict, cluster_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSON\n",
    "with open(OUTPUT_DIR + \"legend_full_label_tree_clusternr.json\", \"w\") as json_file:\n",
    "    json.dump(cat_tree, json_file, indent=4)\n",
    "\n",
    "    # Save as JSON\n",
    "with open(\n",
    "    THREEJS_OUTPUT_DIR + \"legend_tree.json\",\n",
    "    \"w\",\n",
    ") as json_file:\n",
    "    json.dump(cat_tree, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Study1Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
