{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processor and text embeddings\n",
    "\n",
    "In this notebook, we first create a new column `title_abstract` and then use a huggingface model to create text embeddings for this column.\n",
    "\n",
    "This column is a concatenation of the `title` and `abstract` columns and processes the text in the follwing way:\n",
    "\n",
    "- remove phrases like `abstract` and `introduction` from the text\n",
    "- removes ending phrases like copyrights, version numbers of journals, journal names\n",
    "- merges the title and abstract columns with `. ` as a separator\n",
    "\n",
    "We then use specter2 to create text embeddings for this column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.nlp.TextProcessor import TextProcessor\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data and process text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA dict saved to ../output/descriptive-stats-logs/na_log_text_cols.json\n",
      "cleaned text and removed start and ending statements\n",
      "cleaned text - embed me now :)\n",
      "Papers to embed: 40643\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/03-connected/scopus_cleaned_connected.pkl\")\n",
    "cols = [\"abstract\", \"title\"]\n",
    "file_path = \"../output/descriptive-stats-logs/na_log_text_cols.json\"\n",
    "tp = TextProcessor(df)\n",
    "tp.save_na_dict_to_json(cols, file_path)\n",
    "df = tp.clean_text_and_remove_start_and_ending_statements(\n",
    "    return_cleaned_text_separately=True\n",
    ")\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"Papers to embed: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp.EmbeddingCreator import PaperEmbeddingProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5ee6b5120d452a901bc22e2d6df456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [3:59:04<00:00, 843.77s/it]  \n"
     ]
    }
   ],
   "source": [
    "processor = PaperEmbeddingProcessor(\n",
    "    df=df,\n",
    "    model_name=\"allenai/specter2_base\",\n",
    "    adapter_name=\"specter2\",  # this is for \"proximity\"\n",
    "    save_dir=\"../data/04-embeddings\",\n",
    "    batch_size=32,\n",
    "    chunk_size=2500,  # 2500\n",
    ")\n",
    "total_embeddings = processor.process_papers()\n",
    "processor.save_embeddings_with_data(total_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
