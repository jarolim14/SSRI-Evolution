{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src / visualization / edgebundling / preprocessUtilityFunctions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the path for the source code directory\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src/visualization/edgebundling/\")\n",
    "\n",
    "from preprocessUtilityFunctions import GraphToDataFrameUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Disable SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Graphs and networks\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "# Scientific computing\n",
    "import math\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_hex, to_rgb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Data visualization and processing\n",
    "import colorcet as cc\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "\n",
    "# from datashader.bundling import hammer_bundle\n",
    "\n",
    "# Performance optimization\n",
    "from numba import jit, prange\n",
    "\n",
    "# Progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Custom modules\n",
    "from bundling3D import *\n",
    "from fa2_modified import ForceAtlas2\n",
    "\n",
    "# Set Seaborn style for plots\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Constants and configuration\n",
    "INPUT_GRAPH_PATH = \"../data/07-clustered-graphs/alpha0.3_k10_res0.002.graphml\"\n",
    "CLUSTER_INFO_LABEL_TREE = \"../output/cluster-qualifications/ClusterInfoLabelTree.xlsx\"\n",
    "CLUSTER_LABEL_DICT_PATH = \"../data/99-testdata/cluster_label_dict.json\"\n",
    "CLUSTER_TREE_PATH = \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    "OUTPUT_DIR = \"../data/99-testdata/\"\n",
    "THREEJS_OUTPUT_DIR = (\n",
    "    \"/Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/\"\n",
    ")\n",
    "CLUSTER_HIERACHY_FOR_LEGEND_PATH = (\n",
    "    \"../output/cluster-qualifications/ClusterHierachy_noComments.json\"\n",
    ")\n",
    "\n",
    "FR_GRAPH_FILENAME = \"fr_0to100clusters.graphml\"\n",
    "\n",
    "NODES_DATA_FILENAME = \"NodesData0to100_BundlPerc50_BW0,4.json\"\n",
    "EDGES_DATA_FILENAME = \"EdgesData0to100_BundlPerc50_BW0,4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataFrameUtility:\n",
    "    \"\"\"\n",
    "    A utility class for converting igraph graph attributes to pandas DataFrames\n",
    "    and performing DataFrame operations related to graph data.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def minmax_normalize(\n",
    "        data: Union[List[float], np.ndarray], new_range: Tuple[float, float] = (0, 1)\n",
    "    ) -> np.ndarray:\n",
    "        data = np.array(data)\n",
    "        if len(data) == 0:\n",
    "            raise ValueError(\"Input data is empty\")\n",
    "\n",
    "        data_min, data_max = np.min(data), np.max(data)\n",
    "        if data_min == data_max:\n",
    "            raise ValueError(\"All values in the input data are identical\")\n",
    "\n",
    "        normalized_data = (data - data_min) / (data_max - data_min)\n",
    "\n",
    "        if new_range != (0, 1):\n",
    "            new_min, new_max = new_range\n",
    "            normalized_data = normalized_data * (new_max - new_min) + new_min\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def minmax_denormalize(\n",
    "        normalized_data: Union[List[float], np.ndarray],\n",
    "        original_range: Tuple[float, float],\n",
    "        current_range: Tuple[float, float] = (0, 1),\n",
    "    ) -> np.ndarray:\n",
    "\n",
    "        normalized_data = np.array(normalized_data)\n",
    "        if len(normalized_data) == 0:\n",
    "            raise ValueError(\"Input data is empty\")\n",
    "\n",
    "        orig_min, orig_max = original_range\n",
    "        curr_min, curr_max = current_range\n",
    "\n",
    "        if orig_min >= orig_max or curr_min >= curr_max:\n",
    "            raise ValueError(\"Invalid range: min should be less than max\")\n",
    "\n",
    "        # First, normalize to [0, 1] if not already\n",
    "        if current_range != (0, 1):\n",
    "            normalized_data = (normalized_data - curr_min) / (curr_max - curr_min)\n",
    "\n",
    "        # Then, scale to original range\n",
    "        denormalized_data = normalized_data * (orig_max - orig_min) + orig_min\n",
    "\n",
    "        return denormalized_data\n",
    "\n",
    "    @staticmethod\n",
    "    def edges_to_dataframe(g: ig.Graph) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the edges and their attributes of an igraph graph to a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input igraph graph.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing edge attributes, source, and target nodes.\n",
    "        \"\"\"\n",
    "        # check if networkx or igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        # Extract edge attributes\n",
    "        edge_data = {attr: g.es[attr] for attr in g.es.attributes()}\n",
    "\n",
    "        # Add source and target node indices\n",
    "        edge_data[\"source\"] = [e.source for e in g.es]\n",
    "        edge_data[\"target\"] = [e.target for e in g.es]\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        edge_dataframe = pd.DataFrame(edge_data)\n",
    "\n",
    "        return edge_dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def nodes_to_dataframe(\n",
    "        g: ig.Graph,\n",
    "        normalize_coordinates: bool = False,\n",
    "        drop_columns: Optional[List[str]] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the nodes and their attributes of an igraph graph to a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input igraph graph.\n",
    "            drop_columns (Optional[List[str]]): A list of column names to drop from the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing node attributes and node indices.\n",
    "        \"\"\"\n",
    "        # check if networkx or igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        # Extract node attributes\n",
    "        node_data = {attr: g.vs[attr] for attr in g.vs.attributes()}\n",
    "\n",
    "        # Add node indices\n",
    "        node_dataframe = pd.DataFrame(node_data)\n",
    "        node_dataframe[\"node_index\"] = [n.index for n in g.vs]\n",
    "        if normalize_coordinates:\n",
    "            # Calculate min/max for coordinates\n",
    "            xmin, xmax = np.min(node_dataframe[\"x\"]), np.max(node_dataframe[\"x\"])\n",
    "            ymin, ymax = np.min(node_dataframe[\"y\"]), np.max(node_dataframe[\"y\"])\n",
    "            zmin, zmax = np.min(node_dataframe[\"z\"]), np.max(node_dataframe[\"z\"])\n",
    "\n",
    "            # Normalize coordinates\n",
    "            node_dataframe[\"x\"] = minmax_normalize(node_dataframe[\"x\"], xmin, xmax)\n",
    "            node_dataframe[\"y\"] = minmax_normalize(node_dataframe[\"y\"], ymin, ymax)\n",
    "            node_dataframe[\"z\"] = minmax_normalize(node_dataframe[\"z\"], zmin, zmax)\n",
    "            print(\"Coordinates normalized to [0, 1] range.\")\n",
    "\n",
    "        # Drop specified columns if provided\n",
    "        if drop_columns:\n",
    "            node_dataframe = node_dataframe.drop(columns=drop_columns, errors=\"ignore\")\n",
    "\n",
    "        return node_dataframe\n",
    "\n",
    "    @staticmethod\n",
    "    def create_edge_df_with_source_target_coords(g: ig.Graph) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a DataFrame containing edge information with source and target coordinates.\n",
    "\n",
    "        This method processes an igraph Graph object and extracts edge information,\n",
    "        including weights, IDs, source and target nodes, and their coordinates.\n",
    "        It also calculates the length of each edge segment.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        g : ig.Graph\n",
    "            The input graph object from which to extract edge information.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            A DataFrame containing the following columns:\n",
    "            - weight: Edge weight\n",
    "            - edge_id: Unique identifier for each edge\n",
    "            - source: Source node ID\n",
    "            - target: Target node ID\n",
    "            - source_x, source_y, source_z: Coordinates of the source node\n",
    "            - target_x, target_y, target_z: Coordinates of the target node\n",
    "            - segment_length: Euclidean distance between source and target nodes\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        - Assumes the graph nodes have 'x', 'y', and 'z' attributes for coordinates.\n",
    "        - Prints statistics about segment lengths after creating the DataFrame.\n",
    "        \"\"\"\n",
    "        edge_data = []\n",
    "        for edge in g.es:\n",
    "            source = edge.source\n",
    "            target = edge.target\n",
    "            source_coords = (g.vs[source][\"x\"], g.vs[source][\"y\"], g.vs[source][\"z\"])\n",
    "            target_coords = (g.vs[target][\"x\"], g.vs[target][\"y\"], g.vs[target][\"z\"])\n",
    "\n",
    "            edge_data.append(\n",
    "                {\n",
    "                    \"weight\": edge[\"weight\"],\n",
    "                    \"edge_id\": edge[\"edge_id\"],\n",
    "                    \"source\": source,\n",
    "                    \"target\": target,\n",
    "                    \"source_x\": source_coords[0],\n",
    "                    \"source_y\": source_coords[1],\n",
    "                    \"source_z\": source_coords[2],\n",
    "                    \"target_x\": target_coords[0],\n",
    "                    \"target_y\": target_coords[1],\n",
    "                    \"target_z\": target_coords[2],\n",
    "                    \"segment_length\": GraphDataFrameUtility.distance_between(\n",
    "                        source_coords, target_coords\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df = pd.DataFrame(edge_data)\n",
    "\n",
    "        # Print segment length statistics\n",
    "        print(\"Segment length statistics:\")\n",
    "        print(f\"Min: {df['segment_length'].min():.2f}\")\n",
    "        print(f\"Max: {df['segment_length'].max():.2f}\")\n",
    "        print(f\"Mean: {df['segment_length'].mean():.2f}\")\n",
    "        print(f\"Median: {df['segment_length'].median():.2f}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def distance_between(\n",
    "        point1: Tuple[float, float, float], point2: Tuple[float, float, float]\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate the Euclidean distance between two 3D points.\"\"\"\n",
    "        return np.sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(point1, point2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphReader:\n",
    "    @staticmethod\n",
    "    def read_and_clean_graph(path: str) -> ig.Graph:\n",
    "        g = ig.Graph.Read_GraphML(path)\n",
    "        g.vs[\"node_id\"] = [int(i) for i in range(g.vcount())]\n",
    "\n",
    "        if \"id\" in g.vs.attribute_names():\n",
    "            g.vs[\"node_name\"] = g.vs[\"id\"]\n",
    "            del g.vs[\"id\"]\n",
    "\n",
    "        if \"cluster\" in g.vs.attribute_names():\n",
    "            g.vs[\"cluster\"] = [int(cluster) for cluster in g.vs[\"cluster\"]]\n",
    "\n",
    "        if \"year\" in g.vs.attribute_names():\n",
    "            g.vs[\"year\"] = [int(year) for year in g.vs[\"year\"]]\n",
    "\n",
    "        if \"eid\" in g.vs.attribute_names():\n",
    "            del g.vs[\"eid\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.006\" in g.vs.attribute_names():\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.006\"]\n",
    "\n",
    "        if \"centrality_alpha0.3_k10_res0.002\" in g.vs.attribute_names():\n",
    "            g.vs[\"centrality\"] = g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "            del g.vs[\"centrality_alpha0.3_k10_res0.002\"]\n",
    "\n",
    "        g.es[\"edge_id\"] = list(range(g.ecount()))\n",
    "        print(\"Node Attributes:\", g.vs.attribute_names())\n",
    "        print(\"Edge Attributes:\", g.es.attribute_names())\n",
    "        # print number of nodes and edges\n",
    "        print(f\"Number of nodes: {g.vcount()}\")\n",
    "        print(f\"Number of edges: {g.ecount()}\")\n",
    "        return g\n",
    "\n",
    "    @staticmethod\n",
    "    def subgraph_of_clusters(G, clusters):\n",
    "        if isinstance(G, nx.Graph):\n",
    "            nodes = [\n",
    "                node for node in G.nodes if G.nodes[node].get(\"cluster\") in clusters\n",
    "            ]\n",
    "            return G.subgraph(nodes)\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            nodes = [v.index for v in G.vs if v[\"cluster\"] in clusters]\n",
    "            return G.subgraph(nodes)\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "    @staticmethod\n",
    "    def add_cluster_labels(\n",
    "        G: Union[nx.Graph, ig.Graph],\n",
    "        labels_file_path: str = \"../output/cluster-qualifications/raw_cluster_labels.json\",\n",
    "    ) -> Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "        \"\"\"\n",
    "        Add cluster labels to the graph nodes.\n",
    "\n",
    "        Args:\n",
    "            G (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "            labels_file_path (str): Path to the JSON file containing cluster labels.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Union[nx.Graph, ig.Graph], Dict[float, str]]:\n",
    "                The graph with added cluster labels and the cluster label dictionary.\n",
    "        \"\"\"\n",
    "        with open(labels_file_path) as file:\n",
    "            cluster_label_dict = json.load(file)\n",
    "        cluster_label_dict = {float(k): v[0] for k, v in cluster_label_dict.items()}\n",
    "\n",
    "        if isinstance(G, nx.Graph):\n",
    "            for node in G.nodes:\n",
    "                cluster = G.nodes[node][\"cluster\"]\n",
    "                G.nodes[node][\"cluster_label\"] = cluster_label_dict.get(\n",
    "                    cluster, \"Unknown\"\n",
    "                )\n",
    "        elif isinstance(G, ig.Graph):\n",
    "            G.vs[\"cluster_label\"] = [\n",
    "                cluster_label_dict.get(v[\"cluster\"], \"Unknown\") for v in G.vs\n",
    "            ]\n",
    "        else:\n",
    "            raise TypeError(\"Input must be a NetworkX Graph or an igraph Graph\")\n",
    "\n",
    "        return G, cluster_label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout Utilities (Fruchterman-Reingold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutUtility:\n",
    "    \"\"\"\n",
    "    Layout utility class for igraph layout operations. made for fruchterman-reingold layout.\n",
    "\n",
    "    Args:\n",
    "        g (Union[nx.Graph, ig.Graph]): The input graph (NetworkX or igraph).\n",
    "        layout_params (Optional[Dict]): The layout parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[nx.Graph, Dict]: The graph with assigned coordinates and the layout dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fr_layout_nx(\n",
    "        g: Union[nx.Graph, ig.Graph], layout_params: Optional[Dict] = None\n",
    "    ) -> Tuple[nx.Graph, Dict]:\n",
    "        print(\"Starting Fruchterman-Reingold layout process...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if layout_params is None:\n",
    "            layout_params = {\n",
    "                \"iterations\": 100,\n",
    "                \"threshold\": 0.00001,\n",
    "                \"weight\": \"weight\",\n",
    "                \"scale\": 1,\n",
    "                \"center\": (0, 0),\n",
    "                \"dim\": 2,\n",
    "                \"seed\": 1887,\n",
    "            }\n",
    "        print(f\"Layout parameters: {layout_params}\")\n",
    "\n",
    "        if not isinstance(g, nx.Graph):\n",
    "            print(\"Converting to NetworkX Graph...\")\n",
    "            G = g.to_networkx()\n",
    "            print(\"Conversion complete.\")\n",
    "        else:\n",
    "            G = g\n",
    "\n",
    "        print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "        print(\"Calculating layout...\")\n",
    "        layout_start_time = time.time()\n",
    "        pos = nx.spring_layout(G, **layout_params)\n",
    "        layout_end_time = time.time()\n",
    "        print(\n",
    "            f\"Layout calculation completed in {layout_end_time - layout_start_time:.2f} seconds.\"\n",
    "        )\n",
    "\n",
    "        print(\"Processing layout results...\")\n",
    "        node_xy_dict = {node: pos[node] for node in G.nodes}\n",
    "\n",
    "        x_values, y_values = zip(*node_xy_dict.values())\n",
    "        min_x, max_x = min(x_values), max(x_values)\n",
    "        min_y, max_y = min(y_values), max(y_values)\n",
    "\n",
    "        print(f\"Layout boundaries:\")\n",
    "        print(f\"X-axis: Min = {min_x:.2f}, Max = {max_x:.2f}\")\n",
    "        print(f\"Y-axis: Min = {min_y:.2f}, Max = {max_y:.2f}\")\n",
    "\n",
    "        print(\"Assigning coordinates to nodes...\")\n",
    "        for node in G.nodes:\n",
    "            G.nodes[node][\"x\"] = node_xy_dict[node][0]\n",
    "            G.nodes[node][\"y\"] = node_xy_dict[node][1]\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Layout process completed in {total_time:.2f} seconds.\")\n",
    "\n",
    "        return G, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add z coordinates to the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZCoordinateAdder:\n",
    "    \"\"\"\n",
    "    A class for adding a z-coordinate to the nodes of a graph based on their centrality values.\n",
    "    The z-coordinate range is determined by a percentage of the x-y dimension range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, g, percentage=50):\n",
    "        self.g = g\n",
    "        self.percentage = percentage / 100  # Convert percentage to decimal\n",
    "\n",
    "    def add_z_coordinate_to_nodes(self):\n",
    "        \"\"\"\n",
    "        Add a z-coordinate to the nodes of the graph based on their centrality values.\n",
    "        Args:\n",
    "            g (nx.Graph): The input graph.\n",
    "            percentage (float): The percentage of x-y dimension range to use for z-coordinate range.\n",
    "        Returns:\n",
    "            nx.Graph: The graph with the z-coordinate added to the nodes.\n",
    "        \"\"\"\n",
    "        # Calculate the bounds of x and y coordinates\n",
    "        xvalues = [attributes[\"x\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        yvalues = [attributes[\"y\"] for _, attributes in self.g.nodes(data=True)]\n",
    "        min_x, max_x = min(xvalues), max(xvalues)\n",
    "        min_y, max_y = min(yvalues), max(yvalues)\n",
    "\n",
    "        # Calculate the range of x and y\n",
    "        x_range = max_x - min_x\n",
    "        y_range = max_y - min_y\n",
    "\n",
    "        # Calculate the maximum z range based on the larger of x or y range\n",
    "        max_z_range = max(x_range, y_range) * self.percentage\n",
    "\n",
    "        print(\"Bounds of the layout:\")\n",
    "        print(f\"Min x: {min_x}, Max x: {max_x}\")\n",
    "        print(f\"Min y: {min_y}, Max y: {max_y}\")\n",
    "        print(f\"Z coordinate range: 0 to {max_z_range}\")\n",
    "\n",
    "        # Extract centrality values from nodes\n",
    "        centralities = np.array(\n",
    "            [self.g.nodes[node][\"centrality\"] for node in self.g.nodes]\n",
    "        )\n",
    "\n",
    "        # Normalize centrality values to range [0, 1]\n",
    "        centrality_min = centralities.min()\n",
    "        centrality_max = centralities.max()\n",
    "        centralities_normalized = (centralities - centrality_min) / (\n",
    "            centrality_max - centrality_min\n",
    "        )\n",
    "\n",
    "        # Scale the normalized centralities to the desired z range\n",
    "        z_coordinates = centralities_normalized * max_z_range\n",
    "\n",
    "        # Add z-coordinate to nodes\n",
    "        for i, node in enumerate(self.g.nodes):\n",
    "            self.g.nodes[node][\"z\"] = z_coordinates[i]\n",
    "\n",
    "        # Describe the distribution of z values\n",
    "        print(\"Description of the Z coordinate values:\")\n",
    "        print(pd.Series(z_coordinates).describe())\n",
    "        print(\"Z coordinate added to nodes\")\n",
    "\n",
    "        return self.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class PruneEdges:\n",
    "    \"\"\"\n",
    "    A class for pruning edges in a graph based on specific criteria, such as edge weight percentiles or random selection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initial_edge_count = 0\n",
    "        self.initial_isolates = 0\n",
    "        self.final_edge_count = 0\n",
    "        self.final_isolates = 0\n",
    "\n",
    "    def _update_statistics(self, g: ig.Graph, g_modified: ig.Graph) -> None:\n",
    "        \"\"\"\n",
    "        Update class attributes related to graph statistics.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The original graph.\n",
    "            g_modified (ig.Graph): The modified graph after pruning or random selection.\n",
    "        \"\"\"\n",
    "        # if nx object, convert to igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        self.initial_edge_count = g.ecount()\n",
    "        self.initial_isolates = len(g.vs.select(_degree=0))\n",
    "        self.final_edge_count = g_modified.ecount()\n",
    "        self.final_isolates = len(g_modified.vs.select(_degree=0))\n",
    "\n",
    "    def prune_edges_by_percentile_weight(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Remove edges from the graph that have weight less than or equal to the specified percentile weight.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph. Must have a 'weight' attribute for edges.\n",
    "            percentile (float): The percentile to use as the threshold for pruning edges.\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with edges removed based on the specified percentile.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the input graph has no 'weight' attribute for edges.\n",
    "            ValueError: If percentile is not between 0 and 100.\n",
    "        \"\"\"\n",
    "        # if nx object, convert to igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        if not (0 <= percentile <= 100):\n",
    "            raise ValueError(\"Percentile must be between 0 and 100.\")\n",
    "\n",
    "        if \"weight\" not in g.es.attributes():\n",
    "            raise ValueError(\"Input graph must have a 'weight' attribute for edges.\")\n",
    "\n",
    "        # Get all weights and calculate the specified percentile\n",
    "        weights = g.es[\"weight\"]\n",
    "        weight_threshold = np.percentile(weights, percentile)\n",
    "\n",
    "        # Identify edges to keep\n",
    "        edges_to_keep = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] > weight_threshold\n",
    "        ]\n",
    "        threshold_edges = [\n",
    "            edge.index for edge in g.es if edge[\"weight\"] == weight_threshold\n",
    "        ]\n",
    "\n",
    "        # Randomly select from threshold edges to reach target number of edges\n",
    "        target_edge_count = int(self.initial_edge_count * (1 - percentile / 100))\n",
    "        edges_to_add = target_edge_count - len(edges_to_keep)\n",
    "        if edges_to_add > 0:\n",
    "            random.shuffle(threshold_edges)\n",
    "            edges_to_keep.extend(threshold_edges[:edges_to_add])\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_pruned = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Update statistics\n",
    "        self._update_statistics(g, g_pruned)\n",
    "\n",
    "        return g_pruned\n",
    "\n",
    "    def keep_random_percentile_of_edges(\n",
    "        self, g: ig.Graph, percentile: float\n",
    "    ) -> ig.Graph:\n",
    "        \"\"\"\n",
    "        Keep a random selection of edges based on the provided percentile.\n",
    "\n",
    "        Args:\n",
    "            g (ig.Graph): The input graph.\n",
    "            percentile (float): The percentile of edges to keep (0-100).\n",
    "\n",
    "        Returns:\n",
    "            ig.Graph: A new graph with the randomly selected edges.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If percentile is not between 0 and 100.\n",
    "        \"\"\"\n",
    "        # if nx object, convert to igraph\n",
    "        if isinstance(g, nx.Graph):\n",
    "            g = ig.Graph.from_networkx(g)\n",
    "        if not (0 <= percentile <= 100):\n",
    "            raise ValueError(\"percentile must be between 0 and 100.\")\n",
    "\n",
    "        # Calculate the number of edges to keep\n",
    "        total_edges = g.ecount()\n",
    "        num_edges_to_keep = int(total_edges * (percentile / 100))\n",
    "\n",
    "        # Randomly select edges to keep\n",
    "        all_edges = list(range(total_edges))\n",
    "        random.shuffle(all_edges)\n",
    "        edges_to_keep = all_edges[:num_edges_to_keep]\n",
    "\n",
    "        # Create a new graph with only the selected edges\n",
    "        g_random = g.subgraph_edges(edges_to_keep, delete_vertices=False)\n",
    "\n",
    "        # Update statistics\n",
    "        self._update_statistics(g, g_random)\n",
    "\n",
    "        return g_random\n",
    "\n",
    "    def get_prune_summary(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Returns a summary of the pruning process.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, int]: A dictionary containing the initial and final edge counts and the number of isolates.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"initial_edge_count\": self.initial_edge_count,\n",
    "            \"final_edge_count\": self.final_edge_count,\n",
    "            \"initial_isolates\": self.initial_isolates,\n",
    "            \"final_isolates\": self.final_isolates,\n",
    "        }\n",
    "\n",
    "\n",
    "# example usage\n",
    "# g = ... # your graph object\n",
    "# pruner = PruneEdges()\n",
    "# g_pruned = pruner.prune_edges_by_percentile_weight(g, 10)\n",
    "# summary = pruner.get_prune_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Bundled Edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeProcessor:\n",
    "    \"\"\"\n",
    "    A class to process edge data for graph visualization.\n",
    "\n",
    "    This class handles the creation of bundled and straight edges from input dataframes,\n",
    "    concatenates the results, and cleans the edge attributes for further analysis or visualization.\n",
    "\n",
    "    Attributes:\n",
    "    bundled_edge_pts (pd.DataFrame): DataFrame containing points for bundled edges.\n",
    "    edges_to_bundle_df (pd.DataFrame): DataFrame mapping edges to their source and target nodes.\n",
    "    edge_df_with_source_target_coords (pd.DataFrame): DataFrame containing all edge coordinates and their lengths.\n",
    "    threshold (float): Length threshold to determine which edges are considered straight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bundled_edge_pts,\n",
    "        edges_to_bundle_df,\n",
    "        edge_df_with_source_target_coords,\n",
    "        threshold,\n",
    "    ):\n",
    "        self.bundled_edge_pts = bundled_edge_pts\n",
    "        self.edges_to_bundle_df = edges_to_bundle_df\n",
    "        self.edge_df_with_source_target_coords = edge_df_with_source_target_coords\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def create_bundled_edges_df(self):\n",
    "        sub_bundle_idx = 0\n",
    "        x, y, z = [], [], []\n",
    "        bundled_edges_dict = {}\n",
    "\n",
    "        for i in range(len(self.bundled_edge_pts)):\n",
    "            # if not nan\n",
    "            if pd.isna(self.bundled_edge_pts.iloc[i, 0]):\n",
    "                target = self.edges_to_bundle_df.loc[sub_bundle_idx, \"target\"]\n",
    "                source = self.edges_to_bundle_df.loc[sub_bundle_idx, \"source\"]\n",
    "                bundled_edges_dict[(source, target)] = {\n",
    "                    \"x\": x,\n",
    "                    \"y\": y,\n",
    "                    \"z\": z,\n",
    "                }\n",
    "                sub_bundle_idx += 1\n",
    "                x, y, z = [], [], []\n",
    "            else:\n",
    "                x.append(self.bundled_edge_pts.iloc[i, 0])\n",
    "                y.append(self.bundled_edge_pts.iloc[i, 1])\n",
    "                z.append(self.bundled_edge_pts.iloc[i, 2])\n",
    "\n",
    "        # Create DataFrame\n",
    "        bundled_edges_df = pd.DataFrame.from_dict(bundled_edges_dict, orient=\"index\")\n",
    "        bundled_edges_df[\"source\"] = [x[0] for x in bundled_edges_df.index]\n",
    "        bundled_edges_df[\"target\"] = [x[1] for x in bundled_edges_df.index]\n",
    "        bundled_edges_df.reset_index(drop=True, inplace=True)\n",
    "        print(f\"Number of bundled edges: {bundled_edges_df.shape[0]}\")\n",
    "        return bundled_edges_df\n",
    "\n",
    "    def create_straight_edges_df(self):\n",
    "        straight_edges_mask = (\n",
    "            self.edge_df_with_source_target_coords[\"segment_length\"] <= self.threshold\n",
    "        )\n",
    "\n",
    "        straight_edges_df = self.edge_df_with_source_target_coords.loc[\n",
    "            straight_edges_mask,\n",
    "            [\n",
    "                \"source\",\n",
    "                \"target\",\n",
    "                \"source_x\",\n",
    "                \"source_y\",\n",
    "                \"source_z\",\n",
    "                \"target_x\",\n",
    "                \"target_y\",\n",
    "                \"target_z\",\n",
    "            ],\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "        straight_edges_df[\"x\"] = [\n",
    "            [source_x, target_x]\n",
    "            for source_x, target_x in zip(\n",
    "                straight_edges_df[\"source_x\"], straight_edges_df[\"target_x\"]\n",
    "            )\n",
    "        ]\n",
    "        straight_edges_df[\"y\"] = [\n",
    "            [source_y, target_y]\n",
    "            for source_y, target_y in zip(\n",
    "                straight_edges_df[\"source_y\"], straight_edges_df[\"target_y\"]\n",
    "            )\n",
    "        ]\n",
    "        straight_edges_df[\"z\"] = [\n",
    "            [source_z, target_z]\n",
    "            for source_z, target_z in zip(\n",
    "                straight_edges_df[\"source_z\"], straight_edges_df[\"target_z\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Drop coordinate columns\n",
    "        straight_edges_df = straight_edges_df.drop(\n",
    "            columns=[\n",
    "                \"source_x\",\n",
    "                \"source_y\",\n",
    "                \"source_z\",\n",
    "                \"target_x\",\n",
    "                \"target_y\",\n",
    "                \"target_z\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return straight_edges_df\n",
    "\n",
    "    def concat_and_clean_edges(self, bundled_edges_df, straight_edges_df):\n",
    "        # Concatenate bundled and straight edges\n",
    "        final_edges_df = pd.concat(\n",
    "            [bundled_edges_df, straight_edges_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "        # Round to 10 decimal places in x, y, z\n",
    "        for coord in [\"x\", \"y\", \"z\"]:\n",
    "            final_edges_df[coord] = final_edges_df[coord].apply(\n",
    "                lambda points: [round(i, 10) for i in points]\n",
    "            )\n",
    "\n",
    "        return final_edges_df\n",
    "\n",
    "    def post_process_edges(self):\n",
    "        bundled_edges_df = self.create_bundled_edges_df()\n",
    "        straight_edges_df = self.create_straight_edges_df()\n",
    "        final_edges_df = self.concat_and_clean_edges(\n",
    "            bundled_edges_df, straight_edges_df\n",
    "        )\n",
    "\n",
    "        print(f\"Number of total edges: {final_edges_df.shape[0]}\")\n",
    "        print(f\"Number of straight edges: {straight_edges_df.shape[0]}\")\n",
    "\n",
    "        return final_edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes Saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodesSaver:\n",
    "    \"\"\"\n",
    "    A utility class for saving node data from a DataFrame to JSON format, particularly for use in JavaScript applications.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def save_dataframe_nodes_to_json(\n",
    "        df: pd.DataFrame,\n",
    "        paths: Union[str, List[str]],\n",
    "        return_json: bool = False,\n",
    "        attributes: List[str] = None,\n",
    "    ) -> Optional[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Save the DataFrame nodes to one or more JSON files.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The input DataFrame containing node data.\n",
    "            paths (Union[str, List[str]]): Path or list of paths to save the JSON file(s).\n",
    "            return_json (bool): If True, return the JSON data as well as saving it.\n",
    "            attributes (List[str]): List of node attributes to include in the JSON.\n",
    "\n",
    "        Returns:\n",
    "            Optional[List[Dict]]: List of node dictionaries if return_json is True, else None.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If a specified attribute is missing from the DataFrame.\n",
    "        \"\"\"\n",
    "        if attributes is None:\n",
    "            attributes = [\n",
    "                \"node_id\",\n",
    "                \"node_name\",\n",
    "                \"doi\",\n",
    "                \"year\",\n",
    "                \"title\",\n",
    "                \"cluster\",\n",
    "                \"centrality\",\n",
    "                \"x\",\n",
    "                \"y\",\n",
    "                \"z\",\n",
    "            ]\n",
    "\n",
    "        # Check if all attributes are present in the DataFrame\n",
    "        missing_attributes = [attr for attr in attributes if attr not in df.columns]\n",
    "        if missing_attributes:\n",
    "            raise ValueError(f\"Missing attributes in DataFrame: {missing_attributes}\")\n",
    "\n",
    "        # Fix encoding of titles\n",
    "        df[\"title\"] = df[\"title\"].apply(NodesSaver.fix_encoding)\n",
    "\n",
    "        # Convert DataFrame to list of dictionaries\n",
    "        nodes_json = df[attributes].to_dict(orient=\"records\")\n",
    "\n",
    "        # Convert single path to list for consistent processing\n",
    "        if isinstance(paths, str):\n",
    "            paths = [paths]\n",
    "\n",
    "        # Save to all specified paths\n",
    "        for path in paths:\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(nodes_json, f)\n",
    "            print(f\"Graph nodes saved to {path}\")\n",
    "\n",
    "        return nodes_json if return_json else None\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_encoding(title: str) -> str:\n",
    "        \"\"\"\n",
    "        Fix the encoding of a string.\n",
    "\n",
    "        Args:\n",
    "            title (str): The input string to fix.\n",
    "\n",
    "        Returns:\n",
    "            str: The fixed string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            decoded_title = title.encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            return decoded_title.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except UnicodeEncodeError:\n",
    "            # If the above method fails, return the original title\n",
    "            return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges Saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeTransformer:\n",
    "    def __init__(self, edges_df, nodes_df):\n",
    "        self.edges_df = edges_df\n",
    "        self.nodes_df = nodes_df\n",
    "\n",
    "    def add_color_attr(self):\n",
    "        \"\"\"\n",
    "        Add cluster information to edges based on node clusters.\n",
    "        If nodes are in the same cluster, the cluster ID is added; otherwise, -1 is added.\n",
    "        \"\"\"\n",
    "        self.edges_df[\"color\"] = [\n",
    "            (\n",
    "                self.nodes_df.loc[source, \"cluster\"]\n",
    "                if self.nodes_df.loc[source, \"cluster\"]\n",
    "                == self.nodes_df.loc[target, \"cluster\"]\n",
    "                else -1\n",
    "            )\n",
    "            for source, target in zip(self.edges_df[\"source\"], self.edges_df[\"target\"])\n",
    "        ]\n",
    "        return self.edges_df\n",
    "\n",
    "    def transform_edges(\n",
    "        self, x_col=\"x\", y_col=\"y\", z_col=\"z\", extra_edge_attributes=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Transform edge data from a DataFrame into a list of dictionaries with points and extra attributes.\n",
    "\n",
    "        Args:\n",
    "        x_col (str): Name of the column containing x-coordinates. Default is \"x\".\n",
    "        y_col (str): Name of the column containing y-coordinates. Default is \"y\".\n",
    "        z_col (str): Name of the column containing z-coordinates. Default is \"z\".\n",
    "        extra_edge_attributes (list): List of additional attribute names to include. Default is None.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of dictionaries, each representing an edge with its points and attributes.\n",
    "        \"\"\"\n",
    "        if extra_edge_attributes is None:\n",
    "            extra_edge_attributes = []\n",
    "\n",
    "        def create_edge_object(edge):\n",
    "            return {\n",
    "                **{attr: edge[attr] for attr in extra_edge_attributes if attr in edge},\n",
    "                \"points\": [\n",
    "                    {\"x\": float(x), \"y\": float(y), \"z\": float(z)}\n",
    "                    for x, y, z in zip(edge[x_col], edge[y_col], edge[z_col])\n",
    "                    if not (pd.isna(x) or pd.isna(y) or pd.isna(z))\n",
    "                ],\n",
    "            }\n",
    "\n",
    "        return [\n",
    "            create_edge_object(edge) for edge in self.edges_df.to_dict(orient=\"records\")\n",
    "        ]\n",
    "\n",
    "    def save_edges_to_json(self, edges_list, output_dir):\n",
    "        \"\"\"\n",
    "        Save the edges list to a JSON file.\n",
    "\n",
    "        Args:\n",
    "        edges_list (list): The list of edges to save.\n",
    "        output_dir (str): The directory path to save the JSON file.\n",
    "        \"\"\"\n",
    "        with open(output_dir, \"w\") as f:\n",
    "            json.dump(edges_list, f)\n",
    "        print(f\"Edges data saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and layout the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/zjbwrdgj0bg9zyhx3l7134mm0000gn/T/ipykernel_39661/1447177093.py:4: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute. at src/io/graphml.c:488\n",
      "  g = ig.Graph.Read_GraphML(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Attributes: ['doi', 'year', 'title', 'cluster', 'node_id', 'node_name', 'centrality']\n",
      "Edge Attributes: ['weight', 'edge_id']\n",
      "Number of nodes: 40643\n",
      "Number of edges: 602779\n",
      "Starting Fruchterman-Reingold layout process...\n",
      "Layout parameters: {'iterations': 50, 'threshold': 0.0001, 'weight': 'weight', 'scale': 5000, 'center': (0, 0), 'dim': 2, 'seed': 1887}\n",
      "Converting to NetworkX Graph...\n",
      "Conversion complete.\n",
      "Graph has 37804 nodes and 564246 edges.\n",
      "Calculating layout...\n",
      "Layout calculation completed in 1931.34 seconds.\n",
      "Processing layout results...\n",
      "Layout boundaries:\n",
      "X-axis: Min = -5000.00, Max = 3732.82\n",
      "Y-axis: Min = -3769.51, Max = 3854.39\n",
      "Assigning coordinates to nodes...\n",
      "Layout process completed in 1933.11 seconds.\n",
      "####################################################################################################\n",
      "Layout done\n",
      "####################################################################################################\n",
      "Bounds of the layout:\n",
      "Min x: -5000.0, Max x: 3732.816162109375\n",
      "Min y: -3769.513427734375, Max y: 3854.394287109375\n",
      "Z coordinate range: 0 to 1746.563232421875\n",
      "Description of the Z coordinate values:\n",
      "count    37804.000000\n",
      "mean       265.433894\n",
      "std        274.004050\n",
      "min          0.000000\n",
      "25%         76.839088\n",
      "50%        179.341355\n",
      "75%        357.205859\n",
      "max       1746.563232\n",
      "dtype: float64\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n",
      "Z coordinate added to nodes\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# g = GraphReader.read_and_clean_graph(INPUT_GRAPH_PATH)\n",
    "g = GraphReader.read_and_clean_graph(\n",
    "    \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/07-clustered-graphs/alpha0.3_k10_res0.002.graphml\"\n",
    ")\n",
    "cluster_list = list(range(0, 101))\n",
    "\n",
    "# subset to only cluster 0 to 100\n",
    "g = GraphReader.subgraph_of_clusters(g, cluster_list)\n",
    "\n",
    "total_nodes = len(g.vs)\n",
    "################################################################################################\n",
    "layout_params = {\n",
    "    # \"k\": 0.5, # distance between nodes; best to leave it to algo\n",
    "    \"iterations\": 50,  # (default=50) use 100\n",
    "    \"threshold\": 0.0001,  # default 0.0001\n",
    "    \"weight\": \"weight\",\n",
    "    \"scale\": 5000,\n",
    "    \"center\": (0, 0),\n",
    "    \"dim\": 2,\n",
    "    \"seed\": 1887,\n",
    "}\n",
    "\n",
    "g_fr, pos = LayoutUtility.fr_layout_nx(g, layout_params)\n",
    "\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Layout done\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Add z-coordinate to nodes based on centrality\n",
    "z_adder = ZCoordinateAdder(g_fr, percentage=20)\n",
    "g_z = z_adder.add_z_coordinate_to_nodes()\n",
    "\n",
    "print(\"#\" * 100)\n",
    "print(\"Z coordinate added to nodes\")\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved as GraphML: /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/fr_0to100clusters.graphml\n"
     ]
    }
   ],
   "source": [
    "# Assuming g_z is your NetworkX graph object\n",
    "\n",
    "path = \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/\"\n",
    "full_path = path + FR_GRAPH_FILENAME\n",
    "\n",
    "# Save as GraphML file\n",
    "# nx.write_graphml(g_z, full_path)\n",
    "\n",
    "print(f\"Graph saved as GraphML: {full_path}\")\n",
    "\n",
    "\n",
    "# read back in\n",
    "g_z = nx.read_graphml(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_edge_count': 564246, 'final_edge_count': 267167, 'initial_isolates': 0, 'final_isolates': 0}\n",
      "{'initial_edge_count': 564246, 'final_edge_count': 141061, 'initial_isolates': 0, 'final_isolates': 455}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "# prune edges\n",
    "pruning_weight_percentile = 25\n",
    "pruner = PruneEdges()\n",
    "g_pruned_weight = pruner.prune_edges_by_percentile_weight(\n",
    "    g_z, pruning_weight_percentile\n",
    ")\n",
    "summary = pruner.get_prune_summary()\n",
    "print(summary)\n",
    "\n",
    "# random percentage of edges\n",
    "pruning_random_percentile = 25\n",
    "pruner = PruneEdges()\n",
    "g_pruned_random = pruner.keep_random_percentile_of_edges(g_z, pruning_random_percentile)\n",
    "summary = pruner.get_prune_summary()\n",
    "print(summary)\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment length statistics:\n",
      "Min: 0.00\n",
      "Max: 4184.39\n",
      "Mean: 846.34\n",
      "Median: 753.14\n"
     ]
    }
   ],
   "source": [
    "# Assume `g` is an igraph.Graph object and you have the utility class imported.\n",
    "edges_df = GraphDataFrameUtility.edges_to_dataframe(g_pruned_random)\n",
    "# Create edge and node DataFrames\n",
    "nodes_df = GraphDataFrameUtility.nodes_to_dataframe(\n",
    "    g_pruned_random, normalize_coordinates=False, drop_columns=[\"node_id\", \"node_name\"]\n",
    ")\n",
    "\n",
    "# Merge edge and node positions\n",
    "edge_df_with_source_target_coords = (\n",
    "    GraphDataFrameUtility.create_edge_df_with_source_target_coords(g_pruned_random)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10th_percentile': 307.1183069149486,\n",
       " '25th_percentile': 483.5088850752821,\n",
       " '50th_percentile': 753.1420219814437,\n",
       " '75th_percentile': 1111.3386363689194}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dictionary of segment length, 25th, 50th, 75th percentile\n",
    "segment_length_dict = {\n",
    "    \"10th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].quantile(\n",
    "        0.10\n",
    "    ),\n",
    "    \"25th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].quantile(\n",
    "        0.25\n",
    "    ),\n",
    "    \"50th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].median(),\n",
    "    \"75th_percentile\": edge_df_with_source_target_coords[\"segment_length\"].quantile(\n",
    "        0.75\n",
    "    ),\n",
    "}\n",
    "segment_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quick check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37804, 37804)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_edge_df_with_source_target_coords = edge_df_with_source_target_coords.copy()\n",
    "to_normalize = [\n",
    "    \"source_x\",\n",
    "    \"source_y\",\n",
    "    \"source_z\",\n",
    "    \"target_x\",\n",
    "    \"target_y\",\n",
    "    \"target_z\",\n",
    "    \"segment_length\",\n",
    "]\n",
    "for col in to_normalize:\n",
    "    normalized_edge_df_with_source_target_coords[col] = (\n",
    "        GraphDataFrameUtility.minmax_normalize(\n",
    "            normalized_edge_df_with_source_target_coords[col]\n",
    "        )\n",
    "    )\n",
    "\n",
    "Nnodes = nodes_df.shape[0]\n",
    "\n",
    "subedges = (\n",
    "    normalized_edge_df_with_source_target_coords[\"segment_length\"]\n",
    "    > normalized_edge_df_with_source_target_coords[\"segment_length\"].median()\n",
    ")\n",
    "\n",
    "mat = sparse.coo_matrix(\n",
    "    (\n",
    "        np.ones(\n",
    "            normalized_edge_df_with_source_target_coords.loc[subedges].shape[0],\n",
    "            dtype=int,\n",
    "        ),\n",
    "        (\n",
    "            normalized_edge_df_with_source_target_coords.loc[subedges, \"source\"].values,\n",
    "            normalized_edge_df_with_source_target_coords.loc[subedges, \"target\"].values,\n",
    "        ),\n",
    "    ),\n",
    "    shape=(Nnodes, Nnodes),\n",
    ")\n",
    "\n",
    "print(mat.shape)\n",
    "\n",
    "ncomp, membership = sparse.csgraph.connected_components(mat)\n",
    "\n",
    "mvalue, mcounts = np.unique(membership, return_counts=True)\n",
    "mcounts, mcountdist = np.unique(mcounts, return_counts=True)\n",
    "\n",
    "# mcounts, mcountdist\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "dist, bins = np.histogram(\n",
    "    normalized_edge_df_with_source_target_coords[\"segment_length\"].values,\n",
    "    bins=np.exp(np.linspace(-8, 3, 100)),\n",
    ")\n",
    "\n",
    "ax.scatter(np.log(bins[:-1]), dist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUNDLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Threshold for Edge Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nr of Pruned Edges: 141061\n",
      "Edges to Bundle: 70530\n"
     ]
    }
   ],
   "source": [
    "# get edges to bundle above a certain threshold\n",
    "# threshold = 0.03\n",
    "threshold = segment_length_dict[\"50th_percentile\"]\n",
    "edges_to_bundle = edge_df_with_source_target_coords[\"segment_length\"] > threshold\n",
    "edges_to_bundle_df = edge_df_with_source_target_coords.loc[edges_to_bundle].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "print(f\"Total Nr of Pruned Edges: {len(edge_df_with_source_target_coords)}\")\n",
    "print(f\"Edges to Bundle: {edges_to_bundle.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Bundling\n",
      "Start Bundling\n",
      "Start Smoothing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-460.894348</td>\n",
       "      <td>2466.666748</td>\n",
       "      <td>79.636100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-378.387142</td>\n",
       "      <td>2309.987625</td>\n",
       "      <td>90.350801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-303.920197</td>\n",
       "      <td>2157.202680</td>\n",
       "      <td>101.078706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-243.495070</td>\n",
       "      <td>2011.101471</td>\n",
       "      <td>111.613553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-202.482246</td>\n",
       "      <td>1874.469863</td>\n",
       "      <td>121.517589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x            y           z\n",
       "0 -460.894348  2466.666748   79.636100\n",
       "1 -378.387142  2309.987625   90.350801\n",
       "2 -303.920197  2157.202680  101.078706\n",
       "3 -243.495070  2011.101471  111.613553\n",
       "4 -202.482246  1874.469863  121.517589"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundled_edge_pts = hammer_bundle(\n",
    "    nodes_df[[\"x\", \"y\", \"z\"]],\n",
    "    edges_to_bundle_df[[\"source\", \"target\"]],\n",
    "    initial_bandwidth=0.10,  # 0.01,\n",
    "    decay=0.7,  # 0.8,\n",
    "    tension=0.5,  # 0.8,\n",
    "    accuracy=5 * 10**2,\n",
    "    weight=None,\n",
    "    advect_iterations=50,\n",
    "    iterations=5,\n",
    "    min_segment_length=0.01,\n",
    "    max_segment_length=0.05,\n",
    ")\n",
    "bundled_edge_pts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Bundling Processing\n",
    "\n",
    "add source and target columns, create clean df and save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bundled edges: 70530\n",
      "Number of total edges: 141061\n",
      "Number of straight edges: 70531\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use the class\n",
    "edge_processor = EdgeProcessor(\n",
    "    bundled_edge_pts, edges_to_bundle_df, edge_df_with_source_target_coords, threshold\n",
    ")\n",
    "final_edges_df = edge_processor.post_process_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 0, 'target': 2916, 'color': -1, 'points': [{'x': -460.8943481445, 'y': 2466.6667480469, 'z': 79.6361000248}, {'x': -378.3871421136, 'y': 2309.9876252691, 'z': 90.3508005689}, {'x': -303.9201969169, 'y': 2157.2026798955, 'z': 101.0787058512}, {'x': -243.4950695568, 'y': 2011.1014709204, 'z': 111.6135534594}, {'x': -202.4822464515, 'y': 1874.4698632248, 'z': 121.5175890238}, {'x': -184.7617397564, 'y': 1750.2468304005, 'z': 130.1679006888}, {'x': -191.9790434633, 'y': 1641.5569208595, 'z': 136.8582638274}, {'x': -223.2715346754, 'y': 1551.4762414434, 'z': 140.9272595795}, {'x': -275.6149888963, 'y': 1482.4858499842, 'z': 141.8871778232}, {'x': -344.6639917286, 'y': 1435.7156654142, 'z': 139.5338458393}, {'x': -425.7526096844, 'y': 1410.228014487, 'z': 134.0186764917}, {'x': -514.6809663766, 'y': 1402.6451625052, 'z': 125.8644326349}, {'x': -608.0442587824, 'y': 1407.333121151, 'z': 115.9135909236}, {'x': -703.0825761383, 'y': 1417.1461418592, 'z': 105.2149963991}, {'x': -769.4600219727, 'y': 1544.5858154297, 'z': 75.958921497}]}\n",
      "Edges data saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/EdgesData0to100_BundlPerc50_BW0,4.json\n",
      "Edges data saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/EdgesData0to100_BundlPerc50_BW0,4.json\n"
     ]
    }
   ],
   "source": [
    "edge_transformer = EdgeTransformer(final_edges_df, nodes_df)\n",
    "edges_df_with_color = edge_transformer.add_color_attr()\n",
    "edges_list = edge_transformer.transform_edges(\n",
    "    extra_edge_attributes=[\"source\", \"target\", \"color\"]\n",
    ")\n",
    "\n",
    "print(edges_list[0])\n",
    "\n",
    "# Save to JSON\n",
    "OUTPUT_DIR = \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/\"\n",
    "edge_transformer.save_edges_to_json(edges_list, OUTPUT_DIR + EDGES_DATA_FILENAME)\n",
    "edge_transformer.save_edges_to_json(\n",
    "    edges_list,\n",
    "    THREEJS_OUTPUT_DIR + EDGES_DATA_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/NodesData0to100_BundlPerc50_BW0,4.json\n",
      "Graph nodes saved to /Users/jlq293/Projects/Random Projects/LW-ThreeJS/2d_ssrinetworkviz/src/data/NodesData0to100_BundlPerc50_BW0,4.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doi': '10.1016/0024-3205(82)90686-5',\n",
       " 'year': 1982,\n",
       " 'title': 'Serotonergic mechanism in the control of -endorphin and acth release in male rats',\n",
       " 'cluster': 70,\n",
       " 'centrality': 0.0456272141630445,\n",
       " 'x': -460.89434814453125,\n",
       " 'y': 2466.666748046875,\n",
       " 'z': 79.63610002475772,\n",
       " 'node_index': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save nodes\n",
    "OUTPUT_DIRA = OUTPUT_DIR + NODES_DATA_FILENAME\n",
    "\n",
    "OUTPUT_DIRB = THREEJS_OUTPUT_DIR + NODES_DATA_FILENAME\n",
    "\n",
    "saver = NodesSaver()\n",
    "nodes_json = saver.save_dataframe_nodes_to_json(\n",
    "    nodes_df,\n",
    "    paths=[OUTPUT_DIRA, OUTPUT_DIRB],\n",
    "    return_json=True,\n",
    "    attributes=[\n",
    "        \"doi\",\n",
    "        \"year\",\n",
    "        \"title\",\n",
    "        \"cluster\",\n",
    "        \"centrality\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"node_index\",\n",
    "    ],\n",
    ")\n",
    "nodes_json[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Determination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def explore_hammer_bundle_params(\n",
    "    edges_df, nodes_df, params, num_runs=5, base_output_dir=\"output\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Explore different parameter combinations for the hammer_bundle algorithm,\n",
    "    post-process results, and save outputs.\n",
    "\n",
    "    Args:\n",
    "    edges_df (pd.DataFrame): DataFrame containing edge information.\n",
    "    nodes_df (pd.DataFrame): DataFrame containing node information.\n",
    "    params (dict): Dictionary of parameter ranges to explore.\n",
    "    num_runs (int): Number of parameter combinations to try.\n",
    "    base_output_dir (str): Base directory for saving outputs.\n",
    "\n",
    "    Returns:\n",
    "    list: List of dictionaries containing results and file paths for each run.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    all_combinations = list(\n",
    "        product(\n",
    "            params[\"min_edge_length_percentiles\"],\n",
    "            params[\"initial_bandwidth_values\"],\n",
    "            params[\"decay_values\"],\n",
    "            params[\"tension_values\"],\n",
    "            params[\"min_segment_length_values\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"Nr of all possible combinations:\", len(all_combinations))\n",
    "\n",
    "    selected_combinations = np.random.choice(\n",
    "        len(all_combinations), num_runs, replace=False\n",
    "    )\n",
    "\n",
    "    print(f\"Selected Combinations:\")\n",
    "    for run in selected_combinations:\n",
    "        print(all_combinations[run])\n",
    "\n",
    "    for i, combo_index in enumerate(selected_combinations):\n",
    "        combo = all_combinations[combo_index]\n",
    "        (\n",
    "            min_edge_length_percentile,\n",
    "            initial_bandwidth,\n",
    "            decay,\n",
    "            tension,\n",
    "            min_segment_length,\n",
    "        ) = combo\n",
    "\n",
    "        print(f\"\\nRun {i+1}/{num_runs}\")\n",
    "        print(\n",
    "            f\"Parameters: \\n min_edge_length_percentile={min_edge_length_percentile}\\n initial_bandwidth={initial_bandwidth}\\n decay={decay}\\n tension={tension}\\n min_segment_length={min_segment_length}\"\n",
    "        )\n",
    "\n",
    "        # Create a unique identifier for this run\n",
    "        run_id = f\"run_{i+1}_p{min_edge_length_percentile}_b{initial_bandwidth}_d{decay}_t{tension}_m{min_segment_length}\"\n",
    "\n",
    "        # Create output directory for this run\n",
    "        run_output_dir = os.path.join(base_output_dir, run_id)\n",
    "        os.makedirs(run_output_dir, exist_ok=True)\n",
    "\n",
    "        # Calculate threshold and prepare edges for bundling\n",
    "        threshold = np.percentile(\n",
    "            edges_df[\"segment_length\"], min_edge_length_percentile\n",
    "        )\n",
    "        edges_to_bundle = edges_df[\"segment_length\"] > threshold\n",
    "        edges_to_bundle_df = edges_df.loc[edges_to_bundle].reset_index(drop=True)\n",
    "\n",
    "        print(f\"Total Nr of Pruned Edges: {len(edges_df)}\")\n",
    "        print(f\"Edges to Bundle: {edges_to_bundle.sum()}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Run hammer_bundle\n",
    "            bundled_edge_pts = hammer_bundle(\n",
    "                nodes_df[[\"x\", \"y\", \"z\"]],\n",
    "                edges_to_bundle_df[[\"source\", \"target\"]],\n",
    "                initial_bandwidth=initial_bandwidth,\n",
    "                decay=decay,\n",
    "                tension=tension,\n",
    "                accuracy=5 * 10**2,\n",
    "                weight=None,\n",
    "                advect_iterations=50,\n",
    "                iterations=5,\n",
    "                min_segment_length=min_segment_length,\n",
    "                max_segment_length=0.05,\n",
    "            )\n",
    "\n",
    "            # Post-processing\n",
    "            edge_processor = EdgeProcessor(\n",
    "                bundled_edge_pts, edges_to_bundle_df, edges_df, threshold\n",
    "            )\n",
    "            final_edges_df = edge_processor.post_process_edges()\n",
    "\n",
    "            edge_transformer = EdgeTransformer(final_edges_df, nodes_df)\n",
    "            edges_df_with_color = edge_transformer.add_color_attr()\n",
    "            edges_list = edge_transformer.transform_edges(\n",
    "                extra_edge_attributes=[\"source\", \"target\", \"color\"]\n",
    "            )\n",
    "\n",
    "            # Save edges to JSON\n",
    "            edges_filename = f\"edges_{run_id}.json\"\n",
    "            edge_transformer.save_edges_to_json(\n",
    "                edges_list, os.path.join(run_output_dir, edges_filename)\n",
    "            )\n",
    "\n",
    "            # Save nodes to JSON\n",
    "            nodes_filename = f\"nodes_{run_id}.json\"\n",
    "            saver = NodesSaver()\n",
    "            nodes_json = saver.save_dataframe_nodes_to_json(\n",
    "                nodes_df,\n",
    "                paths=[os.path.join(run_output_dir, nodes_filename)],\n",
    "                return_json=True,\n",
    "                attributes=[\n",
    "                    \"doi\",\n",
    "                    \"year\",\n",
    "                    \"title\",\n",
    "                    \"cluster\",\n",
    "                    \"centrality\",\n",
    "                    \"x\",\n",
    "                    \"y\",\n",
    "                    \"z\",\n",
    "                    \"node_index\",\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            end_time = time.time()\n",
    "            runtime = end_time - start_time\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"run_id\": run_id,\n",
    "                    \"parameters\": {\n",
    "                        \"min_edge_length_percentile\": min_edge_length_percentile,\n",
    "                        \"initial_bandwidth\": initial_bandwidth,\n",
    "                        \"decay\": decay,\n",
    "                        \"tension\": tension,\n",
    "                        \"min_segment_length\": min_segment_length,\n",
    "                    },\n",
    "                    \"edges_bundled\": edges_to_bundle.sum(),\n",
    "                    \"runtime\": runtime,\n",
    "                    \"output_dir\": run_output_dir,\n",
    "                    \"edges_file\": edges_filename,\n",
    "                    \"nodes_file\": nodes_filename,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(f\"Run completed in {runtime:.2f} seconds\")\n",
    "            print(f\"Results saved in {run_output_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in run: {str(e)}\")\n",
    "\n",
    "    # Save summary of all runs\n",
    "    summary_file = os.path.join(base_output_dir, \"exploration_summary.json\")\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of all possible combinations: 1\n",
      "Selected Combinations:\n",
      "(15, 0.02, 0.9, 0.3, 0.01)\n",
      "\n",
      "Run 1/1\n",
      "Parameters: \n",
      " min_edge_length_percentile=15\n",
      " initial_bandwidth=0.02\n",
      " decay=0.9\n",
      " tension=0.3\n",
      " min_segment_length=0.01\n",
      "Total Nr of Pruned Edges: 141061\n",
      "Edges to Bundle: 119901\n",
      "Process Bundling\n",
      "Start Bundling\n",
      "Start Smoothing\n",
      "Number of bundled edges: 119901\n",
      "Number of total edges: 141061\n",
      "Number of straight edges: 21160\n",
      "Edges data saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/ParamsFinding/run_1_p15_b0.02_d0.9_t0.3_m0.01/edges_run_1_p15_b0.02_d0.9_t0.3_m0.01.json\n",
      "Graph nodes saved to /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/ParamsFinding/run_1_p15_b0.02_d0.9_t0.3_m0.01/nodes_run_1_p15_b0.02_d0.9_t0.3_m0.01.json\n",
      "Run completed in 2861.68 seconds\n",
      "Results saved in /Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/ParamsFinding/run_1_p15_b0.02_d0.9_t0.3_m0.01\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_edge_length_percentiles\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m15\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_bandwidth_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.02\u001b[39m],  \u001b[38;5;66;03m# [0.05, 0.10, 0.2],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_segment_length_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m],\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m base_output_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/ParamsFinding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mexplore_hammer_bundle_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_df_with_source_target_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExploration completed. Results summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[28], line 166\u001b[0m, in \u001b[0;36mexplore_hammer_bundle_params\u001b[0;34m(edges_df, nodes_df, params, num_runs, base_output_dir)\u001b[0m\n\u001b[1;32m    164\u001b[0m summary_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_output_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexploration_summary.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(summary_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 166\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/condavenv/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/condavenv/lib/python3.11/json/encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/condavenv/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/condavenv/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/condavenv/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/condavenv/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Assuming edges_df and nodes_df are already defined\n",
    "params = {\n",
    "    \"min_edge_length_percentiles\": [15],\n",
    "    \"initial_bandwidth_values\": [0.02],  # [0.05, 0.10, 0.2],\n",
    "    \"decay_values\": [0.9],  # 0.9 results to big main bundles. little detailed bundling\n",
    "    \"tension_values\": [0.3],  # 0.9 results in little bundling\n",
    "    \"min_segment_length_values\": [0.01],\n",
    "}\n",
    "\n",
    "base_output_dir = (\n",
    "    \"/Users/jlq293/Projects/Study-1-Bibliometrics/data/99-testdata/ParamsFinding\"\n",
    ")\n",
    "results = explore_hammer_bundle_params(\n",
    "    edge_df_with_source_target_coords,\n",
    "    nodes_df,\n",
    "    params,\n",
    "    num_runs=1,\n",
    "    base_output_dir=base_output_dir,\n",
    ")\n",
    "\n",
    "print(\"\\nExploration completed. Results summary:\")\n",
    "for result in results:\n",
    "    print(f\"Run ID: {result['run_id']}\")\n",
    "    print(f\"Parameters: {result['parameters']}\")\n",
    "    print(f\"Edges Bundled: {result['edges_bundled']}\")\n",
    "    print(f\"Runtime: {result['runtime']:.2f} seconds\")\n",
    "    print(f\"Output Directory: {result['output_dir']}\")\n",
    "    print(f\"Edges File: {result['edges_file']}\")\n",
    "    print(f\"Nodes File: {result['nodes_file']}\")\n",
    "    print()\n",
    "\n",
    "print(\n",
    "    f\"Detailed summary saved in {os.path.join(base_output_dir, 'exploration_summary.json')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
